{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For tips on running notebooks in Google Colab, see\n",
    "# https://pytorch.org/tutorials/beginner/colab\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Reinforcement Learning (DQN) Tutorial\n",
    "**Author**: [Adam Paszke](https://github.com/apaszke)\n",
    "            [Mark Towers](https://github.com/pseudo-rnd-thoughts)\n",
    "\n",
    "\n",
    "This tutorial shows how to use PyTorch to train a Deep Q Learning (DQN) agent\n",
    "on the CartPole-v1 task from [Gymnasium](https://www.gymnasium.farama.org)_.\n",
    "\n",
    "**Task**\n",
    "\n",
    "The agent has to decide between two actions - moving the cart left or\n",
    "right - so that the pole attached to it stays upright. You can find more\n",
    "information about the environment and other more challenging environments at\n",
    "[Gymnasium's website](https://gymnasium.farama.org/environments/classic_control/cart_pole/)_.\n",
    "\n",
    ".. figure:: /_static/img/cartpole.gif\n",
    "   :alt: CartPole\n",
    "\n",
    "   CartPole\n",
    "\n",
    "As the agent observes the current state of the environment and chooses\n",
    "an action, the environment *transitions* to a new state, and also\n",
    "returns a reward that indicates the consequences of the action. In this\n",
    "task, rewards are +1 for every incremental timestep and the environment\n",
    "terminates if the pole falls over too far or the cart moves more than 2.4\n",
    "units away from center. This means better performing scenarios will run\n",
    "for longer duration, accumulating larger return.\n",
    "\n",
    "The CartPole task is designed so that the inputs to the agent are 4 real\n",
    "values representing the environment state (position, velocity, etc.).\n",
    "We take these 4 inputs without any scaling and pass them through a \n",
    "small fully-connected network with 2 outputs, one for each action. \n",
    "The network is trained to predict the expected value for each action, \n",
    "given the input state. The action with the highest expected value is \n",
    "then chosen.\n",
    "\n",
    "\n",
    "**Packages**\n",
    "\n",
    "\n",
    "First, let's import needed packages. Firstly, we need\n",
    "[gymnasium](https://gymnasium.farama.org/)_ for the environment,\n",
    "installed by using `pip`. This is a fork of the original OpenAI\n",
    "Gym project and maintained by the same team since Gym v0.19.\n",
    "If you are running this in Google Colab, run:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'bash'\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip3 install gymnasium[classic_control]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also use the following from PyTorch:\n",
    "\n",
    "-  neural networks (``torch.nn``)\n",
    "-  optimization (``torch.optim``)\n",
    "-  automatic differentiation (``torch.autograd``)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from env import PacmanEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import math\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "env = PacmanEnv()\n",
    "\n",
    "# set up matplotlib\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "# if GPU is to be used\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replay Memory\n",
    "\n",
    "We'll be using experience replay memory for training our DQN. It stores\n",
    "the transitions that the agent observes, allowing us to reuse this data\n",
    "later. By sampling from it randomly, the transitions that build up a\n",
    "batch are decorrelated. It has been shown that this greatly stabilizes\n",
    "and improves the DQN training procedure.\n",
    "\n",
    "For this, we're going to need two classes:\n",
    "\n",
    "-  ``Transition`` - a named tuple representing a single transition in\n",
    "   our environment. It essentially maps (state, action) pairs\n",
    "   to their (next_state, reward) result, with the state being the\n",
    "   screen difference image as described later on.\n",
    "-  ``ReplayMemory`` - a cyclic buffer of bounded size that holds the\n",
    "   transitions observed recently. It also implements a ``.sample()``\n",
    "   method for selecting a random batch of transitions for training.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([], maxlen=capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Save a transition\"\"\"\n",
    "        self.memory.append(Transition(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's define our model. But first, let's quickly recap what a DQN is.\n",
    "\n",
    "## DQN algorithm\n",
    "\n",
    "Our environment is deterministic, so all equations presented here are\n",
    "also formulated deterministically for the sake of simplicity. In the\n",
    "reinforcement learning literature, they would also contain expectations\n",
    "over stochastic transitions in the environment.\n",
    "\n",
    "Our aim will be to train a policy that tries to maximize the discounted,\n",
    "cumulative reward\n",
    "$R_{t_0} = \\sum_{t=t_0}^{\\infty} \\gamma^{t - t_0} r_t$, where\n",
    "$R_{t_0}$ is also known as the *return*. The discount,\n",
    "$\\gamma$, should be a constant between $0$ and $1$\n",
    "that ensures the sum converges. A lower $\\gamma$ makes \n",
    "rewards from the uncertain far future less important for our agent \n",
    "than the ones in the near future that it can be fairly confident \n",
    "about. It also encourages agents to collect reward closer in time \n",
    "than equivalent rewards that are temporally far away in the future.\n",
    "\n",
    "The main idea behind Q-learning is that if we had a function\n",
    "$Q^*: State \\times Action \\rightarrow \\mathbb{R}$, that could tell\n",
    "us what our return would be, if we were to take an action in a given\n",
    "state, then we could easily construct a policy that maximizes our\n",
    "rewards:\n",
    "\n",
    "\\begin{align}\\pi^*(s) = \\arg\\!\\max_a \\ Q^*(s, a)\\end{align}\n",
    "\n",
    "However, we don't know everything about the world, so we don't have\n",
    "access to $Q^*$. But, since neural networks are universal function\n",
    "approximators, we can simply create one and train it to resemble\n",
    "$Q^*$.\n",
    "\n",
    "For our training update rule, we'll use a fact that every $Q$\n",
    "function for some policy obeys the Bellman equation:\n",
    "\n",
    "\\begin{align}Q^{\\pi}(s, a) = r + \\gamma Q^{\\pi}(s', \\pi(s'))\\end{align}\n",
    "\n",
    "The difference between the two sides of the equality is known as the\n",
    "temporal difference error, $\\delta$:\n",
    "\n",
    "\\begin{align}\\delta = Q(s, a) - (r + \\gamma \\max_a' Q(s', a))\\end{align}\n",
    "\n",
    "To minimize this error, we will use the [Huber\n",
    "loss](https://en.wikipedia.org/wiki/Huber_loss)_. The Huber loss acts\n",
    "like the mean squared error when the error is small, but like the mean\n",
    "absolute error when the error is large - this makes it more robust to\n",
    "outliers when the estimates of $Q$ are very noisy. We calculate\n",
    "this over a batch of transitions, $B$, sampled from the replay\n",
    "memory:\n",
    "\n",
    "\\begin{align}\\mathcal{L} = \\frac{1}{|B|}\\sum_{(s, a, s', r) \\ \\in \\ B} \\mathcal{L}(\\delta)\\end{align}\n",
    "\n",
    "\\begin{align}\\text{where} \\quad \\mathcal{L}(\\delta) = \\begin{cases}\n",
    "     \\frac{1}{2}{\\delta^2}  & \\text{for } |\\delta| \\le 1, \\\\\n",
    "     |\\delta| - \\frac{1}{2} & \\text{otherwise.}\n",
    "   \\end{cases}\\end{align}\n",
    "\n",
    "### Q-network\n",
    "\n",
    "Our model will be a feed forward  neural network that takes in the\n",
    "difference between the current and previous screen patches. It has two\n",
    "outputs, representing $Q(s, \\mathrm{left})$ and\n",
    "$Q(s, \\mathrm{right})$ (where $s$ is the input to the\n",
    "network). In effect, the network is trying to predict the *expected return* of\n",
    "taking each action given the current input.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "\n",
    "    def __init__(self, n_observations, n_actions):\n",
    "        super(DQN, self).__init__()\n",
    "        self.layer1 = nn.Linear(n_observations, 128)\n",
    "        self.layer2 = nn.Linear(128, 128)\n",
    "        self.layer3 = nn.Linear(128, n_actions)\n",
    "\n",
    "    # Called with either one element to determine next action, or a batch\n",
    "    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        return self.layer3(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "### Hyperparameters and utilities\n",
    "This cell instantiates our model and its optimizer, and defines some\n",
    "utilities:\n",
    "\n",
    "-  ``select_action`` - will select an action accordingly to an epsilon\n",
    "   greedy policy. Simply put, we'll sometimes use our model for choosing\n",
    "   the action, and sometimes we'll just sample one uniformly. The\n",
    "   probability of choosing a random action will start at ``EPS_START``\n",
    "   and will decay exponentially towards ``EPS_END``. ``EPS_DECAY``\n",
    "   controls the rate of the decay.\n",
    "-  ``plot_durations`` - a helper for plotting the duration of episodes,\n",
    "   along with an average over the last 100 episodes (the measure used in\n",
    "   the official evaluations). The plot will be underneath the cell\n",
    "   containing the main training loop, and will update after every\n",
    "   episode.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH_SIZE is the number of transitions sampled from the replay buffer\n",
    "# GAMMA is the discount factor as mentioned in the previous section\n",
    "# EPS_START is the starting value of epsilon\n",
    "# EPS_END is the final value of epsilon\n",
    "# EPS_DECAY controls the rate of exponential decay of epsilon, higher means a slower decay\n",
    "# TAU is the update rate of the target network\n",
    "# LR is the learning rate of the ``AdamW`` optimizer\n",
    "BATCH_SIZE = 128\n",
    "GAMMA = 0.99\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 10000\n",
    "TAU = 0.001\n",
    "LR = 1e-5\n",
    "\n",
    "# Get number of actions from gym action space\n",
    "n_actions = 4\n",
    "# Get the number of state observations\n",
    "state = env.reset()\n",
    "n_observations = len(state)+1\n",
    "\n",
    "policy_net = DQN(n_observations, n_actions).to(device)\n",
    "target_net = DQN(n_observations, n_actions).to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "optimizer = optim.AdamW(policy_net.parameters(), lr=LR, amsgrad=True)\n",
    "memory = ReplayMemory(10_000)\n",
    "\n",
    "\n",
    "steps_done = 0\n",
    "\n",
    "\n",
    "def select_action(state):\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    eps_threshold = 1*(0.9995**(steps_done/100))\n",
    "    steps_done += 1\n",
    "    \n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            # t.max(1) will return the largest column value of each row.\n",
    "            # second column on max result is index of where max element was\n",
    "            # found, so we pick action with the larger expected reward.\n",
    "            return policy_net(state).max(1)[1].view(1, 1)\n",
    "    else:\n",
    "        return torch.tensor([[np.random.randint(4)]], device=device, dtype=torch.long)\n",
    "\n",
    "\n",
    "episode_durations = []\n",
    "epsilon_values = []\n",
    "\n",
    "def plot_durations(show_result=False):\n",
    "    plt.figure(1)\n",
    "    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
    "    if show_result:\n",
    "        plt.title('Result')\n",
    "    else:\n",
    "        plt.clf()\n",
    "        plt.title('Training...')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Duration')\n",
    "    plt.plot(durations_t.numpy())\n",
    "    plt.plot(epsilon_values)\n",
    "    # Take 100 episode averages and plot them too\n",
    "    if len(durations_t) >= 100:\n",
    "        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n",
    "        means = torch.cat((torch.zeros(99), means))\n",
    "        plt.plot(means.numpy())\n",
    "\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "    if is_ipython:\n",
    "        if not show_result:\n",
    "            display.display(plt.gcf())\n",
    "            display.clear_output(wait=True)\n",
    "        else:\n",
    "            display.display(plt.gcf())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop\n",
    "\n",
    "Finally, the code for training our model.\n",
    "\n",
    "Here, you can find an ``optimize_model`` function that performs a\n",
    "single step of the optimization. It first samples a batch, concatenates\n",
    "all the tensors into a single one, computes $Q(s_t, a_t)$ and\n",
    "$V(s_{t+1}) = \\max_a Q(s_{t+1}, a)$, and combines them into our\n",
    "loss. By definition we set $V(s) = 0$ if $s$ is a terminal\n",
    "state. We also use a target network to compute $V(s_{t+1})$ for\n",
    "added stability. The target network is updated at every step with a \n",
    "[soft update](https://arxiv.org/pdf/1509.02971.pdf)_ controlled by \n",
    "the hyperparameter ``TAU``, which was previously defined.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
    "    # detailed explanation). This converts batch-array of Transitions\n",
    "    # to Transition of batch-arrays.\n",
    "    batch = Transition(*zip(*transitions))\n",
    "\n",
    "    # Compute a mask of non-final states and concatenate the batch elements\n",
    "    # (a final state would've been the one after which simulation ended)\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                          batch.next_state)), device=device, dtype=torch.bool)\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                                if s is not None])\n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
    "    # columns of actions taken. These are the actions which would've been taken\n",
    "    # for each batch state according to policy_net\n",
    "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
    "\n",
    "    # Compute V(s_{t+1}) for all next states.\n",
    "    # Expected values of actions for non_final_next_states are computed based\n",
    "    # on the \"older\" target_net; selecting their best reward with max(1)[0].\n",
    "    # This is merged based on the mask, such that we'll have either the expected\n",
    "    # state value or 0 in case the state was final.\n",
    "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
    "    with torch.no_grad():\n",
    "        next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0]\n",
    "    # Compute the expected Q values\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "\n",
    "    # Compute Huber loss\n",
    "    criterion = nn.SmoothL1Loss()\n",
    "    loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "    # Optimize the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    # In-place gradient clipping\n",
    "    torch.nn.utils.clip_grad_value_(policy_net.parameters(), 100)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, you can find the main training loop. At the beginning we reset\n",
    "the environment and obtain the initial ``state`` Tensor. Then, we sample\n",
    "an action, execute it, observe the next state and the reward (always\n",
    "1), and optimize our model once. When the episode ends (our model\n",
    "fails), we restart the loop.\n",
    "\n",
    "Below, `num_episodes` is set to 600 if a GPU is available, otherwise 50 \n",
    "episodes are scheduled so training does not take too long. However, 50 \n",
    "episodes is insufficient for to observe good performance on CartPole.\n",
    "You should see the model constantly achieve 500 steps within 600 training \n",
    "episodes. Training RL agents can be a noisy process, so restarting training\n",
    "can produce better results if convergence is not observed.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHFCAYAAAAOmtghAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAACYsklEQVR4nOzdd5wTZf4H8M8zMynbC2WXssDSQRBxQQFRQRFEBNspZwNsJ6KiYDlQz8JPRT2P47wTbChnR2ynggVQQAFFqiBVellYWJbtm2Rmnt8fk0z6lmySSbLf9+u1r02m5cmkzDdP+T6Mc85BCCGEEJIgBKMLQAghhBASThTcEEIIISShUHBDCCGEkIRCwQ0hhBBCEgoFN4QQQghJKBTcEEIIISShUHBDCCGEkIRCwQ0hhBBCEgoFN4QQQghJKBTcEEKiav78+WCM6X+SJKFVq1b485//jN27dxtdPDDG8OSTT+r3t23bhieffBL79+83rEyEkIah4IYQYoi33noLa9aswdKlS3HPPffgiy++wODBg1FSUmJ00bxs27YNTz31FAU3hMQRyegCEEKapl69eqFfv34AgCFDhkBRFDzxxBP4/PPPccsttxhcOkJIPKOaG0JITHAFOsePH9eXrVu3DmPGjEF2djasViv69u2Ljz76yGu/qqoqPPjgg8jPz4fVakV2djb69euHDz74QN9myJAhGDJkiN9jTpgwAR06dAhapvnz5+Paa68FAAwdOlRvSps/f37oT5QQEnFUc0MIiQn79u0DAHTt2hUA8MMPP+DSSy/Fueeei1deeQUZGRn48MMPMXbsWFRVVWHChAkAgKlTp+Kdd97B008/jb59+6KyshJbt25FcXFxo8s0atQoPPvss3jkkUfw8ssv4+yzzwYAdOrUqdHHJoREDgU3hBBDKIoCWZZRU1ODVatW4emnn8YFF1yAMWPGAAAmTZqEM844A99//z0kSfuqGjFiBE6ePIlHHnkE48aNgyAIWLVqFYYPH44pU6boxx41alRYytiiRQt06dIFANCzZ08MGDAgLMclhEQWNUsRQgwxYMAAmEwmpKWl4dJLL0VWVhb+97//QZIk/PHHH9ixYwduvPFGAIAsy/rfZZddhsLCQuzcuRMAcM455+Drr7/GtGnTsHz5clRXVxv5tAghMYCCG0KIId5++238+uuv+P7773HnnXdi+/btuP766wG4+908+OCDMJlMXn+TJk0CAJw8eRIA8NJLL+Gvf/0rPv/8cwwdOhTZ2dm48sorY2JYOSHEGNQsRQgxRI8ePfROxEOHDoWiKHjjjTfw8ccfo3fv3gCA6dOn4+qrrw64f7du3QAAKSkpeOqpp/DUU0/h+PHjei3O6NGjsWPHDgCA1WpFaWmp3zFcARIhJLFQcEMIiQkvvPACPvnkEzz++OPYunUrunTpgs2bN+PZZ5+t9zFycnIwYcIEbN68GbNnz0ZVVRWSk5PRoUMHLFy4EDabDRaLBQBQXFyM1atXIz09vdZjuran5i5C4gcFN4SQmJCVlYXp06fj4Ycfxvvvv49XX30VI0eOxIgRIzBhwgS0adMGp06dwvbt27FhwwYsXLgQAHDuuefi8ssvx5lnnomsrCxs374d77zzDgYOHIjk5GQAwM0334xXX30VN910E+644w4UFxfjhRdeqDOwAbR8PADw2muvIS0tDVarFfn5+WjWrFnkTgYhpFGozw0hJGbce++9aNeuHWbMmIELLrgAa9euRWZmJu6//34MGzYMd911F5YuXYphw4bp+1x00UX44osvcMstt2D48OF44YUXMG7cOHz55Zf6Nueddx7++9//4vfff8cVV1yBp59+GtOnTw+Y+8ZXfn4+Zs+ejc2bN2PIkCHo37+/17EJIbGHcc650YUghBBCCAkXqrkhhBBCSEKh4IYQQgghCYWCG0IIIYQkFApuCCGEEJJQKLghhBBCSEKh4IYQQgghCaXJJfFTVRVHjx5FWloaGGNGF4cQQggh9cA5R3l5OVq3bg1BqL1upskFN0ePHkVeXp7RxSCEEEJICA4dOoS2bdvWuk2TC27S0tIAaCenPqnXCSGEEGK8srIy5OXl6dfx2jS54MbVFJWenk7BDSGEEBJn6tOlhDoUE0IIISShUHBDCCGEkIRCwQ0hhBBCEgoFN4QQQghJKBTcEEIIISShUHBDCCGEkIRCwQ0hhBBCEgoFN4QQQghJKBTcEEIIISShUHBDCCGEkIRiaHCzcuVKjB49Gq1btwZjDJ9//nmd+6xYsQIFBQWwWq3o2LEjXnnllcgXlBBCCCFxw9DgprKyEn369MF//vOfem2/b98+XHbZZTj//POxceNGPPLII5g8eTI++eSTCJeUEEIIIfHC0IkzR44ciZEjR9Z7+1deeQXt2rXD7NmzAQA9evTAunXr8OKLL+Kaa66JUCnrT5YVHC08AiWpGSySgNNVDpglAZU2GTnpVpyssCHVIkHlHCrnMIkCHAqHRRJQXiPDJDKkWiWoHFBVDkXlAACFc8gKh0NRYZYEJJtFKCqHQ+GossswiQLSrBLssgqHwsHBkWKWUONQwBiD1aQ9jso5JIFBYAycAxzaMU2iAJUDnHOYJQHVdgWSKEBggKxy2GUVAmOwSAJMkgBV5Thd5YBJYki3mvRySiJDlV2BQ1HBOSAK2j4A4FBU1DhUpFi0ckoig6Jy53aAJAiositgDLDJKlLMImoc2vOtsDmQlWyGonIIAoOsaOfGLAlQVO38VdhkAECaVQIDg8o5Tlc7IDAgK9mMSrsMSRBgFgWU1ThgNQkAGAQGcADlNTKapZjhULTnKqsqLJKIGoeCSruCZLOonzMA4BwoqbQjzWqCJDKYRAbnaYCscJglBpusQhQYRMZQVuNAikWCJGgTvjHGUOksc4pFgqpyJJlFVNhk57mQkWqRUGVXIDDt+GU1DqRbTVCd50xgDIxpz9UkCDhVZUe6VXt/yar2HnDNL2d3loWBQRC0+2ZJe19IAtPfB67/ssphErVzLavceb40KldxsrpIPxeMm5BpyYZZcm+jcAUnq4v0+2aWBquYBKtJBGOAqgIOVQXnHDZZ1c9bklmEyrX3hUNRtddMYqhxqM7nqz3vaoeCVIuof35qHNoxzBKD1STqj2tXbCixndJu25OQaU2FwBiSzSIcimsf13uUwyYrSDFLkFWufx4AoNquQOVAslkrf7Xd/dmqtitwKFx7jwCocSjgXDuuKDBU2WX982B2fn4EgUFVOWocKlSu7SuJ2rFMIoPCOcyi9tg1DhUORdWXZSab9Ncv2GuinfMUZCW5Jwe2K3aU2Ir192+ymAWRmfTn5HqfuM5FoHPk+boJjHmVoVquQpm9VN+/ZVIuTKL2GZVE90SHlY4KVDjKEYwiS2id3sLvOdY4bBAFCSbR4/X12UZWZRTXnAh6bKNYhFRkWtNQZVf07/pqu4LmaRZwDq/Pl0N14FTNyYDHUVSG3OQcCIL7fJbUFMOu2htVPkXhyLC0QIrZpC+rkitRbi/T76sqQ8ukHMicQ/W4NikqhyRo5WdM+xyXVjvQoXkyWmUkNapcjRFXs4KvWbMGw4cP91o2YsQIzJs3Dw6HAyaTyW8fm80Gm82m3y8rK/PbJhz4sa04OudKqBAw1D4LQN2zlhISj6xt/wtT2navZTXHroCjZKB+P6n9K5CS9+v3uWpC5Z4HwOXMKJUSALMjpfPfIUjl7jLsnQLuyI5eGaLE2uYdmNJ/91rGVRFV+++BamsFQEFKp39AMJ/S16u25qjcOwWAiMZiUglSOs0CExz6MkdZL9QcuclrO8FyFMkdXgYTlFqPV330T5BL+3k8gAOpXZ6GKmegau/UIHupSO44G6KlKMh649T/vacgpeM/IVgCBzcA4DhdgJrCawEApqw1sOb+LyxllKvao/rAXQAAZipGSsfZXq8nANiLz4OtaHS9j7n/uVFhKVso4qpD8bFjx5CTk+O1LCcnB7Is4+TJwG+GmTNnIiMjQ//Ly8uLSNnUzPbIYSXoIBxHJ3Y0Io9BiJEskgCLJEBKPgBAu3hyrn2FiEkHPLZh+n2uSuCcgQkOCNbCqJbVmnTaHdg4yyBaoleGaAj4mujnXIFgPaJtY63UAxuuar9pBctJMLFaP05dzEG2sUgCLCnHwAQHOGfgqhYsiUkHA2xXCCYozu0k/z/9/XTIaz/JWggm2iBaimB2Pme/Y5vtemAT8NhG/dXzvWeRBFgsNXpg438s13k9oL/upmTtHHMuNKqM7tdLqwm1JB/3eD0lcO587OSD/gWPUXFVcwNo1fmeOOcBl7tMnz4dU6e6I/2ysrLIBDjmVPys9sSF4m8YJmzAHqVN+B+DkCiaMKgD5q/er9/f+bTWhNz/3cdRowDfXrsI18x/C5VpCwDm0LepkWvQ/z3tc/nzjT+i/xs3QErZB8YaV3VeX2e0Tseiyedjy4ktuGEx0DqlNQ4WJUFK2QP4/BJ1eeuW/rjlrV+jUr5wcr0m5773JKpk4OtrvkReeh66//t6mNK3om22hOXTR2Jf6T6M+RxIM6dhxXU/oe/b/bRf5YIdULTjdJi2KOjjnN0uE+/dPgA9Hv/Ga/ndQzvhoRHd8fU+4OGVwLmt+uOctDvwn913gAnu1/uDOwZgYKdmeH97CWauBUZ0uAT/GPIPv8fp+veHYGn5DRjTmmwzkkzY/MRwLNmzFlN/0rZZ+8jFyEw26+VtnWHF6ukX41jlMVzyMSAJEjaO39iY0xpWPV6+ClLqH9q5rsXOp0fiUNkhXPYZkCwl45cbf/Fa/9yyJXjv8FRAcOiv+/0/fItlB4HHBz6K67pdF1L5th49juuXDANjHNMv64I7L+iGL/fIeOQnYFDrAXht+GuY9OmH+LH8GSBKn+FwiKvgJjc3F8eOHfNaVlRUBEmS0KxZs4D7WCwWWCyWaBQPy9S+uFD8DReJG/GqUv+qO0KMwEynYMn5CnLZmZDLzvJbr3IFllYfQ63JhaNkMADgUNkh1Cg1AACraAXjWlOwKf132Iq0moHP//hcP4ZVsgLcDACwtPwOcnmfCD4jb4fKD7nLoGrlFMyBa3hVrsKS+xnU6rZwlPaPWhkbq0auwZNrnkSVXAXA+VwB/fmWmpdg/Ne7UC1rNTRJotYHgqsmrTbBegiyR1OJYD0ES/NlsJ86H0pVJ6/HklUZ1lYLoTqyYD85zGvd9uLt+uObBO37lok1+vpyx2lM+eFpbD/l3i4QVw0BmLvZ6pv93+CfG/+l37/7h9sgCQJSOu+FYDqNCrkFxn/9NmyKzes5xgru/IxYmi+DKX0zao5fDu5oHnDbMofWbSLQ+ZFc51Uqx/ivxwMA/jj9R9Dt68ssuq+PDq69ZvvL9nsdV4K2jWg9DnOz72Evvijkx4uWuGqWGjhwIJYsWeK17LvvvkO/fv0C9reJtmXK2QCAfmwnMhG8wxwhscDcbDlMaduQ1ObDgOuL5N9gzlwHa+5X+rJF+9y/7tPN6RAV95e0KX0zAOD9He/ryyRBgurIBAAI5uKo/vI7UX1C/8+kilq33VqyBuasX2BtHV8jLzcUbcCivdprkmZKQ7pF60CsOgMWWSjGhqINelDRNq0tAECQtGBITNnndTxr7ueQ0nbA2nqB32NtOfkbTJnrYWmxFGA2r3WugPdk9UkkiWnuFYK2fHPxaiw9uBRHKo54lcMPd/7edtbcAMDrv72Oo5WH9fu/ndyEDUUbIJhOO3c5gQ1FG/B7sdbnqE1abNWac7v2WgiWk5DSdsCUEbxWqdSmdcg+VXPKb12qmA2uSmBMxYaiDdhQtAFlzg6/bVODnM96kAR3HUeVclorK9NCg+JqrQN6suj+nJtbLNFramOZoTU3FRUV+OOPP/T7+/btw6ZNm5CdnY127dph+vTpOHLkCN5++20AwMSJE/Gf//wHU6dOxR133IE1a9Zg3rx5+OCDD4x6Cl6OoAW2q3noIRzCEGEzPlcHG10kQoJyXRyCcfAqj3vaqBlXDcDQvKEwiSZIckco1W0hJh3Wq91tsnbhmzVklnb/+CiYs7QqdibYwBVzGJ9FLeVXtS/g/jn98U1RmVZGpgbctkqOzx8jrnMNAB9e/iEszl/h9uKhUKrboUMLCdNG9gAAMDAU5BRo60+dB3P2KgDeHXvFJC34EEz+Ay9cAQwAMMEOrrh/8atcO6/n5J4DEyze26lW1CiVAICzW56N23vfjnNbnRv4CTlrbphHzU2NrD2u/XQ/qDVt8OLVg5FsFjF1ubu7geu9BgB9W/YNfGyD2E5cCrmqM0yZv8KUtg1MsAXdVlG1590qpZXfOouYgqp9kyFYjmPuTQX68hZJLdCnReNqRDkXwZgChWufGVnVgsuu2V0BAElCNir33YuU/H+DMa4FN9z4CoXaGBrcrFu3DkOHDtXvu/rGjB8/HvPnz0dhYSEOHnR3YMrPz8fixYsxZcoUvPzyy2jdujVeeumlmBgG7rJULUAP4RAuEddRcENii1AFKW271p9BsENK3aWvsuR+Di6nQq1pBQh2cNWCA7bN+nopYyMW7qrB7ye1X8ddsroA0C6YcmVniEmHISYdwsJdC1HqHA7cIb2DtjM3680gzHwKvNrjl30EHa88DgBomdwSXNYuGoKp2G87JlZi22mP/g3MBnDnBVqogpT2O6TUXbAXXwi1JvRfyJEgc+0idHbLs9EuvZ17BZegVHZDalYGLmnv/T3kUFSo9iwAgDnrV9iOa03ozORbW8DhGvXpYKfw05Hf9DVMKgdX3K+jK5BMN6eDORi4YgETbTBlrINc2RXlDud7IqMDzm97ftDn4+rcyszFkNK2gMt99GHOjpJzodbkYUjbi5GR5HFh5QyXtL+kttNkLG6CUtEDovUIkLYNguV40E1dz7VFcouA61V7S6j2lmF/vtyeBWY5iZ0VK7FwVwm2nNwCAMi0ZLofu6aNHgSJSUegVHYJaxnCzdDgZsiQIXqH4EDmz5/vt+zCCy/Ehg0bIliqxlmiFOBe6XNcKPwGMxywI7ajW9J0WFp8B3P2zwHXmbP8lx93twwgqfVCzFjjvp9m8ghQVGe7fMofmLFmhnsbs8c2zlEwlpaL9eGmkeZqptCq2LWLtOgxPN3FkvMlNp3apN83N/tR71NiyVkMc+Y6AIApfQvKtz8X0TI3lOsXtmfTQn1w1d1HQ6vBuQrJ7eZ5bSNYj+jB3DHLG1i4e6/HPj+ipnCsft+uaBdls2gGHNrxmWiDpeV3MKs/4FCl1mTP6kqRoTr7dliKkNT2PeAE04+tN1m5noOSBCZWQ3B0qPfzNpSzVkpK3R10E4eiBYlmITq1my6u98P6059h/ZrP9OWpplTvDVUJEBUktf0vKnY+Hc0iNlhcdSiOB1t4Po7zTOSw0xggbMNKNXodKAmpDQvQ1AA4h0mz4D8yXDIsGShoWYA0cxpGdXTnr3CUng3BfAIQqzGiZy4AoGeznshNydW3kcvPgClzgz4KJhpcwVWmNROqXbtAcsW/symTvM8L82iuE6TSyBUwDFzBjcgalqtGLu+p32Ym7TkKZu9aLUEqhQotuJFZifcBfJr3XAGISdB+zNmOXw4pfROktG1ggkNvtvJMMhiwXJVdYD81AFLaDq3ZVDytX/C5T3BTtf8umLJWI8t+aV1PNyYoVfkA4NWc58tVc2MWoxvc2E4MhylzLbq3SkX77GQA2udndKfRfttZc78EE2RoTdWx222Xgpsw4xCwTDkbN0jfY5iwgYIbEiUqtNqJ4L+MmVDjt6xi9yOQ0n4PmghMqcmFaNVGKPbI7oF/XfQvv224nK4nFfvXPYGTdjlKC2DK3KD1y2F256/YxiePq02lQ+vn0TmzM7hdu7j6JiUDoAdccmW+NmRdrIL+xe23ve8XugztnEf2uQQTas0N1GTYjo+EJefr4EP0PZ676uxAbD81EObsNf7Bjc9FWS7vDbm8N1K7PgWI1Sh3aMFRpwzvEVh+uBm241cC7HOYs34GF6rd2Xe59zlW7S1hO34lhIzQRwpFk+rQmgKZGLzPjV4DFuWaG6WyK5TKrhjdtyduG5wfdDvH6f6w5n6p3WGyPhIyFsVu2BXHlqhaZ69h4nowBO7ASEjYMBnJHf+J5PavAEF+GZtbfAMpRWtWcCVKAwCumoPuAwBccVdLN2a4qfY4gGg5gbTujyO125MQk/bWsVfoTlafxOYTWp+hJCkJXB8K7t/nxjXsmKtarY4pbRtSOs4CmMMryzKg9QVxEVN2IrXbk0jt+hQE6yEYwdXnpsHBDQDuvDBJ6b9hd4l/U4mUukO7wRxQmda5XG/O8qmBW35oOQB3zY3+GM7zfqiygUOWnfshc5k+xNu3WSreuD4DAIK+9/ec3gMAMIkx2p3B4zXw7LMXiyi4CRPP38ur1TNQxpPQmp1CPxbbbwAS/wRzEUTLCYjJB4AgIzFMGev123L5GeBchFzVHlAtcJT2herIAKA1UbmYWRrsp84DVyzgnGFQ60Ehl1G1tYRqz9TvM8EBMXlf8B0aaVvxNv129+zu+kXZM7BzF8Z5ofZ47oLlJARzsX5eXESzO7W/mLwXTJDBRHvAvjzREHLNDaDXhKiOLGw6scl/tfNCJpjdczVxV+2DMyB09aHJSdYyxyebkr3LV9Fdv51qSsVZLc+qV9Hkqk5652IA6JTeDVxOrWWPOODRz8kzA7OndLM2lL+wIlYzabs/P4I5eMfoWBDfoXCMssGMb5RzcJ20AleKq/Cr3L3unQgJlUcTgWvorf827toZuawPao6OdV7cGKAmofKPvwIQnEM8BYCpGDegI96uOISKXY8DTMX1E64MvYzcgso9DwNMhiVnkTY0nCl17xciV1K7vi37onlSc72vDWMqtOHP7iYO14VateUA8JifiTn0LLuqIw2CqdyrqcYzAy+rI/tspDQmuFFqtOHGTHDow60d5T2hVHaENfcrMFcuE+dzbp3SBntctQ8+r51rmHinjE7Y6JEn0XbsatiOX475t/THeZ1z/Gp2gpatojsqdj6J9GQBP0+/GCfKVFz4y4oGP8fYwmAv6Q9z1q+AELjvmSvVwtk5Z0ezYA2ipxEIku07VlDNTYR8qWqTCA4Xf4VATVMxQ0zeDUvO53pysUQgmNydPbX+Ir5UCF5J7FRn9bJnfaPzq4CbAIgAN0HQO6mKYcppIWht9M4mB0uL7yPWnPNHidYMkmJK0RZ49g3wCETElF3uSQp9+g+k5L+sz73kap5LavMhrG3egbX1B1rfEydTujHp/l15USQWwu9UZ6DCxHJ8uvtTAACXU/TzIKbsRVqPaUjpMBeANiUAAmQQPlZ5TE8+F7DZiZthEZPqHdi4SWDcgmRTsp5ULu4FSFLocrDsIN76/S0AWlNqrHI1r2mj7GJXgrxjYs8atSdO8xS0YGU4R9hhdHGIU1Lef2HO/hnm7J+MLkrYCB5NJYGqigWfKnDVHniqkmhhHsFYSv7LEXmM07bTAIByuzM5n0dnVM+ZsS0tvtNvK9XB55zjzizLgDbVhCljs9d614ijaGtMnxtVSQXnApig6Gn8uZyhN8W5Jh11sat2fXoEzyR7X+z5Qr/tmReFBOAMbliAWsuPd32s385JyfFbHyu4rDWdMcHhl6k6llBwEya+XTJlSPhO6QcAGCn84r8DMQRzVgfXlkgr7ngO4w6QgZcJ1frtqoO3QbUZm56eBamSDydX/qzezXu7HlXvb8OYZ9OSVoM3Ku9WKFWdUHXgDlQdvAVKtTtZn1zeHbYTw/X7gYOguofSR4IreV5IfW6UFFQduBM1hVfhbwP+huojY2EvPh9KZRdUH7rZb/ObeowPWHPjCiD75fTz63NDvPFaam5cTan5Gfm4otMV0SxWgzhOu+deq23kl9EouImgxaqWYnyk+CuNmiIRwzx+YQdqlnKle5erOsRIVtHIfxZ2luwE4O7oCrj61ADQz5GiN0n1zNS+sJWqTlAqu8F+6jx9P7kqH6rz1yoAr8BH78uj5/2IrkZ1KAagVreH4/S5uK7bdZDL+jozMwuQK87w2zYvNc89PYJH/p+SGq0mrl9uv5DK0KS4zl+Az6nrtRzdcXTU89w0CJfcU6jE8BxTFNxE0Cq1F8p4Mlqy0yigUVMkQvQhuz63XVzzBcXKUNpIN4upsOvDwL1qEpwXFlPmr9q69q/pqyyCT42Dx7BdqBav+54dtl19cgBEdPRXMI0NbmqjOtK97iebUuDqpyVIlfryXSXad1tI/X6aGmftYaDRUo2qhYsyfSSdFDgxaCyg4CaCHJD0nDeXiWsNLg1JVJ5DZANl4HXlGqltwr5oshe755PzHB4eLipzd56+qN1F+m39PDm/mMXkA/q6Flbvpjq5sjMcpWfCUd4TcvkZADfBVnQJ7KcGQi4NPDEj8+mjEg2RDG5qCq8BV7RALt0xCF0zu+mJ6LhHHyZX7ZjCIzf6LVG4ggLfwBFwT73Q8I7X0eeaVT6SIx4bi4KbCFusnAMAuFRcS01TMaWOOW7iSR1Dkl1ZeZWqDtEqUa24nIHqI9q8RKqjefiP7+zkmG5OR/Mk9/Ed5b0ABDlHzOf9wC2oOXoDag6P0yeItBdfDNvxK6D65FuRK7o5DxK9qSVcXAFFJGpNlMpuqNj1JMq3P4cc+ziIgqgHO1qHWO2xHc6ZpFuntg57GRKNatcmxAyUKdvVOTweghu935lBKRDqg4KbCPtJ7Y1yZ0K/s9geo4vTxLk7fYpJB2rZLr6IFneSNSnNv1lKSteaaDwzpBqulo6VjWUXtWY4v+G0zucvpe6ElN6IyXd9hoy7ajGSWn8MS+4noR83BFtOaLM3R60pwyMlgJS2FUBka48SjrMWVUw67LdKr7mJ1ezEHly1wdbcz+rY0jgU3ESYDWYsU7Vq7JHUNGUoJrr7Cag1ifIr07s2ULVn+W3hbraKndoq95Di8Ac3rmap41XeI+IUWyv9tpS+NfQH8GiSqT58kzZTspM569fQjxuCVqnac3INfY84j35bYspeMOYObuKhxsForik+Av3QiKc+N6ojG4B3n7NYQ8FNFHytaKOmLhN/gVFDRgl82ocT5HXwbfMOlDXUWXWsVHaMQoHqKYI1Nxza8x3TaYz3cnsL1BzTZjlmTIZc0RUAUH302gY+AkP59mdQvvNxyOW9AnTUjl7zsyuzcPfsaGVBZ7AVabNwuybcjKeLstH0HxoB3veu8xgPQaK9aIR2gymI1e9SCm6iYLnaB5XcgrbsJHqz6I+oIE4eXyhS2g4wsaKWjeOD70zfglQBU/ZKuL9wuN5sxWNpBl9Xp17njOPhVGZZCiBwlleuODMWM9k98V9IzXUioGojrLjPbNVSRvSyFbvmhLKK0ZsZm6sWANDn06KamwbQayxV+AbBW05qTYzxcB7dNa88ZoeDU3ATBTaY8YOzaWqU+LPBpWm6fJtAXEOC45m5+ff6bVeSOmvOYj1Jodekh7E08aCzrJ6TI4YDMxVDFbSgtVlSgCHneo2Ru8arsX2RfDsoW1t9gmj9mhWcX+GGTE/gPId6nxsaCl4n7lnL51Pr6qr54jFaE+LF43mYm600sCDBUXATJYucTVOjBGqaMoxfE078zy8lJh3Ub1cfGq/f1mt0PJ4jlzOjVaw6qa4alDDn3mGi+/ne0P0Gv/Wui4tnQFLbtAv14Zp3Si8DU6M2cso1yis/Iz8qjwcAqnPCTVeAqtfcxEFHWMN5BTfe7xFXcNg+vX00SxQaj9pK0erfOToWUHATJT+oZ6GSW5AnnEBf9ofRxWmafL5M/Duzys6JHGM3d4Mfj4BNqewGpcaZhdfZ98Y11YFiaxH1otVKjVCfG+fx2qa2RYYlI8Dj+mfY9R391FCuuZi8ihGlnEKnarR5spKl6E17oNd0CT41N9Tnpm4eQYFvk3KJTcv0HM3XMnQeTbEx2qmYgpsoqYFFT+h3pZg4kzbGE8Hkk01T8A5irK0/Rkr+y7C0it3hjb58M4SKVq05ytLyK22BK3iIkezEOq/mofDVZLoC1qDp651DmfUkZIDXBSckAWZM92wujBQmndZvJ5miOIu0Pvmjdq6pWaoh3CMWU7s877HY3W8l3ubnkpJjM60GBTdR9JlyPgAtW7FACf2M59sHJ2MTAMCcuc6AwoTG7jGJnSdXkNOY4MY1+WQkeHVIDOdnwVmTFSy4UWraQC73HVnEGhVfBay58Ug7ECmC+aR+u5k18JQW4XoFPY+jd6BmMjivX81NqP1IIvkejCWegxuyLP7pHAAg1k4Fj1C/uXCh4CaKVqln4DRPQQtWin5sp9HFaXqYd8fPSORYMYq9eHDA5cx5sfcd0VMfEf0uraXvQaO4am6E4DU31YcnQJXTwvaQrqyzAGAvcQabgYbkh5vzMXo16+WfYTmSfDpl+w4Fj2ZREoaz+TjVlBrd19JHQx65cs9U7QaPzTAiNksVh+rzC0OGhKXOpilK6Bd9ok/1qSljk55llcXwBHDBMLEcluYrAPiMwtDXVyKp7XvanQg1S4X8NezZ90AMX8du0Tk6rM7+H9yn5I25nnhOqqloTQqmtG1I6zENpqzVjThw7aytPtb+S9EbBg7Ao1lKRZlyVO8r4hrCHIlrc23HNDIYaDztusHqqHGMJM/zF+xUskAfENd3ihCbfRQpuIky11xTI6lpKvoC/MJIavsuAEBMdk+N4Tt3UKwyeTafOYMFzxm3xeS9+m3V1jIiZQi9dscd3AimU+EoCgB3eQ5X1D6Cw1EySPtf2qfxj6mkQJVTwBWzNoO4B2vuF40+fkDMps/MHe3RNa75pQBgW+Ui/XbLZO09Fonmk9qOGW9NVzXHL9Nv682XzLhcQZ7nL9ipDNisqAe5sZnIj4KbKPtJ7Y3TPAW5rAQDhd+NLk7T4vx1ZDsxzH+VZ9OIzwUqZnmOyHF+0VTtv8tvvepIg+345Q0+fKR/D+tTRbDwBfmuCQnPb3N+rdvZiy9ExZ4HUHP0usY/KJdQuedBVOz5KxRbbuOPVw+uUXAA8OiAR6PymG4iVFmroapRtVFnF7S9IO46whrFceoC9x1XSgIDa25CVVvOnlhAwU2U2WHCl8pAAMAN4jKDS9O0uAIY16RvLmLKLr3NGwAEczGktC1RLVtIPJp2XF803GPkjiuBn1LdDqF81CNd3e+aZycsX4yCDUl582BpoWUnrvtCy8DtLeA1pLUx1CTAlbsnGpzvZZGJtf7aD/QKhvKqMng3Wbhy+xQ7tNrBnOScOvYP7b0U6D0Y161QTq7g0JVvyZU6IGhfMcTg8/bsx+cx2ktK+w1J7V8xPHMxBTcGeE/Rag6GC+uRiXKDS9OEBBk5lNzuTb9OrUlt34v56Rm4V18PZ6CgeibXKtRuhLFmJKw8Rt00lqXFt5BSd+v300zh6zDcENyRGZ0HqmvIe4RxWQvkKpQiAECmJdOQcsQrVx8b14g313+bEp38SGHhmcjPoz9jUtv3ISXvR1Lb/xpRKh0FNwbYwdvhd7U9TEzBZdSxOHqE4MOiWaDag1jPYOxRSyOX9Xbe8q+JiNoFt4Hcw8EbX3NjSt/kdf9PXf/U6GOGQrV5zzbv2T8lnFznzKh5iGzHR8NePBg9k0fhjt534IYe/tmgSX04+6o4+wPGVyJEAdzZMT9Q0kop1dhktRTcGOQLRevQOEqguaYiTqgBhBoIzpqYQMOiWYBOrYLlZGyPonINxS09C+CufkJMf36CuRgAoNoj05m40fSam8bXLDHPpHwAWiQbl5HZdnyk+06kas0MrrlRba1hK7oc52bcgslnT0bzpOaGlCNeKTVttRuuwN7ZPNWreS+DShQapaIbAPcM8bGEghuDLFK1uaYGCNvQDKV1bE1CJlQjtfNMpHadATHZOQ9TgODGnOVfg5acNx+pXZ6FmLot0qUMkfPC6TMKzF3lrQU3sZpkK1zNUp6ZemOCR/8trU9F+EeSCCbv4dckzui5gpwJEFO00ZpRH9bfSK4+foL1qMEl8UfBjUEO85bYrHaEyDhGiPGTETfeCKZTYKJNm8zQSa1pDduJS+p9DL3vSoxxPSde18c4wPQAMSFMzVKxN7u7bzATgZEkzte+sDI235ukdr5NstyZfqLSHvnM1uEkOOdoc+V38nyvyxVdDCiRGwU3BlqszxROTVMRE+DCqcqZsJ+8GOXbn63nMWI0k7HrudWRfdgz900scafxb9zFn0UjG3BjRKJpyvmeHNBqQPiPTSLPd+JY53u4T8vG512KJm0kJtzPw+OzrI+GNAgFNwbybJpqTk1TERGwVkDPTlu/t7+l+Q+wtnkPSW3nB+ybYxgWuFnKjxqjuTP0vkEn69iwdsxUHI7SRE4EgxvD86LE3PjkOOFslhKdzTmm9N8AAEmSsQFBQ3GfSVS9ph0xOK8fBTcGOsxbYpPaCSLjGCn+YnRxElPA4CZ4HxS5smPA5ab0LZDSdsDS4ptwlSwM6llzI6dHoSwN5+o3whsZfPl2mE6vubRRx2ssubyH1/1wjAbzpafrryUvColdTNJSgGjBgfv90SLJuI7wIXF99zinYGCiR8d+Zmx0Q8GNwb5UtGrlK8TIzUHTpPlcWJQq74R29pJzvNbbjl1Z6+HEGOo45+5H5P0xLt/5FKoP34iao9eg4o+HtARzMUipaeO81bgvQVd7vyqnoHLfJGTYRjWyZI2j2tqgYs8D7gWRyN7qStcvxmh/KlIrpaoDAGeNh0dtR//c/gaVKEQ+HaOZZ+I+g7MWU3BjsC+VQVA5Qz9hF9qx40YXJ/H4Bjc270yq3Gd26MbWIkRVsBm/VQvk8t5wlPYHd8RmfxsAekfn2mo2BMtRpPWYBiHpQNBtxKT9AAClojvUmnZg4co63Ajc3gJcT6gY/mYpwaQ1Y9NoqfjEVW1UlGA+odd2MDBYxDiZ+sVJTzthOgUwGUlt39HXRaLGsiEouAmTUH97FiELq9QzAACXC2vCVyACIMAHzKdJSrX75Oeoo4kntjoX17PPTYyqT4filI4vaf87zA28AbPDlO6aoy3WMjGHp8N0IELSIQCAwmNvTh9Sf8xUBilNe/9y8Lib4Zw5r3yCqRSWnC8gmEs81lJw0+R9oWoJ/a4Wf4LhvbASjd+FxfstL5ed6TVkkXMRthMXBz+cEEPJqurboThWhWG0lFdm1FibZsL1ukSiXM7pNuqa04nEJu7sB8eVJL0zbjNrDNeyBqE65xjjSrJ/rjCquSFfK+egglvRWTiKc9kOo4uTIGSA2cF8p1Dwix1F2Io8OqByEUp1++CHjaHgxl0rZXwzTEj09vr6fgnWsV1dtW5RFs7pJfw4L4idMzuH/9gk4vS8MEzRX8th7YcZWKLQ6M36AWq0mWTs3HwU3MSACiRjkd6x+CeDSxP/mFiBtB6PIa3747C2+tx3bYA9PD8GtV8gmRBDzVKuJH5xWnPjKnd9L/5pPR6Fb4DDTO5qcFdG5pihvy7UoZh4cw+hdgc3hg/rD0Utta+i5USUC+MtPr8VE9Dn6nkAgMvEtTAjxpOSxTjRmcrcF1eskMv9525RbS2hVLeFXNFNq7mp7AilppV233dbR0bYyxu6+g0Fj1khNEsJFu9O94JHcMNMsZYrKnxzZ/mioeBxTm+yVPRmqXh8LT3z3DhOF3itUx1pgXaJmhiddKbp+UXtgWM8C7msBBcKm7FE7Wd0keJXgG5L9lODYDs+GoFrbkRU7b/bY52Eqn2TATCk9Zjmc+wY+j2g97mJ1+DG9fXTiJoNr+zEMdZfLYwTg/px1iAaPVoqvrq/xhDPwN6ZIyYua+E85ofzHGkqV3RD9aEJxpTJKYa+qZs2FQK+cjZNjRJpOobG8X9bc9WE2r+KfdcF3lYwlwBMRlqPaUjO/1fIJQwHMemwq1SGliNUrj4p2min+jX3eWcz5khq/XH4CxYmrhnlpdTtYT+2K99SXDZlED2wZ1AgJmkT+sZjzY3reQimMpizPUf7chgd+sbnt2KCcs01NUzYAAtip+Nq3AnwS5k7skI6lGLzzxhqyfkCgDahJjMb166sd+bzHDEUR7jsbuITkwPlsfGviRE98t0I1sNe6xw+CRmN5przytJ8ediPzWWtQ6rA6Cs8HnGPZilXjUeVXFXLHrHJN0+Yi6O0b5RL4o8+GTFkI++Mw7w5UlkNhgkbjC5O/ArQc99xOrRmvuqDt/stEyxF7ocSqkM6bjhxe7bRRQiJUtlJv+03qg1A4Lw17q8s5hPU2YuHhKdgcSQehw8TeI0UdOWK6Z7d3cAChYYrKX7Lqg7eArnM+AlAKbiJIRwC/qdoOW+upFFTAABmOonk/JdgbfM+mHQ66HZiyg5YW78PwXoE5uyVAbYIrXuZZ+2CXiaPFOPMyNwqziCO8zhsqwcACJArtaHMTKr0XxtgqgtXU492x/fcx2nfo1A4OxQb3eeGhMiVJkCQ9VrLNJOxHXDDQbVnQqnshlgILYwvAfHymTIYADBE2EwzhQNI7fwiROtRmNJ/Q2qX5wJvJNQgud18mDJ+Q0r+vyFaIz2Nhbst2dBZwlmcj5YC9A7ariytOmZHSv7Lfpt7BjyC5Zh+W5szrAlxvvaSQGNC4lGgHyRx2aHYh2prZXQRdBTcxJg/eFtsUjvBxBRcIwaqgSC+BM9f81Hg3c5s3EeI6TU38XuBcyUz44r3nDpM9G7u0zqE+1SDe4xcqz48LkIlDJ1Xcsiw4u6amwS4IDZJqhWO02d7LWqVEjuBQUPUHL1Gv20rGmlgSbxRcBODPlAuAgCMFX9AzA1vjarGPXeluk3dG9WnFIrPrNqe/UOMnGvK9dgRqrnhPPLvPVe/GyYEz+0kV3VA9eEbte08mwSd+9hP9wN3poEHgJCKHYGnKldofShU2b9fQuOoYEwrsMRqD2zD9bSCHae+x+chliQa70Gj2IqHet23StZat4/VU+Eo7Y/y7c+hfPtzUO0tjS6OjoKbGPSlMhAV3IqOwjEMEMI/jDR+1N2fhUllSOk0K6Kl8J11W0rZp982pW+O6GMHp0IwOWusIlRzE43vUlf1vJTm/T5nkrtJVrQeBbg2okRMOgJz8+8AAJaW3wIABJN3ZuJYuQZw1TlMVqpEWLMUe/Q1isWamzib+zFmxMKw/kR67Si4iUFVsOILZSAA4M/i9waXxkD1yFwrWg8FXVdz7EpwVWx080DNkev1C5UvKXV3o44dKs9mG9Ue2jD3sJSjkftzVWuOUuVUr+WeHYyZYAf3qP2wtPD+THgGmyGLwJc6lzPdhzeHsW+Wx+ciFjsUswiczNouuvE2k7aL7yhHo/LceJ6/YGcyEq9ppFFwEybhrjL80Nk0NVL4FRkwdgIyw9QnLX8t26g1eajYOaPRQ4SVqk6o2PkUqg7c0ajjhJVncxi3BN8uxrm+4JlPLR3zae5TFe/gJy5wSW/S9H1+jeF5bozuUBx/l7xYInpNURALNTeJhIKbGPUb74htantYmANXNdFh4YEmVEzrMQ0QPJJdBenzwrnrazdc/VHEWqZeqEfzmVgOS84XEJICJasLgaszsRrfX4g82PxSvvfj9Hm6OkKHtW+W89xwLlASvzgnmMrdt+m1DCs6mzGL4QNF63D256basThIrYyrrwUQfJZuV4fLMBco4FIxeW+de5pbLIE5ezWS2r4bnpK4zk2Q5rK4ETS4cb+ujtI+fv2KmMk9DUO4Oo5HRAiTg9bFNVmooTmWCIlxFNzEsP8p56GGm9BdOIS+7A+jixN9+lBn76DCMwW/50XDs2+N/os5jHiQ4IaJdadNd5VZkMrr2LKeXOcmgonr6tPk0PgQMvDkkp5NLzWFVwNgqDk+yr1edI9Yqz5yg/e+jS5TGLmStYUzENE/F7GZ3yjUkVG1HrOWQybyiKpo8Dx/wUfFxd85puAmhpUhBYtUbb4prfamadEvcL5NEh4z0bomJXSUnuXVt4bL6eEvEA9y2azHRcZrqoBwTNmgDwOP3Ec4Kh01neXXLv4eX6DOYd6Ost56nyK1xp0HRErb4j6ETwr4WOpfyj3eq2EjaPPOeZ6PYAKdilBe16AdTet5qFA7pAYqawy9vGGj1OTUuU0sva/jgeHBzZw5c5Cfnw+r1YqCggL8+OOPtW7/3nvvoU+fPkhOTkarVq1wyy23oLi4uNZ94tmHstaxeLS4BqmIv4nVGiO5g5ahlok2KNVt9eWuETaWnC8gpe5ybqONrnElg4tIUwUP3O9DSt8ScLknwXxav53a5dlGF8Xa6hPtuKb4zmLtXfvgroWztNCGe5s8zq1nVldL8xXu3SJQSxc+EWiWck7WGqs1N6ThAk3zQhrH0OBmwYIFuP/++/Hoo49i48aNOP/88zFy5EgcPHgw4PY//fQTxo0bh9tuuw2///47Fi5ciF9//RW33+4/uWGi+JV3wx9qayQzG8aIa+reIYEw0T0zuiuJGwAo1XkAAHPWWn2Z4BxqW33kRsgV3WA7Ef7ssKotB1z1v6CYMjY16Di1Jayrr8hPMRElnhdoj6abQOdIrQ42xUIMX+Qj0OcGzuBekOI7sCVA1YHbIZf3QE3hNXVvTBrE0OBm1qxZuO2223D77bejR48emD17NvLy8jB37tyA2//888/o0KEDJk+ejPz8fAwePBh33nkn1q1bF+WSRxPDh86Oxdc1waYpFy5nwXZyCAD/YcIAIDsz3SqVXVF96BZwRyRmymao2PmMno2ThIFns1qdAQCD7eSFES1OuHG9z004k/hp73+lun34jkkMoVR1RvXh8VRzEwGGBTd2ux3r16/H8OHDvZYPHz4cq1evDrjPoEGDcPjwYSxevBiccxw/fhwff/wxRo0aFXB7ALDZbCgrK/P6izefKYPh4CLOEvaiGwtcq9UkOC8U5mar4Nf1TY3dXC+mzF/8ljExTB2L45671qVeAUCczYAuWgoBBH4PhCwRJkwlJMIMC25OnjwJRVGQk+PdkSonJwfHjh0LuM+gQYPw3nvvYezYsTCbzcjNzUVmZib+/e9/B32cmTNnIiMjQ//Ly8sL6/OIhmJkYKmqTbJ2g7jM4NIYyKPGxnNGaACwlwyIdml0cmXnWtdbW33mt0xMDlO+m7jHwF21NwGCG9XezPu+I9PrvlzePVIFCwsmah3JpdTwjXZ0jbzixneZJCRmGf7p8O0NzzkP2pt/27ZtmDx5Mh5//HGsX78e33zzDfbt24eJEycGPf706dNRWlqq/x06FDxdfyx7VxkGALhG/LHJdSx2dQ5WazwCU5+htdzhfRGMBlcTiVqPkQ7+Gjc0WK7oAgCoPjK2UceJCQH6pbien+3ExV6bKhXewUz14QkRLVpM0kfKGZ/jKB7T8pOmwbBPR/PmzSGKol8tTVFRkV9tjsvMmTNx3nnn4aGHHgIAnHnmmUhJScH555+Pp59+Gq1a+Q+NtFgssFhit8mivlapvbBbbYMuwhGMFZdjnnKZ0UWKIu0LlHv0z0jJD15bFzXOi7KUtg22otEBN2HS6cD7BqilMGWtgTX3f5ArO0GwFAJcRPWRm6AG6luhN00Y/vuk8VzDwcVKva+UPmeXzwXcM9eQb61Ok0HNUoTUybBvRrPZjIKCAixZssRr+ZIlSzBo0KCA+1RVVUEQvIssitoHPPETOTHMU0YCAMaL34Z1rppYJ1dqv+KDdbpT5bSAyyNNTDoCABDMJQiW/iq5/WuBd/YJbgRzEay5/wMASCl7IEhVEEzlSM6bX8f+CXCBc+ZtkVJ3OBd4jJrymEATgNcFva7mwFgjWMPTX45RcENInQz92Td16lS88cYbePPNN7F9+3ZMmTIFBw8e1JuZpk+fjnHjxunbjx49Gp9++inmzp2LvXv3YtWqVZg8eTLOOecctG7d2qinETWfK+ehnCehnXAC/dlOo4sTNY4SLZGhWhM4d031wduiWRwdEz0nNA0cbApBZoP26zwrBk7sx4It95hfKN6pNa7PrjNA9Dg33OGTjNEjkaLj1HkRLlnjVR+5Xr8d7L3QYPprT8ENIcEY2mg7duxYFBcXY8aMGSgsLESvXr2wePFitG+vVcMXFhZ65byZMGECysvL8Z///AcPPPAAMjMzcdFFF+H555836ilEVQ0s+EoZgOulH3CtuAJr5R5GFymC3MGCZ/I2xdYCouWE95a+F8Co8ehvwNSG/ZL2Gc4eaHh77fu7fr0b3++isZSqfK0WzPWcPIMbv9FRgse62A/sVFvz8B+Uam4IqZPh34yTJk3CpEmTAq6bP3++37J7770X9957b4RL1XDRmnvjY+UCXC/9gMvEX/CkPB6VSIrK40ad4J47yPMC7hvYaOuNGR6s2ptBTDqs3WFKg8phafEtHCUeNQ8NTs/vDP7i4AJfF+58fV2ToEqp29wr/abe8OzAGvvPnXtltQ5P51t9brUEeO0JiRT6dMSZ9bwr9qitkMJsGJ3AGYu9+lrUlcPGoODGdsKdo6k+NS+eU0J4Zl+u7/7e2yfQr3ef+Zc8p5RQ/LISS7CXDICjtC+4IytKBQwd9+j0zB3h6RumuhJUes5XRgjxQsFN3HFnLL5e/N7gskSO6+Ktyt6TInIl8PxORuCOZrXmaPFVtf+e4Ctr3T9AraAr10lCBDfOmjmfZil7ybkI9BVlO3Ylao6ORXxMoSi4J0UM08zg+mfD3iIsxyMkEVFwE4c+Vc6HjUvoI+zF2WyX0cWJCMFcpP33HS0TpgtEuLgSqqV2mQlmqmsC1+AXY8FaWMt+AZ6zHgzF/0fY1SxlznROo5JItVJwzwMmWI+E54AJ1N+KkEiJ/2/GJqgYGfhcGQwAuF1abHBpIiOp7fsBl8fyBHNJrRfUuU3wTrDBgzYmBkjamEABAPNoXmHS6cRqcvNgzfk6PAfSk/gZf36C5FslxHAU3MQpV86bEcKvyGMJMkN0PchlfWEvHuy+Xx47I8aYyX+WZtdIrqr9fwEA2Iq0181R2sd7X+cs2HJFtwAH9g989DxHMXCBayyluq37DlNpqHMdXP2zONXcEBIUBTdxahfPwwrlTIiM41bxG6OL02Bi8h8Qk/cGWVv7yDO5qqN7y1iaMDNAp2DBpE3UqirOzqTOC7ZgKfLYzw5ztjZZrBqok6zfcVUwSavNSYwAwP01ZG62HObsVX7LE4WYuq3RzVP6e4eCG0KCSrxvjybkdUWbDf06cTnSUVn7xrFEqEFy+ze07L0BAgIxtf4JClVbbjhL1ih+zUeCx31nc5SUpg1zFj362Jib/eixnX89v2/CPzHFYxJG36HS8cjjOZuz1uq33RmLE0dy3tuNnzpEb7ZrfHkISVQU3MSxn9Re2K7mIYXZMEH81uji1BvzzGETKLixHtZvy1Ud/NZzj+kWHKcLwlq2RvH5Je0d7GgXcNHqP3GrKdN9QdeH+XodyLtZiknl7odUwjO82FiBv4ZE69EolyMyHGW9AQBcDVPKAkWrreSyUckrCYl9FNzENYb/yFcBAP4ifYW0RJkt3KOpRakKMGmkR16bmGqW8Q1uAo7sCvSR88jG7Mj0X+2bzdjZAddRdkYDCxijYuk1jADX9BKuflWNI7ubJGOpSZaQGEPBTZxbpJ6LXWobpLIaXCuuMLo4DRYoeZ13wOLfTMNVjyAihi6MfiOhAgQ3XHFfkATLMe2/yaMmJlAzk1ezFIc19wvnfmWhF7YeojUZbbAA1TfHUf2PF8pOIT1U/Q4dtkzCClK7PeFx4Lr73ITraQU7Tn3PdagZ3BN/QuT6o1PRMBTcxD2G/yojAAA3i99BiIvZwj0CFsHut9azup0FyMLKHdmQKzvDUd4T4Mb2ObGfcs9grwQa6eTkyqZbc+wqfZmUvjHAhiIcpX2hOtwzoHv1ufG4LSb5N3GFU7S+S4NPiHpHSMeLtWtA4NHSDS8lM5WCCR7zbimhBX+RxuIiuSIJJJFeOQpuEsBnymCc5inIF47jciEOpmQIcrH2WOhxM3DTTvXB21FzeByM/jjajo+BrWiE855PWZy1Ulqgoq0LdiHXcQk1R8ei8o/pUGqcnaW9zpc7GFRl4/vbhOfsC1Dt7r5GqpyK8u3PRbezeCTfRixQIFN3RuvaqPZMGP3eDyYSuW9qOyajZDuN4nn+gp3LeAxYKbhJAFWw4nVZGzn1oPQRTGjoJIzR5v6y9x0JBADm5ks91oejn0JkufKNmDLXewUfTHI2G3k0H3jOci2YSpHWY5rPsdwfSVfH6+R282Bt8w4E62HvTsoJNHGiZ9OUIFUYWJLoMGWuD2Evz0A/dppjCYlFifPtaDCj20PfVC5FEc9EO+EEbhCXGVuYunjWxvgFN7L3zN9idVSK1Bieo788h3ULzuCGmU67N/YYMWPK2BTgaB4XebN7P1P677C2WgjBclJfZj91HhJGDPWdCjelppXfMmurzxp8HM/AlplONapM4UKVJiRWUXCTIKphxb/kqwEAd0pfxnTtDfP6BeoT3AiKz7axT7Xl6LeZ5JGl2Nkc4T3iS4Bc2RHBBY+StTmK3OfOcWpw0G3jTiIHN5Vdw3IcJrg/064RWISQwCi4SSALlQtxnGeiNTuF68TlRhcnOI+aG7/RUn73G9c3IRo8RziZs9aCieUQU3bpz4X79I2pfTbn2juEu5rxtPw/CfTxTeDgJlwhumfNDQ0DJ6R2CfTtSOwwYY58BQDgL+JXMTxyKnizFPMps2pvHo0CNY5q9bqb2vUZJLd7E6b0TdoCvyG7tbRh1nXRStBJJUndvKcriYc6TUKMQ8FNgvlIuRAlPBXthSJcIoTSaTEKvPrc+ARgPsGO7cTwKBSocZTqdgGXi0naHEK+Exz61uS42IpGQLW7m7gq90z13yjGgpuwdTULS4K7xOadAyl2g5tI9D+s7ZiUC6dxPM9fsHMZap4iI1Fwk2CqYcV7ysUAtKzFsclztFTwZilHeU+/WpHYVMfHyCcQ8eyj48lePNR7uwDp9d0zQkc+uInm5TNgJuoQxeJl3yvxZIi8RhbG37WGkKii4CYB/VceARuXUCDsxsUxWHuTkj9Hv83M3qM+Ag0Nj3++V6L6pnX1D2D0UTbRCG6iORQmjDNcx+IInoB9ZAJk566VV3BTv3mqAp2KUE4PQ+DzWt9jhZonJdB7sKnmtWmiTztkFNwkoBPIxFvKpQC0vDcx/TPPd7oBry/w+Pk0yxVdgq4Tk/d530/Z67eNo+xM/x1ry2MTI81S4SJ4zJKuVLc1sCSRUX3oFr9lYvKehh3EownXnkgj5QiJAApuEtRceQwquBU9hEMYKGwzujjB+dbUeN2Pn+BGqe4QfF1VJ+8FHoFJxZ4HUL79WdQcuSHAnk0nuPEMaGzHLzewJJGh1rRF+fZnYSu6tDFHAQDYTlzs/54ihHih4CZBlSIVnytakrcbxaV1bG0ca+4XMGWt0u8zr6R98RPcNKh2zLMJRrUg+MeQBZ90McCcXPHNHazxuHrdG0IA90ji6JnwsT70Jtt6NklFAzWVkFhFwU0Ce1e5BAAwQliHHMRGRtNArLlf6rf1KQsAyBXdjShOSJSq/KDr5HLv5yFXuJO6cSWp9gMHCW5M6VvrX7g4oHgkNuQe80wlGs/3iZTyR8MyDTuDm2h0Jick3lFwk8B28Hb4Re0OE1Nwm/S10cWpA/f5D8ilfY0pSgiCNRPIFV2gVHXx2bYzbEWXovrwjXX/Cm8iFzKlqhNqjl+G6iPXgyvGTwgaKarNO7Mwa0gNnKvPTQLNKUZIpNCnJMG9Io8GAFwvfo90VBpcGo0qp/ovZArA7JBS/gDg6mAb/2/PmsJrAi63Fw+BXN677gMk5OixQBgcpy6AXNbH6IJEnCqneNxrSGf/2MpxREgsi/+rB6nVcrUPdqltkMaqca243OjiAPDPQqwtlJGUNx+mjM3a/UT5ddrIC5HnfEIkMQiS54+M+gc3LMYSOBISyxLkCkKC4RDwpjISADBB/A5mxEAm2AC1EYwpkDyGSLM4mA28PnyzE4dL5Z4pETkuiTLfDN312JbT1zYhdaJPSRPwuXIeTvAM5AkncK24wujiBP5C90lopsThrMfezQ1OEQhu5IquXtM0kDjWkGZHvc8N1dwQUhcKbpqAGljwH/lKAMBE8UtIMLipI0Bw4zlKCgCYUBOt0oRPoECGLkSkFoLP+752rmYp+tompC70KWkiFihDcJKnI084gTHCaoNLEyi4qfC6L6VviVZhwsZefL5+m6uSMzFd+D9igrk47MckRqE+N4REAgU3TUQNLJgnXwYAuFv6X+BOvVGhgjH/L3T/8sTwlBFBqLZc/XbFrr+hav9dEXmceGyyI25KjUeTYkNmQ9f73FBwQ0hdKLhpQt5WLkEZT0YnoRCXGDahZpCgKiGGPHuka+UWgC5CJBCP4F4wldR7N8F6RLsRQ81STXUSSxL7YudTQiKuEkl4VxkGQKu9MaR2JNjoEJ/gJp4S+LmojqwoPRJdUBJFg5L46TOLx1+tJiHRRsFNE/OGfBlquAl9hL0YLBiQwr+ewU3jJhg0Bndko+rgBFTumxS2Y1buuxdyZUdU7PqbxwNRcBPf3MFJ0LnDAu3l7GvD5Yywl4iQREPBTRNzCulYqFwIAHhaehNW2KJcgsDBDfMLeiKTHybSlMruUGvahe14ak0bVB/8C7gSYJg5iXsNqblxJf/jqjlSxSEkYVBw0wS9IP8ZJ3k6OgjHcb34fVQfWzAFGfqaEH1uooN+ucc31ebuUGzOru/IRY/Phxo7s4ITEqsouGmCypGMf8p/AgDcJ32KDFTUsUf4MDHY/FYKuPNL21Ga+PMLhaLm6DWQKzt6DTmPJM7js29HSMWO4lMNqclVcNewciW53ruF62kFO0593yM8xJLE63swEuhUNAwFN03Ux8oF2KO2QiarxK3RnDE8WA0NU8FVKwDAXnxh9MoTRxyl/Z1NVNGZNTtev0tjvdzc0bzB+3g328b21zYNoIpfiTT6LbY/JSRibDDjBXksAOA28WtkoSGZUkMnJh0MuNyasxjMNQUDJSmLGwnzVRjrT8T5o0DrgBzrhQ2/2q65iXRBNoLn+Qt2KlkcvucouGnCvlX7Y6vaAamsBrdFqfbG0mJp0HWuyTJpYkCS6GwnG1g7SdmJCWkQuoo0aQz/lq8CAIwTlyANVQaXx4m+wEmCk8vPBACojvR67uGaNJO+sgmpD/qkNHHfqQXYrbZBOqvCNOkDo4ujoS9wkuhULdWBNnqwtolsOUwZv0LUsxPHVuBPTUIkVtFVJEzitSc7h4DH5QkAgBulZTiL/WFsgYCY+wInJNy4xwzySXn/DbqdlLYV1tafIKmt9sODmmwJqR/6pBCsUc/AJ4o2vPhR07uI1ngTuaIzHKfPDrCG3pYksXkmZZRSdwfdTp9PSt+RAn9C6oOuIgQA8Lzjz6jhJvQXdmGosCkqj1l96HbUFF7nt5zTFzhJdKEm4qPPBiH1QsENAQAUIQtvK8MBAI9I74MFm707TGrtSEl9bkjCq1+QYmm+3HsBfTYIqRf6pBDdv+WrUMqT0UU4gsuEtRF9LNvxy4Ov5DR3Dmk6bCcvqve2VKtJSP1QcEN05UjGm/JIAMDD0ocwwxH2x+CKFrgoNW3CfmwSXvUZBxOL/ejjZfyO3t9MsTRgr6b5lV3bgA2aoqFxPM9fsFMZ6vQZRmqanxQS1OvKKBTxTLQXinCn+GXYj89E5yzIPD5n/W5K4nWYb7wU2zW7t5i602+dKWsV0npMC7BTw2puAp2KUM4PQ+Oy1Ia6b6D3YJy8vGEXL+/rWEHBDfFSBSuedtwEALhX+gxd2aGwHdtz0syGTP5HSCJigjPQD/A1bM0N8sOC+twQUi/0SSF+vlAHYpnSF2am4DEpjEPDmUeyMu4eLVK+Y0Z4jk9IHJErums3WG1J/LzFWp8bqk0gsYqCGxIAw1PyONi4hAvELRgZrs7Frsn/fIfBUgdi0gRxVetrIyXvB5NKPNfUsldsBTeExCoKbkhAB3kOXlFGAwCmSR/AVGuK+Pqqe34cTtXupIlgQo1+Oynvbf22lPZ7LTuF43NISOKjKwkJ6lV5NE7wDLQXinCX+EWjj8dcNTcBqtZtJ4YBAKr23dvoxyEkPrjbdERroft28t5a9oi/USuEGIGCGxJUFax4xnEjAOBu6XO0Z8cad0DmSgzo/7aznxyG8u3PQbW1atxjEBIneAgjBpWa1hEoCSGJx/DgZs6cOcjPz4fVakVBQQF+/PHHWre32Wx49NFH0b59e1gsFnTq1AlvvvlmlErb9HyunocflV6wMBkzpPmNO5iz5oZSyBMCv8+BmFz3pLViUvhGLxKSyAwNbhYsWID7778fjz76KDZu3Ijzzz8fI0eOxMGDB4Puc91112HZsmWYN28edu7ciQ8++ADdu3ePYqkDi8ckR/XD8Df5Fti5iAvF3zBS+KURx3L1uaHghhClspPX/eT2bwAAVFtO0H3EpMMRLRMhicLQ4GbWrFm47bbbcPvtt6NHjx6YPXs28vLyMHfu3IDbf/PNN1ixYgUWL16MYcOGoUOHDjjnnHMwaNCgKJe8adnPW+ENZRQA4FHTe0hCTR17BMZY3R2KCWk6AjdLuUZREUJCZ9hVxm63Y/369Rg+fLjX8uHDh2P16tUB9/niiy/Qr18/vPDCC2jTpg26du2KBx98ENXV1UEfx2azoayszOuPNNy/5KtxlGejLTuJ28SvQzuIq0Ox8a2hhMQmZkdSmw+NLgUhcc+wq8zJkyehKApycryrYHNycnDsWOCOq3v37sVPP/2ErVu34rPPPsPs2bPx8ccf4+677w76ODNnzkRGRob+l5eXF9bn0VTYYMZzjhsAAH+RFiEbIQSJVHNDSK3MvrOA+5CrOkSlHITEO8OvMr5zh3DOg85po6oqGGN47733cM455+Cyyy7DrFmzMH/+/KC1N9OnT0dpaan+d+gQdcgL1ZfqAPyutkc6q8JfpVB+XVKHYkI8Veye7nVfMJ2qdfvqA3dEsjgN1pj5pgiJJMOCm+bNm0MURb9amqKiIr/aHJdWrVqhTZs2yMjI0Jf16NEDnHMcPhy4o53FYkF6errXHwkNh4AnHOMBAGOl5Rgh/Nqg/ZlU4bxleExNSEzgcobXfVPGpjr2oB8GhNSHYVcZs9mMgoICLFmyxGv5kiVLgnYQPu+883D06FFUVFToy3bt2gVBENC2bduIlpdo1vHueEXWMhfPNL3eoOappNYfA6DhrIQQQiLL0J/QU6dOxRtvvIE333wT27dvx5QpU3Dw4EFMnDgRgNakNG7cOH37G264Ac2aNcMtt9yCbdu2YeXKlXjooYdw6623Iikpyain0eT8Q74W29U8ZLOKEJunCCF1qTk2Bo7TBajcdzfsJeei+tDNRheJkLjR8BSZYTR27FgUFxdjxowZKCwsRK9evbB48WK0b98eAFBYWOiV8yY1NRVLlizBvffei379+qFZs2a47rrr8PTTTxv1FJokByQ85rgVn1iewlhpOT5SLsR63s3oYpEw4zw+czeFVOwYe6qO0j5wlAyCw3nfdiy0gRDhelrBjlPf/F6h5gGL1/dgJNCpaBhDgxsAmDRpEiZNmhRw3fz58/2Wde/e3a8pi0Tfet4NH8pD8GdpOZ4xvYnL7c9ANv7tRMIoXr9L47XcngSPuaYIiZYgY3niUshXo9OnT2Pt2rUoKiqCqqpe6zybkkjiek6+HsPFdeguHMKd4ld4WbnS6CKRKEuY78IYeyKipcjoIoQs2GjXxh0zuo/XlHiev2BnMh5HxYUU3Hz55Ze48cYbUVlZibS0NO+TwxgFN03EaaThacdNmGV+BZOlz/CN2h97eBuji0VIXKk+fCOS2r5ndDEISSghdSh+4IEHcOutt6K8vBynT59GSUmJ/nfqVO15Gkhi+VQ93zmxpgNPSG8jMRoFCCGExLOQgpsjR45g8uTJSE5ODnd5SNxheFS+DTYu4QJxC4YL6+rcQ6mmYfuEuNQ2UWasi8fmCtI0hBTcjBgxAuvW1X0RI03DQZ6D15TLAQCPm96pc2LNmmNjolEsQuKCam/pt8xRelb0C0JIAgmpz82oUaPw0EMPYdu2bejduzdMJpPX+jFjmt7FKxaG6THTSUipO+AoOQ/R7iE5Vx6DK4VVyBNO4AFpIZ6W/XNycFUCE2RwJTWqZSMk1jlO94Upc6N+n3MaeUhIY4T0CbrjDm1+kxkzZvitY4xBUZTGlYqEQEFq5xcBAFLaNlQf/EtUH70KVjwhj8eb5hdxq/gNPlEuwHbe3nsjfeJM+uImxJNnYAMA3EHTxBDSGCE1S6mqGvSPAhuDCDb9ppSy15AifK+eja+UARAYx5Om/4LBM0UAB6NZwQmpk1zZyVn7SggJFV1lSFg9J1+PKm7BucIOTBK/8FjjDno5zQpOSFDVh24BV1KMLgYhcS3k4GbFihUYPXo0OnfujC5dumDMmDH48ccfw1k20gB6rYiTJedLQ8pxmLfADGd/m6nSQvRgB7QVzKNGj4IbQoKjmk1CGi2kT9G7776LYcOGITk5GZMnT8Y999yDpKQkXHzxxXj//ffDXUZSH8y7OdCcvcqgggAfKhdhkXIORMbxnOl1SJB9ghv68iYkOBpeTUhjhdSz85lnnsELL7yAKVOm6Mvuu+8+zJo1C//3f/+HG264IWwFJPXEYquv07OOGzFY2Io+wl7cIn6DNzDEYy3V3CSKGBgkmBBcIwk18R3cRGKyy9oOSZNrNo7n+WvsBKmxJKSf0Hv37sXo0aP9lo8ZMwb79u1rdKFIKNQAy4x7Qx5BCzwr3wgAeFD6CO2FI1qJuIB4//JuKuL1VYrPcsffxQNIrIkWSWIJKbjJy8vDsmXL/JYvW7YMeXl5jS4UaTjfPjeaQMuiZ4EyBN8rZ8HCZEyxvAMgWDlJLIrXCQnjsdhy+RkAAKUmN6zHDXQqQnldGQKf1/oeKdRMxoHKGo+vbzg01ecdqpCapR544AFMnjwZmzZtwqBBg8AYw08//YT58+fjX//6V7jLSOojULMUUw3uvMvwiOM2LBEeRkfhMIDwfnETkihqjl0NpboD5LLeRheFkIQQUnBz1113ITc3F//4xz/w0UcfAQB69OiBBQsW4IorrghrAUk9BQxuFICb/JdH0TE0wzPyjbg6Sau5sdgyUG5oiQiJQaoVjpJBRpeCkIQRcqrYq666CldddVU4y0IaJUBzT4x0Mv5QGYo/0lcCqEEeSlCDKlSAJl0lhBASGTQmN0GwAIEMM7jPjRvDDlWbiiFTteMV0z+RXMfkmoQQQkio6h3cZGdn4+TJkwCArKwsZGdnB/0jBgjWLBUjFGdZLi+3YbD4O14x/RMiYqd8hBBCEke9m6X++c9/Ii0tTb8dryMpEhGTSpHc/g2/5aldnoNc0RXVh25t1PEF6xGk5P8bAMCVJFTsfrTBk19KqX8AAOY4rsZI/j4uELfgQf4Rnpevb1TZCCGEEF/1vkKNHz9evz1hwoRIlCWuGZmlwtxsZdB1UuquRh/fFdgAABOrIabsglLRswFHcJ+dw1YHHqq4Ey+bX8Jd0pdYrZ6BH9UzG11GQgghxCWkPjeiKKKoqMhveXFxMUSRss9GG5NOR/fxmFz3Rl47uLfnnGGROgDz5eEAgGekecik8VOEEELCKKTgJli6a5vNBrPZ3KgCkeCY6SSS82fD0nIxPGtDBMuJRh9bTNkJc7NlEJPqk2G6gU2Sgt192zk0/e/yWBzmzdFOOIF55hdhha1hxySEEEKCaFDHiZdeegmAljXyjTfeQGpqqr5OURSsXLkS3bt3D28JiS6184sAANF6DHJlJyiV3bT7Fv9atIZgUimS272l3y/f/gxc8z8JlmOB9mjQ8QXTaf22amsJAKhEEibYH8Yn5idRIOzGP01zMMlxHzgN4CMkblDXSxKrGhTc/POf/wSg1dy88sorXk1QZrMZHTp0wCuvvBLeEpKAROtRPbhpLCaVei8QHIDqDG7MgWqFGjjKyaNZSi7vpd/+g7fFX+wP4G3zTIwUf8W96ud4Sbm6YccmhBBCfDQouHFNijl06FB8+umnyMrKikihiD9mOuW7JOi2ckU3SKk7Q38s5gCHtZYNnMENswO87mZIVw4exdYCvi2hv/AeeEy+FX83vYappo+xk7fFt+o5oRadEEIICa0N4IcffqDAJoqsbd5DaucXgqz17//kH9jUnsxPtHo3PQlJh/TbzFTit71gOQ4xZRfSuj8OczP/CVT9OYOhIPNcLVSGYJ48EgDwT9Nc9GZ763FMEmnB+tbFupCKHZ9PtU7helrBjlPfc81DLEm8vgcjgU5Fw4Q8/cLhw4fxxRdf4ODBg7Db7V7rZs2a1eiCETdT+hb/hXrtiffIJVvRJbC0XOK/LQ8ex5qyVnndF6QKj4anAJ8oNQnW3M8AAJaWS2AvvriW0kObwBOodRLPZ+Ub0IUdxgXiFrxrfhZ32B/AWt6j9uOSiIrX79J4LXeioBxo8SuRXrmQgptly5ZhzJgxyM/Px86dO9GrVy/s378fnHOcffbZ4S4jCUQPbrxrZeTKrrAgUHBTywSazOdyUFdm4wYPBXcdL3iApUDEJMd9eIu9gP7CLrxlfgHj7X/FOk4d1GNZwnwZJswTMV4kTmVt8RIFU43jdf6CnEsWhx+QkJqlpk+fjgceeABbt26F1WrFJ598gkOHDuHCCy/EtddeG+4yNmmC+XiQNYrP/1rUEawIPh2KpTR3TRHzDXygNXsJZv/mqmBM6b85b9XePFaBZNxkfwQrld5IYTbMM7+ITuxIvR+HEEIIAUIMbrZv365nLJYkCdXV1UhNTcWMGTPw/PPPh7WATZ219UcBl3OH1ufJd8JM1eE/t1ddE2jKPqOupBR3nxceoClJ9OiTUx+mjE3O/eoOVGww4w7HA1ivdkEGq8IC8//hbNb4LMuEEEKajpCCm5SUFNhsWtK11q1bY8+ePfo61+SaJDyCBQRcdY5m8ghuKvdMBZQUOMp9pkaoo+ZGqc5rVBnDzQYz/mKfiq1qBzRnZVhg/j8ME9YbXSxCCCFxIqTgZsCAAVi1SuuEOmrUKDzwwAN45plncOutt2LAgAFhLSAJxlkb4wxcuGqGam/pXOXTv6aO4CZQzY6YshtMKvWrGWoowRxagsFiZOA6++P4RukPE1MwxzQbQ4SNjSoLISS8qLsLiVUhBTezZs3CueeeCwB48skncckll2DBggVo37495s2bF9YCkiBcHYn1kUjul1K1N/feVKyq41j+AUxyu3lI7TKz4Z2HfaR0Cn3kXBWsuNsxGV8pA2BmCl41zcZgIcDIMUIIIcRDg0dLKYqCQ4cO4cwztZmck5OTMWfOnLAXLN5EOx8DcwY1rpoVz74x9uILYUrfDMHiaiKso2yslj45HutUW3OPY0aHAhH3OyZBgoJLxV/xhulF3OJ4GGvUM6JaDkIIIfGjwTU3oihixIgROH36dASK09Q0LCCqOnC7R38a574sQII8bkbl3geh2rQaHFZb8OJ5jECrnDU39uLBqDl2VZCtIhvYyZBwr+NeLFX6wsocmGd6Ef3Zjog+JiGEkPgVUrNU7969sXcvZZFtDCl9M1K7PgUx+Y8G7MXdQQxTAShIyf+3c5X/S6lPQllnv5ngwY+52UrnLSFoIsDUrk9BylgXuLxh4oCESY77sVzpg2Rmw1vmF2gUFSGEkIBCCm6eeeYZPPjgg/jqq69QWFiIsrIyrz9St6Q2H4CJNUjKm1/vfZSqfIC7evCpELymTQiQ/dcVjNRRc+Oe+6ll0G0EcxEES6BJNKE9j9YfB1jRuM7Ivuww4U7HFPyknIFUVoP55ufRhzUkOCSEENIUhBTcXHrppdi8eTPGjBmDtm3bIisrC1lZWcjMzKQ5pxoqQJK84CToLxlT664Y0Zuq6so4rAU/su8Qcg+KLSdgzpvajxve4AbQhonf7ngQP6s9kM6q8a55JgYI28L+OIQQQuJXSNMv/PDDD+EuR5PV4KHWzpoba84ir8WCuTjAxkI9HkOGOXu189gSOGcBsxIDrNa5oQCASaXgcgYg2GBp8S2475D0MKmBBbfaH8IbphcxSNyG/5qex52O+7Fc7RuRxyOEEBJfQgpuLrzwwnCXg9STlLa93ttyr/45QY6nT40AZzOWgMA1PQxKTZtaHy+pzXuoOjAJluZL3AGTB8fp8AUfVbDiFsfD+A9ewiXiBrxh+gemyXfgY4Xem4QQ0tSFFNysXLmy1vUXXHBBSIUhvtw1KJX77gag9W+p/+5197kRzKc8the1fYLU9HB7i1ofTkw+qB0zQN8cW9ElsJ8K7/vCBjPuctyP5/EarhF/wgvSa3BwEf9TB4f1cQghhMSXkIKbIUOG+C3znFlUUcLf1yKRMVMxuKNZgDXu8+ibmK9e9GakWjoUezQ1aaOrgnXk8U5FyrnYoCY1e/HF9d62IWRIeMBxFyp4EsZLSzDLNBeyQ8IilTJlN1Z9ks9GN7tT/VDS3OgJNFt0JN4TtaURi3aOsUTjdf6CnEsek5/02oXUobikpMTrr6ioCN988w369++P7777LtxlTHipnf8eeIVn8NDQzrwAUI+h4Jx7xrcqmBAkI7HPe1utZWRV9DE8KY/Hh/IQiIzjX6b/4FpxOWLz0hs/WJzm1o/TYkdEuE4FC3Ks+p7rQEFQvfYL8AChHive0fu6YUKqucnIyPBbdskll8BisWDKlClYv54mOQyLRgY3nLs6FAevueFKsvvhBHtthQEAVO6/C+bsVbCfGFbL1Ap1JA2MAA4B0+XbYWIKrhF/xN9Nr6GA7cKj8m1QAg2TJ4QQkrBCqrkJpkWLFti5c2c4D9mkeTf71P5SubIRe9E7FNeWgdhjXT2GpavV7VFz5AaojlqG/EdgCHh9cAh4yHEn/u64Dgpn+LO0HHNNs2FBbUEbIYSQRBNSzc1vv/3mdZ9zjsLCQjz33HPo06dPWArW1KT1mAZb0QjYi4e6FzprUrgqos4K5kC1M3pG4VqCDa9ApLbgxufxg2QrTmr3GqQU47JXqxDwsnIldvI8vGx6CcPF9VjInsJd9vtxBLV3iCaEEJIYQgpuzjrrLDDG/DpyDRgwAG+++WZYCtYUWVp+6xXcuJqJmOAOQGqOXQ5r7ld++wae96nuoeDegU/w7Ryn+/ksCRzcGBnYeFqqFmC846+YY5qNM4V9+MryKB503IllaoHRRSOEEBJhIQU3+/bt87ovCAJatGgBq9UalkI1Bao9C4K5pPaNnLUqqiNNX+Q43d8vuCnfMQPgZv/969HnxrNZKlDyvvLtMwHmCHD8+vduq9wzpd7bhtPPak9cbnsWc82z0UfYi9dMszBLvhZzlDHuebcIIYQknAYHN6qqYtmyZfj000+xf/9+MMaQn5+PP/3pT7j55pvjdoRFYzV0XE6dgQ3gMeO3Z6bfQHNIBQhs4JHEr5ZmKcFa6HHPOwjSOiSzoMePB0fRHNfan8BT0nxcL/2Ah0wf4WxhN+533I1yJNd9AEIIIXGnQT9fOecYM2YMbr/9dhw5cgS9e/fGGWecgQMHDmDChAm46qpATSPEX/1GEzFnUOI1p5NPXxfH6VqaWeqRxI9J7olOleoO3scuObde5awLV1LCcpxQ2WHCdPl2POT4C2xcwsXiRrxpfgFpqDK0XIQQQiKjQcHN/PnzsXLlSixbtgwbN27EBx98gA8//BCbN2/G0qVL8f333+Ptt9+OVFkTB3PUcztnUOIV0Lhvq3Iaaoouq+UA9ZgV3JnnRqlpBbm8Jyr33avdr2oH2/HL61fOOnAlNSzHaRyGhcoQjLU/jjKejP7CLnxmfhxd2GGjC0YIISTMGhTcfPDBB3jkkUcwdOhQv3UXXXQRpk2bhvfeey9shUtUTKhvcONqTgqcp6Xm6DVAbbUizhofVkswxaQKAIC9+EIAAtSaNijf/hyqDkwK+rjxbBPvjD/bH8MxnoXOwlF8ZX4Ek8TPIdY1czohhJC40aDg5rfffsOll14adP3IkSOxefPmRhcq0TGxEgDAeV3Du119boIEGbz2WbddSfzE1GC5hzhE61Hn7egn3jPKNt4Bo23PYKnSFxYm42HTR3jf/AxaoB79oAghhMS8BgU3p06dQk5OTtD1OTk5KCmhC0SdXEO860ia5xrJxH362dhOXAJHaR8oVfn1ejgeNOGeO6ARTKX1OlZDOUrPjMhxG+sEMnG740FMsd+Fcp6Ec4UdWGyZjjHCKtC0DZp4nbMnpGLH51OtU7ieVmOPE+rcRIHeg/E4z1E4xOnH0TANCm4URYEkBR9gJYoiZDnI3ERE58pfo9Q1P5Pe58a75sZ+8mLUHL0edWctbu08TpDXxGO5bwBVH9VHrtdvO8p6+a23nbgINUdvaPBxo4fhM/V8jLE/jR1qHlqwMrxkfhkvm/6FdFQaXTjDxet3abyWO1E0zfGyCSKBRjs3aCg45xwTJkyAxWIJuN5mszW4AHPmzMHf//53FBYW4owzzsDs2bNx/vnn17nfqlWrcOGFF6JXr17YtGlTgx83GsTkvbC2XgAmVkOpzgOgovrwzRDMJ7QNVP8h1lLGOjChxjuXTUiTZsKjz03g/iTefX8al/dFMJ8K8Pi1N5vFin28FcbYn8ZfxK8wWfoUo8S1OEfYgbvt92Et72F08WJawnwVJswTMV4kro+1HbOpph8JF8/zF+xMxuNkpQ0KbsaPH1/nNuPGjav38RYsWID7778fc+bMwXnnnYdXX30VI0eOxLZt29CuXbug+5WWlmLcuHG4+OKLcfz48Xo/XrQlt39Nvy2l7AEAmJutAJczAcAd5HhIav2x3zJXp9+G4qrz5Q1Sc8NE91BoufyMkB7Dxd13Jz7ZYcJ/lKuwWj0DL5heQ2fhKD6y/B8WyhfgOfl6FMN/slhCCCGxqUHBzVtvvRXWB581axZuu+023H777QCA2bNn49tvv8XcuXMxc+bMoPvdeeeduOGGGyCKIj7//POwlinSmFgDLms1KXJlN5jSf6tjDwSdx6nu/WoPbjyHpHNHdgjHr2uD+Iv2N/CuGGN/Go9Lb+PP0nJcK63EEHETJjvuxRq1cQEgIYSQ6DAsB73dbsf69esxfPhwr+XDhw/H6tWrg+731ltvYc+ePXjiiSciXcTIcTUTqfWNLRsX3IjW47C09J+PiglaM6Jqbxba8eMvdqmXKlgxTf4LrrI9pffFedf0LP4qfUAzjBNCSBwwLLg5efIkFEXxG32Vk5ODY8eOBdxn9+7dei6d2jo2e7LZbCgrK/P6MxQX9Lme6ju/kWANMdGcR/I+c7OfvLIRAwAzOe8H6ZNTF9Vee22PaovvWbg38i640j4DH8kXQmQcd0lf4jPzE+jJ9htdNEIIIbUwfPZA385gnPOAHcQURcENN9yAp556Cl27dq338WfOnImMjAz9Ly8vr9FlbgzV3swrf03V/juh1AQfXt8YXPHu+M1En747+vQMoY1wU2vyUHP0GlQduAM1x0d5PK4VNceugFzRM6TjxpIaWPCwfCf+Yp+CUzwVPYUD+Mz8OO4Qv4IEGhlICCGxyLDgpnnz5hBF0a+WpqioKGAunfLycqxbtw733HMPJEmCJEmYMWMGNm/eDEmS8P333wd8nOnTp6O0tFT/O3ToUESeT70x1Su4UarzUbWv9lmzg+epqQP3qd3ynYbBNet4TavQjg/AUdofSlUncEemvqzq4O1wlAxEIrVbfaf2x3Db37FEORsWJuNR0/v4zPw42rIio4tGCCHEh2HBjdlsRkFBAZYsWeK1fMmSJRg0aJDf9unp6diyZQs2bdqk/02cOBHdunXDpk2bcO65gSd5tFgsSE9P9/ozkiljo3todr2HeIcWJHDf4/s2P7lqbEIdau71WB6BVKgdoGPcSWTgDscDeMjxF5zmKegt7Mci8yO4WFhvdNEIIYR4aNBoqXCbOnUqbr75ZvTr1w8DBw7Ea6+9hoMHD2LixIkAtFqXI0eO4O2334YgCOjVyztRXMuWLWG1Wv2WGyFQ9kjVkQbBVO69nZwOBJjtW7U3g2AuDnLwEIMbh09HYSXJ6647A3Ljgxul2j1035WkMDFpE3D+pPTGHPO/0Ff4A6+bZmGW/CfMUa6AanxLLyGENHmGfhOPHTsWs2fPxowZM3DWWWdh5cqVWLx4Mdq3bw8AKCwsxMGDB40sYqOottwAS5WAs33LlR2DHoeH3LzDIFd18LgbuFkqHDU3tU7gmYAK0QzX2R/H+/JFEBjHg6aFeN/8DFohSIBKCCEkagz/mTlp0iTs378fNpsN69evxwUXXKCvmz9/PpYvXx503yeffDJmsxMDCBg0SKl/QEze77znub62ACP0viuC5FFz5NNxWHQmFmQRmlcq0Tkg4RH5Nky1T0Qlt2CAsB2LLNNxLttudNEIIaRJMzy4SWRcDTxNhWgtdG7gDmgcp88OehzHqcEhl8Grqcunz40pbRsAQEo+EPLxA1Hs8T0EvGEYPlUvwCj7s9iidkA2q8AH5qcxWfwUIkIbYk8IIaRxKLiJJN/RSr6rPZql1JrA001U7psEx+n+YSkOi/DFtmLXY6jY/dcm10QFAPt5K1xrfwKfKOdDYBxTTR/jHdNMtMBpo4tGCCFNDgU3EVTnTNs+61Vbc79NtKAnPEOqk9q/ATizEgvm8A9h5koquBzisPUEUAMLHnBMxAPOZqpB4jYstkzDIGGr0UUjhJAmhYKbiKo9KJFSd3ndFywnI1kYMKYitcv/AQBSOs2K6GM1XQyfqBdgjP1pbHdO3fC++Vk8Kc2HFTajC0cIIU0CBTcRVXtwIybvrXV99eGbGl2Cit3TvEsk+GfVdZzu2+jHId728Da42v4U3pGHAQAmSN/hS/NjKGA7DS4ZIeETKJs8IbGAghsj1TEEWy5vfP4eLmfWuY1ia93oxyH+qmHF3+RbMd7+V5zg6egiHMFH5hl40fQKUlBtdPHCos6J4UmTEyjnVySPySPxgE2I5/kLdiZ5HH7SKbgxEFfNRhdBo5qMLkFCW6H2wTDbi/hUGQyRcfxJXImF5hlox44bXbRaxetv8ngtNyEkfCi4iSgt2rWfGgjVnum31nb8Cq/7cmV+5EsUoJOzo6xPxB+3qStFKqY6JuE6299QzNPQUziAr83TcL/0MSyIzYzO8drkEKfFjohwnQqGwO+H+h6fhViSwI/ZNF9gel83DAU3UcCVVFTu+avfctXuPT2Co8R/Tq1wcJT30G8rlZ38NwiSj4eE31reA6Nsz+IXtTtSmA33S59iqfkhDBR+N7pohBCSMCi4iQYO1Oc3TjjmeAqEebaXMg7AZxoGehtE1TE0w5/tj+Fu+2Qc4c2QJ5zAe6Zn8bj0NtJRaXTxCCEk7tFVzUCqI8PrvmAq0W/zECfLDMRR2s/jngLJmZmYGIdDwCJ1AEbYnscH8lAIjONW6Rsst0zBOPFbym5MCCGNQMFNuDSwM3nVoQmAmux9CNWq367c/WgYCqWRy3tBrugKQJsJnIlUOxArKpCM6fIdGG//K/5QWyObVWCG6b/40Px/6MwOG108QgiJSxTcGECuzIdS0b3WbbiSGtbHtJ/S+vMIlmN+mZGJ8VaofXCp/Tk85rgF5TwJ/YVd+Mr8KO6XPqbkf4QQ0kB0lTOA6mgWcDmXIzgnE9P62TDRHocZC5oGGRLeVS7BSPtzWKn0hpU5cL/0Kf5n/hvOZrvqPgAhUUYjeEisouAmiqr23wn76X6wHb8s4HqlshvsxYNRfWRs2B+bMc/MxPSNFMsO8xYY55iGe+z34gRPRzfhMD61PIlZpjnU4ZgQQuqBgpuo0IIJpToftsI/+fW18dzOVnQ55LJITIfgfqmZEJt5VYgnhq/UgRhjewYfykMgcwFXiz9hsWU6xgirEI3cwPGa+TWkYsfnU61TuJ5W0My19XyAUDPcBnoPxmO23HCI04+jYSi4aYKsuV8YXQRST4VohmnyXzDW/jccVFugLTuJl8wv40Pz0xgibILgN6w/fOL1uzRey50oqKkqfiXSS0fBTRMhV3YOuNxRemaUS0JCsZ53w6X25/EPx59g4xIGCNsx3/wCFpmn4yrhR0jwnxA1GhLmyzBhnojxIpFBuLaAKV4zaccKz/MX7FTGY1ZoCm6aCo9h5i5yRRfUHL3egMKQUFTBin8rV2OI7Z94Sx6BMp6EHsIh/NM8Fyst9+N2cVHMTuVACCHRRMFNRMV4BbngAP1kjT+FaIan5PEYbPsXXnCMRRHPRGt2Co+Z3sMKyxTcK36KdFQYXUxCCDEMBTdNmJS83+gikEYoQyrmKFdgsO1feNhxBw7z5shlJXjA9DFWWqbgYelDNEep0cUkhJCoo+AmKqh2hESOHSZ8pAzFxbYXcZ99EnaoechklZgkfYHllimYIb2FfmwHYr4mkRBCwkQyugCEkPCwwYz/qYPxlX0ghgnrMUn6An2EvRgnLcE4aQl2q23wunIZPlXOh0wffUJIAqOamyZMsbUwuggkAhSI+FY9B1fY/w/j7X/FQvkCVHMzughH8ILpday2TMYD0kfIZ4VGF5XEORqoRGIVBTdNiO3EMK/7NYV/MqgkJDoYVqh98JA8EefY5uD/HDeiiGeiJTuNe6XP8YPlAXxsfhJjxR+QjBqjC0sIIWFDddORxGKrj4P95DDYTw6re0OScMqRjHnKKLytjMBwYR2uFVdgsLAF/YRd6CfswuPS21imno0vlYFYofaBHSaji0wIISGj4CZMmmpKcBJfHJCwSB2AReoAtEAJrhZ/wljxB3QUjmGMuAZjxDUo48n4Tu2HqrIrIKEF9c8hhMQd+tYipIk6gSy8qozGq8rlOJPtxWhxDUaJP6M1O4U/iSuBPStxuSUVi5QBWKyeCygjAJG+MgghsY++qQhp8hh+453wm9wJz8o3oIDtwmhxDa6xrkO2XIKbpaW4GUuBF+cAXUcC3UcBnS4CzMEmgCWEEGNRcEMI0XEIWMe7Y53cHft6PYY9a7/GaGENhonrkV1dAmx+X/uTkoDOF+MSRyd8iDNQilSji04IIToKbgghAalMwo/qmfhRPROirGDPxGxgxyJg+1dA6UFgx1eYDuAhi4Bf1B74Vu0HlPYBMtoaXXRCSBNHwQ0hpE4KRKDDYO1vxLPAsd+AHYuw58cP0Uk9gPPE33Ge+Dvwz/8CrftqTVfdRwMtuhlddEJIE0TBDSGkYRgDWvUBWvXBHesHQS7ei+HCOgwX1+EcYRdwdKP29/3TQHYnTJN64julABt5Z3BKrZVQKIcfiVUU3EQFfQWQxHWQ5+ANZRTeUEZh/2P9gZ1fAzu+AvYuB07twURpDyZKX+I4z8QSpQDfqf3wi9oDNpiNLjohJEFRcEMICZ/UlkDBeO3PVg7sXoL/LXgdQ4WNyGGncZO0DDdhGaq5GYvUAZgrj8Ye3sboUhNCEgwFN4SQyLCkAb2uxn3vWmCGAwOEbRghrMNF4ka0cubSuVL4CZ8oF+A95WL8xjsZXWJCSIKg4IYQElB9GlPrm5fbDhNWqn2wUu0DyBxns924S/oSl4jrMVZajrHScixV+uLv8ljs5O0aU2xqBDZYJLK181oOyWtbSerkef6Cncp4zMBPvfsiiMXhG4IQFxaxKZ8ZNvCuuMPxAK61PY5PlcGQuYBh4kZ8a5mGOabZ6M32hn50im504ToVLMix6vseYSGWJNDxQz1WvKP3dcNQcEMIMcyvvDumOiZhhP15LFLOAQBcJq7Fl5bH8KppFtqyEwaXkBASjyi4IYQYbg9vg7sd92OE7Tm9JmeEuA5LzA/hCem/aIVio4tICIkjFNwQQmLGTt4OUx2TMNL+HNYoPZHE7LhF+hbLLA/ifuljpKDa6CISQuIABTdhQn3aCAmf3bwtrnc8ipvt07BW7YZkZsP90qdYZnkQN4jLYIHd6CISQmIYBTeEkBjF8KN6Jq6zP45J9snYr+Ygl5XgWdM8rLJMxj3iZ8jBKaML2aRRJ1cSqyi4IYQEFDtDbBkWqwMwwv48nnLcjMO8OZqzMjxoWohVlsl4xfRP9GW79a1DKnasPNUwC9fTCnac+p7rUIcSB3oPxuOw5HCImY9jnKA8N4SQgGLtu9QGM95SRuJtZTguF9bgRmkZzhF24lLxV1wq/opNakcsUIZit3qJ0UUlJC4lUk0cBTfRwBPoHUOIByPe2QpE/E8djP/ZB6MLO4w7xEW4QlyFs4S9OEvYC0fpf4EPhgNnXA10HQ5YM+o+KH1EwyYSeWhqu+hGLh9T0+B5/oK9dvGYW4iCG0JI3NrN2+Jh+U48L/8ZV4s/4k/iSnQTDgM7F2t/ggnoOARjxQ5YohTgFNKNLjIhJAoouCGExL1iZOB15XK8rozCyJYlmHvWAeD3z4Hi3cAfS/C8CXhaehNL1AJ8r/bFV8oA1MBidLEJIRFCwQ0hJIEw7Bc7ABfdDFz0GHBiJ7DtC2xd9i56CftxmbgWl4lrMV16H4uUAfhaPQc/qz2MLjQhJMwouImoWOuSSUgT06IbcOFDuPzrnujJ9uNScS2uElYhTziBcdISjMMS7FNzIG24DEOE5vhZ7Uk1OoQkAApuCCFNwjbeAdvkDvgXrsEFwm+4VPgVI8VfkC8cB3a+hflmoIJb8aUyEIvUAfhZ7QGZviIJiUv0yY0Cqr8hJHYoEPGD2hc/qH0xQ74ZQ4TNeKTHcfA/lqEtO4nrpR9wPX5AGU/GCvVMLFXOxnL1LJQi1eiiE0LqiYIbQkiTVYkkLFIH4E/n9Mctv4/BQGEbRgtrMEL8Fc1YOUaLP2O0+DNkLmCN2hNfq+dipdobh3kL0PjxxMqLQhILBTeEEAIAYFijnoE16hl4TL4VZ7E/MEzcgIuEjeguHML54lacL24FAJzgGVij9sRq9QysVs/AQd4SFOwQEjsouCGEEB8qBGzgXbFB7ooX8Ge0Z8cwUliLS8W16MkOoAUrxRhxDcaIawAAh3lzrFa0QGeN2hPHkW3wMyCkaaPgJkyoXw0hiesAz8Uryhi8ooyBGQ6cxf7AIPF3DBS2oS/bjbbsJK6TVuA6rAAA7FFb4Se1F75SBmI97wqVpvEjJKoM/8TNmTMH+fn5sFqtKCgowI8//hh0208//RSXXHIJWrRogfT0dAwcOBDffvttFEtLCGnq7DBhLe+B2fKfMNb+OPrYXsfN9mmYK4/GZrUjFM7QSSjEeGkJFlpm4GfLPfib9A56sb2gn0GERIehNTcLFizA/fffjzlz5uC8887Dq6++ipEjR2Lbtm1o166d3/YrV67EJZdcgmeffRaZmZl46623MHr0aPzyyy/o27evAc+gvqgtnpBEVQ0rflTPxI/qmQCAdFRgoLAdl4jrMVz4FS3ZadwmfY3bpK9xhDfDUuVsvK9cjJ3c/zuOEBIehgY3s2bNwm233Ybbb78dADB79mx8++23mDt3LmbOnOm3/ezZs73uP/vss/jf//6HL7/8MsaDG0JIU1GGVHyr9se3an+YcDsuFDbjSvEnXCRsQhtWjPHSEoyXlmCT2glvyJdhiVoAG8xGF5uQhGJYcGO327F+/XpMmzbNa/nw4cOxevXqeh1DVVWUl5cjO5s67xFCYo8DEpaqBViqFsACOwYLW3C1+CNGCOtwlrAH/zH/GyU8FR8pF+IN+TKcQJbRRSYkIRgW3Jw8eRKKoiAnJ8dreU5ODo4dO1avY/zjH/9AZWUlrrvuuqDb2Gw22Gw2/X5ZWVloBSaEkEawwYxlagGWqQVohlKMk5bgT+IKtGHFuFNahAnid/hKHYDPlMH4Re0BB433ICRkhncoZj5ZoDjnfssC+eCDD/Dkk09iwYIFaNmyZdDtZs6ciYyMDP0vLy+v0WWuP+o8SAjxV4wM/FP+E863/Qu32h/EOrUrLMyBa8Qf8a55Jn6xTMI06QM0R6nRRa0V9SYkscqw4KZ58+YQRdGvlqaoqMivNsfXggULcNttt+Gjjz7CsGHDat12+vTpKC0t1f8OHTrU6LITQkg4qBDwvXo2/mR/AlfZnsL78lCc4BnIZhWYKH2JNZZ78LZpJq4Vl8MKW53HI4RoDAtuzGYzCgoKsGTJEq/lS5YswaBBg4Lu98EHH2DChAl4//33MWrUqDofx2KxID093euPEEJiC8NG3gWPyHdggO0/uN3+ADaqnWFiCi4Qt+DvptewznIX/m16CUOFjTDDYXSBCYlphjbqTp06FTfffDP69euHgQMH4rXXXsPBgwcxceJEAFqty5EjR/D2228D0AKbcePG4V//+hcGDBig1/okJSUhIyPDsOdBCCHhokDUOiHbC5DPCjFS+AVjxeVoLxTpc13ZuITtvD3wzSqgzdlAuwFARluji05IzDA0uBk7diyKi4sxY8YMFBYWolevXli8eDHat28PACgsLMTBgwf17V999VXIsoy7774bd999t758/PjxmD9/frSLTwghEbWPt8Ic5UrMVcagD9uL0eIajBFXowUrxVlsD/Dzy+6N09sCrc8C2vZDbyZhO+XRIU2Y4d3xJ02ahEmTJgVc5xuwLF++PPIFIoTUG3WZjw4OAZt4Z2ySO+P/5JvQjhXhLPYHXhpUAxzdCBRuAsoOa387vsKXFqCSW7CntBvw3YVAq7OA1n2BrHxAiGxvBB6BdwWv5ZC8tpWkTp7nL9hrF4nXNNIMD24SGg0lIHEsXt++8Vru+mM4yHNwkOfgpcud/Q5ryoBjv2mBzoHVKN2xHBmsCmc6fgNW/+be1ZIOtOqDv0qZ+F3tgPVqVxTSJJ/EKZHiRApuCCEB1SclQyyK02I3jjUd6DBY+xt0L86a9iW6s0MY1awQ93Sv1Gp2jm0FbGXA/h9xl8c3fzFPA97pj4elVOxU22Ib74C9vBUUiPo2DEHOaz1PNgsx5Az0Hgz1WPGuSb6vG4GCm6igdyUhJHo4BGzn7WG2nol7Lh+sLVQcwIkdwJH1ePezL3CWsAfd2CE0Y+XAnu8xyeNqUMkt+E3thK28A7ao+XAoZyfWz3qS8Ci4CRNq9yWExDTRBOT2BnJ747GFLQAAFtjRlR3Gl9ek4P3Pv0RX4TB6sANIYTYMFLdhILZp+xYD/B/T8LqpHTaqnfGz2gObeGcDnwwhtaPghhASULwG7CEVOz6fap3qelo2mLGFdwT6jcIjH2vJUxlUdGOH0VvYizPYfvQR9qKXsB+myhO4RDyBS8T1AIBynoSqX7oDpwdpo7RyegHNuwQpR2gnONB7MB47t4ZDnH4cDUPBDSEkoHj9Lo3XcscKDgE7eDvsUNphoXPZOXnJWDA6GU+/+jbOFnZhsLAVGawKaSUbgZ83uncWLRic1hlPSG2xVu2OdWo3nECmEU+DhCCR+vVQcBNR9DVLElvCfBcmzBOJDAczA3nnYJ5yEvOUyyBCQWd2BI/3k3Ge9YA2Uuv474C9Apmnf8ct0u+4Bd8CAIp4JkzLegN7zwZangE06wRkdwSS6z9Kq7aLbrx2fI8VnucvWGfteOzETcENIYSQBlEgYidvh71teuG8AVrSVagqcHo/Nqz5HpvXfIfBwlZ0YkfRkp0Gjv6o/XlKygKyO2nBTrPOQHZH9GKF2M9zUYHkqD8nklgouCGEENJ4ggBkd0RhXhKe+rEVACAZNejGDuHFCwR0UvYDJ3YCp/YA5YVAdQlwZJ325/SVRft/gqdjH2+F3egIrC+E2doBGahAKVINeGIkHlFwQwghJCKqYMVG3gXHu56LTp2au1fYK4FTe4HiPVqwU7wXOLUHJw78jhasTP87BzuBL79GSwCbrcBh3hzmhf2AVr1xuVCDHTwPNt7RsOdHYhcFN4QQQqLLnKIPS/fUf9oipKIKHdgxdGZHUWDej5s72SAf3w6p4ijaspPA7m+A3d/gP2ZtH5vNDLzaE2jRHWjRFcjpDeT2AtJaJVYPWdIgFNwQQgiJGRVIxlbeEVt5R3yPIbj55hE4VlKFkc8vQk92AO9cngRz8U5sWLcK3dghpDCbloG5cJP3gcxpWrCT2xto1QfIPRNo2RMwU3+epoCCG0IIITGvHMn4hfeA3H8EzGYJV69eBAEq+qeXYsGV6Vp/nhM7gGNbgOLdgL0cOLJe+9MxIDsfaNEDyOkJ5Jyh5efJ7ggIYtDHJvGHghtCCCFxSYWAw0JroOdF3itkG3BqH1C0DSjcrA1VP7YFqDyh9fU5tRfYuci9vWjREhDm9NKatJp300ZxZbYHRLpMxiN61aKBU7svIYREjWQBWnbX/npd7V5eUaQFPEU7gONbtdw8J3YAjirn/a3Ab57HSXIOU8935+dp1gVo2QNIyoz2syINQMENIYSQpiG1pfbXcYh7maoCpw8ARdvdAU7xHq12x1EFHN+i/flKawU076r9teyudWRu2R2wZkTt6ZDgKLghhBDSdAmCVjOTnQ90v8y9XFWdTVh7vIetn9gFlB3WcvWUFwL7VngfL72NVsuT1QHI6oBRwmkc5C1xkLekPD1RRMENIYQQ4ksQgOadtT9fNaVakHNyp9aRuWgbcHwbUH4UKDui/e1bCQB42ezerZQn64HOQZ6j3z7AcwBFpv49YURnMkwCzyJFc0sRQkjCsWYAef21P0/Vp7Vgp2QfULIfOLUPv27agHasCDnsNDJYFXqz/eiN/f7HfPoBIDMPyMrXan0y84C01kBaLpDeGibZBu2aQn0464OCG0IIISQckjKBdudqf07XrtVGZVlhQx47gXbsONqzIuSxIrRnx9GOFSGPnYAFDi0gKtkf8NA3A7jaYsExng3Mn6v1+XEGPkjLdQdCaa0AyRzwGE0JBTeEEEJIhNXAgt28LXbztn7rGFTsm362O7gp2QeUHtGaucqPAWWFgK0UKcyGTqwQ2F9Y+4MlN9OCnNQcLeDx/Z+WC6TmAiZrRJ5rLKDghhBCCDEQhwBktNH+OpwXcJu3V2zDm9+sRg5OY8H17d0dmssLteCnvFALhBQbUFWs/R3fWvsDWzPQJqkl3jOZUYRMdNvRBVC6uAMgV+1QHKLghhBCCIlxspiE/bwV9qMVcOaowBtxDlSdAiqOOYOd487brv/Ov4rjgFwD1JTCXFOK81zJmfetAvb5H/YhMQ3XmrNwmDfHYd4CR3hzHHHe3sNbowqxVwNEwQ0hhBCSCBgDUpppfzlnBN+Oc23EV8VxFB7Zj+c/Wo6WrARXd5HQPbVKC4ZctUKOKiQp5eghlKMHDvodSuUMR9EMh3kLHOYtcEBtiX28FTbxTtrjGDR5KQU3hBBCSFPCmNb5OSkTNawtPldlAECHHr3R/dx27u04B2zlmPPFj1i7aRPasJNef+3ZcbRgpWiLk9qM7dgOOGuBbNwEKDdo2aINQMFNVNDQPUIIIXGGMcCajpNJ+ViuBt4kG2XoyI6iNSvWR351Ew6imlsx0KDABqDghhBCCCEhOoV0nOLpfmndGNRA3XeiRjDwsQkhhBCSgLjB4QUFN4QQQghJKBTcEEIIISShUHATUTS3FIlf9ekGH4vvcOq+bywegXcFr+WQvLaVpE6e5y/YaxeJ1zTSKLghhATEDMpP0VhxWuyICNepYAj8fqjv8VmIJQn8mE3zBY7G+zqR4kQKbsIkkd4UhADx+4s4pGLH51OtU7ieVrDj1Pf4of7yD/QejMdahHCI04+jYSi4IYQEFK/fpfFabkKMlki1nhTcEEJCljDfhQnzRIwXiWaj2i668dp8Gis8z1+w1y4emwIpuCGEEEJIQqHgJpLiL9glhBBC4h4FN1FBUQ4hhBASLRTcEEIIISShUHBDCCGEkIRCwQ0hhBBCEgoFN4QQQghJKBTcRBSlEyOEEEKijYKbqKDRUoQQQki0UHBDCCGEkIRCwQ0hhBBCEgoFN4QQQghJKBTchAmnzsOEEEJITKDghhBCCCEJhYIbQgghhCQUCm4IIYQQklAouCGEEEJIQqHghhBCCCEJhYKbiKIRVIQQQki0UXBDCCGEkIRCwU00cJpbihBCCIkWCm4IIYQQklAMD27mzJmD/Px8WK1WFBQU4Mcff6x1+xUrVqCgoABWqxUdO3bEK6+8EqWSEkIIISQeGBrcLFiwAPfffz8effRRbNy4Eeeffz5GjhyJgwcPBtx+3759uOyyy3D++edj48aNeOSRRzB58mR88sknUS45IYQQQmKVocHNrFmzcNttt+H2229Hjx49MHv2bOTl5WHu3LkBt3/llVfQrl07zJ49Gz169MDtt9+OW2+9FS+++GKUS+5P4QqYVOL9J9iNLhYhhBDS5EhGPbDdbsf69esxbdo0r+XDhw/H6tWrA+6zZs0aDB8+3GvZiBEjMG/ePDgcDphMJr99bDYbbDabfr+srCwMpfdXaitBapfnI3JsQhpDFBgUteFpCUxi3b99LCYxlCJFlFlq+G82kdW/079FEmCT1QY/hhHM9XgNG3OcQOdNFPyXCQ04v56szvdXbftbQni945FJjMzAFM+XK9jbxSTF36AYw94VJ0+ehKIoyMnJ8Vqek5ODY8eOBdzn2LFjAbeXZRknT54MuM/MmTORkZGh/+Xl5YXnCQTAVcnvT3VkQKnKj9hjElKbu4Z0wgd3DEC77GQwBozq3Qr/uLYPOjRLxlf3DkavNun4c/88dM1JhVkU0KVlKq4/Jw89W6XjweHdkGrRfv/MG98v4PFnjz1Lv73gLwMCbvO3y3vqtx8c3hUfBtkuXObceLbfsr7tMoNu/85t52BQp2Zey5JMIlplWPHitX3w9X3n68sHd26Or+4drN9/aES3xhc4BG0yk/D6uMCvCQD8/U9nokOzZDz/pzMDru/UIkW/3S0nDQAwbWR3JHkEq1nJ2o/F7BQzZl7dGwBwTn6213Gu6tvG79gXdW+p376uX1v075CF/h2y/bYL5LWbC/Tb7Zsl4w3n+65VhhVDu7XAyF65SDZr78n/3NAX7Zsl4z83+L/eseSpMWegY4sUvBDktQDg9Z4K5pqCtujZKh0TL+wUzuKhXXayfvuKs/xfTwCYeEEndGmZ2qDjDunWolHlaizGOTck09zRo0fRpk0brF69GgMHDtSXP/PMM3jnnXewY8cOv326du2KW265BdOnT9eXrVq1CoMHD0ZhYSFyc3P99glUc5OXl4fS0lKkp6eH+VkRQgghJBLKysqQkZFRr+u3Yc1SzZs3hyiKfrU0RUVFfrUzLrm5uQG3lyQJzZo1C7iPxWKBxWIJT6EJIYQQEvMMa5Yym80oKCjAkiVLvJYvWbIEgwYNCrjPwIED/bb/7rvv0K9fv4D9bQghhBDS9BjaE2vq1Kl444038Oabb2L79u2YMmUKDh48iIkTJwIApk+fjnHjxunbT5w4EQcOHMDUqVOxfft2vPnmm5g3bx4efPBBo54CIYQQQmKMYc1SADB27FgUFxdjxowZKCwsRK9evbB48WK0b98eAFBYWOiV8yY/Px+LFy/GlClT8PLLL6N169Z46aWXcM011xj1FAghhBASYwzrUGyUhnRIIoQQQkhsaMj1u2kkCCCEEEJIk0HBDSGEEEISCgU3hBBCCEkoFNwQQgghJKFQcEMIIYSQhELBDSGEEEISCgU3hBBCCEkoFNwQQgghJKFQcEMIIYSQhGLo9AtGcCVkLisrM7gkhBBCCKkv13W7PhMrNLngpry8HACQl5dncEkIIYQQ0lDl5eXIyMiodZsmN7eUqqo4evQo0tLSwBgL67HLysqQl5eHQ4cO0bxVEUTnOTroPEcPnevooPMcHZE6z5xzlJeXo3Xr1hCE2nvVNLmaG0EQ0LZt24g+Rnp6On1wooDOc3TQeY4eOtfRQec5OiJxnuuqsXGhDsWEEEIISSgU3BBCCCEkoVBwE0YWiwVPPPEELBaL0UVJaHSeo4POc/TQuY4OOs/REQvnucl1KCaEEEJIYqOaG0IIIYQkFApuCCGEEJJQKLghhBBCSEKh4IYQQgghCYWCmzCZM2cO8vPzYbVaUVBQgB9//NHoIsWsmTNnon///khLS0PLli1x5ZVXYufOnV7bcM7x5JNPonXr1khKSsKQIUPw+++/e21js9lw7733onnz5khJScGYMWNw+PBhr21KSkpw8803IyMjAxkZGbj55ptx+vTpSD/FmDRz5kwwxnD//ffry+g8h8+RI0dw0003oVmzZkhOTsZZZ52F9evX6+vpXDeeLMt47LHHkJ+fj6SkJHTs2BEzZsyAqqr6NnSeG27lypUYPXo0WrduDcYYPv/8c6/10TynBw8exOjRo5GSkoLmzZtj8uTJsNvtDX9SnDTahx9+yE0mE3/99df5tm3b+H333cdTUlL4gQMHjC5aTBoxYgR/6623+NatW/mmTZv4qFGjeLt27XhFRYW+zXPPPcfT0tL4J598wrds2cLHjh3LW7VqxcvKyvRtJk6cyNu0acOXLFnCN2zYwIcOHcr79OnDZVnWt7n00kt5r169+OrVq/nq1at5r169+OWXXx7V5xsL1q5dyzt06MDPPPNMft999+nL6TyHx6lTp3j79u35hAkT+C+//ML37dvHly5dyv/44w99GzrXjff000/zZs2a8a+++orv27ePL1y4kKempvLZs2fr29B5brjFixfzRx99lH/yySccAP/ss8+81kfrnMqyzHv16sWHDh3KN2zYwJcsWcJbt27N77nnngY/JwpuwuCcc87hEydO9FrWvXt3Pm3aNINKFF+Kioo4AL5ixQrOOeeqqvLc3Fz+3HPP6dvU1NTwjIwM/sorr3DOOT99+jQ3mUz8ww8/1Lc5cuQIFwSBf/PNN5xzzrdt28YB8J9//lnfZs2aNRwA37FjRzSeWkwoLy/nXbp04UuWLOEXXnihHtzQeQ6fv/71r3zw4MFB19O5Do9Ro0bxW2+91WvZ1VdfzW+66SbOOZ3ncPANbqJ5ThcvXswFQeBHjhzRt/nggw+4xWLhpaWlDXoe1CzVSHa7HevXr8fw4cO9lg8fPhyrV682qFTxpbS0FACQnZ0NANi3bx+OHTvmdU4tFgsuvPBC/ZyuX78eDofDa5vWrVujV69e+jZr1qxBRkYGzj33XH2bAQMGICMjo0m9NnfffTdGjRqFYcOGeS2n8xw+X3zxBfr164drr70WLVu2RN++ffH666/r6+lch8fgwYOxbNky7Nq1CwCwefNm/PTTT7jssssA0HmOhGie0zVr1qBXr15o3bq1vs2IESNgs9m8mnjro8lNnBluJ0+ehKIoyMnJ8Vqek5ODY8eOGVSq+ME5x9SpUzF48GD06tULAPTzFuicHjhwQN/GbDYjKyvLbxvX/seOHUPLli39HrNly5ZN5rX58MMPsWHDBvz6669+6+g8h8/evXsxd+5cTJ06FY888gjWrl2LyZMnw2KxYNy4cXSuw+Svf/0rSktL0b17d4iiCEVR8Mwzz+D6668HQO/pSIjmOT127Jjf42RlZcFsNjf4vFNwEyaMMa/7nHO/ZcTfPffcg99++w0//fST37pQzqnvNoG2byqvzaFDh3Dffffhu+++g9VqDbodnefGU1UV/fr1w7PPPgsA6Nu3L37//XfMnTsX48aN07ejc904CxYswLvvvov3338fZ5xxBjZt2oT7778frVu3xvjx4/Xt6DyHX7TOabjOOzVLNVLz5s0hiqJfVFlUVOQXgRJv9957L7744gv88MMPaNu2rb48NzcXAGo9p7m5ubDb7SgpKal1m+PHj/s97okTJ5rEa7N+/XoUFRWhoKAAkiRBkiSsWLECL730EiRJ0s8BnefGa9WqFXr27Om1rEePHjh48CAAek+Hy0MPPYRp06bhz3/+M3r37o2bb74ZU6ZMwcyZMwHQeY6EaJ7T3Nxcv8cpKSmBw+Fo8Hmn4KaRzGYzCgoKsGTJEq/lS5YswaBBgwwqVWzjnOOee+7Bp59+iu+//x75+fle6/Pz85Gbm+t1Tu12O1asWKGf04KCAphMJq9tCgsLsXXrVn2bgQMHorS0FGvXrtW3+eWXX1BaWtokXpuLL74YW7ZswaZNm/S/fv364cYbb8SmTZvQsWNHOs9hct555/mlM9i1axfat28PgN7T4VJVVQVB8L5siaKoDwWn8xx+0TynAwcOxNatW1FYWKhv891338FisaCgoKBhBW9Q92MSkGso+Lx58/i2bdv4/fffz1NSUvj+/fuNLlpMuuuuu3hGRgZfvnw5Lyws1P+qqqr0bZ577jmekZHBP/30U75lyxZ+/fXXBxx62LZtW7506VK+YcMGftFFFwUcenjmmWfyNWvW8DVr1vDevXsn7HDO+vAcLcU5nedwWbt2LZckiT/zzDN89+7d/L333uPJycn83Xff1behc91448eP523atNGHgn/66ae8efPm/OGHH9a3ofPccOXl5Xzjxo1848aNHACfNWsW37hxo57OJFrn1DUU/OKLL+YbNmzgS5cu5W3btqWh4EZ6+eWXefv27bnZbOZnn322PqyZ+AMQ8O+tt97St1FVlT/xxBM8NzeXWywWfsEFF/AtW7Z4Hae6uprfc889PDs7myclJfHLL7+cHzx40Gub4uJifuONN/K0tDSelpbGb7zxRl5SUhKFZxmbfIMbOs/h8+WXX/JevXpxi8XCu3fvzl977TWv9XSuG6+srIzfd999vF27dtxqtfKOHTvyRx99lNtsNn0bOs8N98MPPwT8Th4/fjznPLrn9MCBA3zUqFE8KSmJZ2dn83vuuYfX1NQ0+DkxzjlvWF0PIYQQQkjsoj43hBBCCEkoFNwQQgghJKFQcEMIIYSQhELBDSGEEEISCgU3hBBCCEkoFNwQQgghJKFQcEMIIYSQhELBDSEkbuzfvx+MMWzatClijzFhwgRceeWVETs+ISTyKLghhETNhAkTwBjz+7v00kvrtX9eXh4KCwvRq1evCJeUEBLPJKMLQAhpWi699FK89dZbXsssFku99hVFUZ+lmBBCgqGaG0JIVFksFuTm5nr9ZWVlAQAYY5g7dy5GjhyJpKQk5OfnY+HChfq+vs1SJSUluPHGG9GiRQskJSWhS5cuXoHTli1bcNFFFyEpKQnNmjXDX/7yF1RUVOjrFUXB1KlTkZmZiWbNmuHhhx+G74w0nHO88MIL6NixI5KSktCnTx98/PHHETxDhJDGouCGEBJT/va3v+Gaa67B5s2bcdNNN+H666/H9u3bg267bds2fP3119i+fTvmzp2L5s2bAwCqqqpw6aWXIisrC7/++isWLlyIpUuX4p577tH3/8c//oE333wT8+bNw08//YRTp07hs88+83qMxx57DG+99Rbmzp2L33//HVOmTMFNN92EFStWRO4kEEIap8FTbRJCSIjGjx/PRVHkKSkpXn8zZszgnGszxk+cONFrn3PPPZffddddnHPO9+3bxwHwjRs3cs45Hz16NL/lllsCPtZrr73Gs7KyeEVFhb5s0aJFXBAEfuzYMc45561ateLPPfecvt7hcPC2bdvyK664gnPOeUVFBbdarXz16tVex77tttv49ddfH/qJIIREFPW5IYRE1dChQzF37lyvZdnZ2frtgQMHeq0bOHBg0NFRd911F6655hps2LABw4cPx5VXXolBgwYBALZv344+ffogJSVF3/68886DqqrYuXMnrFYrCgsLvR5PkiT069dPb5ratm0bampqcMkll3g9rt1uR9++fRv+5AkhUUHBDSEkqlJSUtC5c+cG7cMYC7h85MiROHDgABYtWoSlS5fi4osvxt13340XX3wRnPOg+wVb7ktVVQDAokWL0KZNG6919e0ETQiJPupzQwiJKT///LPf/e7duwfdvkWLFpgwYQLeffddzJ49G6+99hoAoGfPnti0aRMqKyv1bVetWgVBENC1a1dkZGSgVatWXo8nyzLWr1+v3+/ZsycsFgsOHjyIzp07e/3l5eWF6ykTQsKMam4IIVFls9lw7Ngxr2WSJOkdgRcuXIh+/fph8ODBeO+997B27VrMmzcv4LEef/xxFBQU4IwzzoDNZsNXX32FHj16AABuvPFGPPHEExg/fjyefPJJnDhxAvfeey9uvvlm5OTkAADuu+8+PPfcc+jSpQt69OiBWbNm4fTp0/rx09LS8OCDD2LKlClQVRWDBw9GWVkZVq/+//buF1WVKIDj+E+D4GAwia5AMApGFyEuQDFaDCZtYrC5C2GaVTdw12ASm9kV3NcuvMdr1/eH4fOJw5kJJ3055zDnI61WK7PZ7A/MEPBd4gb4qy6XS3q93k/P+v1+brdbkmS326UsyyyXy3S73ZxOpwwGg99+q9FoZLPZ5PF4pNlsZjwepyzLJElRFLler1mtVhmNRimKItPpNMfj8ev99Xqd5/OZ+Xyeer2exWKRyWSS1+v1NWa/36fT6eRwOOR+v6fdbmc4HGa73b57aoA3qX1+/vJTB4B/pFar5Xw+u/4A+BZnbgCAShE3AEClOHMD/DfskgPvYOUGAKgUcQMAVIq4AQAqRdwAAJUibgCAShE3AECliBsAoFLEDQBQKeIGAKiUHzd/pEUQ7x58AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    num_episodes = 10_000\n",
    "else:\n",
    "    num_episodes = 50\n",
    "\n",
    "for i_episode in range(num_episodes):\n",
    "    # Initialize the environment and get it's state\n",
    "    state = env.reset()\n",
    "    goal_event = np.random.randint(2)\n",
    "    state = torch.tensor(np.append(state, goal_event), dtype=torch.float32, device=device).unsqueeze(0)\n",
    "    \n",
    "    \n",
    "    \n",
    "    r_sum = 0\n",
    "    for t in range(100):\n",
    "        \n",
    "        action = select_action(state)\n",
    "        observation, reward, terminated, info = env.step(action.item())\n",
    "        \n",
    "        observation = np.append(observation, goal_event) \n",
    "        #if i_episode %100==0:\n",
    "        #    env.render()\n",
    "        \n",
    "        r = 0\n",
    "        if (info['E'] == 1 and goal_event ==1) or (info['E'] == 3 and goal_event ==0):\n",
    "            r = 1\n",
    "        reward = torch.tensor([r], device=device)\n",
    "        r_sum +=r\n",
    "        done = terminated or t==99 or r==1\n",
    "\n",
    "        if terminated:\n",
    "            next_state = None\n",
    "        else:\n",
    "            next_state = torch.tensor(observation, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "\n",
    "        # Store the transition in memory\n",
    "        memory.push(state, action, next_state, reward)\n",
    "\n",
    "        # Move to the next state\n",
    "        state = next_state\n",
    "\n",
    "        # Perform one step of the optimization (on the policy network)\n",
    "        optimize_model()\n",
    "\n",
    "        # Soft update of the target network's weights\n",
    "        # θ′ ← τ θ + (1 −τ )θ′\n",
    "        target_net_state_dict = target_net.state_dict()\n",
    "        policy_net_state_dict = policy_net.state_dict()\n",
    "        for key in policy_net_state_dict:\n",
    "            target_net_state_dict[key] = policy_net_state_dict[key]*TAU + target_net_state_dict[key]*(1-TAU)\n",
    "        target_net.load_state_dict(target_net_state_dict)\n",
    "\n",
    "        if done:\n",
    "            episode_durations.append(r_sum)\n",
    "            epsilon_values.append(1*(0.9995**(steps_done/100)))\n",
    "            if i_episode%100==0:\n",
    "                plot_durations()\n",
    "                pass\n",
    "            break\n",
    "\n",
    "print('Complete')\n",
    "plot_durations(show_result=True)\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9995,\n",
       " 0.9990901865555974,\n",
       " 0.9986805411422696,\n",
       " 0.9981812008716985,\n",
       " 0.9978467825760566,\n",
       " 0.9973478591847686,\n",
       " 0.9968491852551763,\n",
       " 0.9963507606625488,\n",
       " 0.9958774881343659,\n",
       " 0.9955239259891691,\n",
       " 0.9950261640261745,\n",
       " 0.9945435727165928,\n",
       " 0.9943147968063615,\n",
       " 0.9939419054484496,\n",
       " 0.9934449344957255,\n",
       " 0.9929482120284777,\n",
       " 0.9927346977334779,\n",
       " 0.9923673620150318,\n",
       " 0.9918711783340244,\n",
       " 0.9913752427448574,\n",
       " 0.990879555123485,\n",
       " 0.9903841153459234,\n",
       " 0.9898889232882505,\n",
       " 0.9893939788266064,\n",
       " 0.9888992818371931,\n",
       " 0.9884048321962746,\n",
       " 0.9879106297801765,\n",
       " 0.9874166744652865,\n",
       " 0.9869476456811028,\n",
       " 0.986523243337075,\n",
       " 0.9860299817154065,\n",
       " 0.9857242833758109,\n",
       " 0.9853053348423836,\n",
       " 0.9848126821749624,\n",
       " 0.984320275833875,\n",
       " 0.9838281156959582,\n",
       " 0.9833362016381102,\n",
       " 0.9828445335372912,\n",
       " 0.9823531112705226,\n",
       " 0.9821664352412683,\n",
       " 0.9816753520236478,\n",
       " 0.9815035309129713,\n",
       " 0.9810127791475148,\n",
       " 0.9806252587518953,\n",
       " 0.9802329890319659,\n",
       " 0.97974287253745,\n",
       " 0.979458717264181,\n",
       " 0.978968987905549,\n",
       " 0.9784795034115963,\n",
       " 0.9779902636598905,\n",
       " 0.9777115064644274,\n",
       " 0.9772226507111952,\n",
       " 0.9767340393858397,\n",
       " 0.9762456723661468,\n",
       " 0.9757575495299637,\n",
       " 0.9752696707551989,\n",
       " 0.9747820359198213,\n",
       " 0.9742946449018615,\n",
       " 0.973831849159646,\n",
       " 0.9733449332350662,\n",
       " 0.9728582607684488,\n",
       " 0.9723718316380646,\n",
       " 0.9718856457222457,\n",
       " 0.9715065894692269,\n",
       " 0.9712053938090399,\n",
       " 0.9707731955214696,\n",
       " 0.9702878089237089,\n",
       " 0.9700840189307884,\n",
       " 0.969598976921323,\n",
       " 0.9691141774328624,\n",
       " 0.9686296203441461,\n",
       " 0.9683438453103215,\n",
       " 0.9679952171185376,\n",
       " 0.9677677080938754,\n",
       " 0.9674144490319959,\n",
       " 0.96693074180748,\n",
       " 0.9665149470334294,\n",
       " 0.9660316895599128,\n",
       " 0.9657804911730016,\n",
       " 0.9655003854155836,\n",
       " 0.9650176352228758,\n",
       " 0.964597838906047,\n",
       " 0.9641926916053289,\n",
       " 0.9637105952595263,\n",
       " 0.9635660133656643,\n",
       " 0.9630842303589815,\n",
       " 0.9628241677057404,\n",
       " 0.9623427556218875,\n",
       " 0.9618615842440766,\n",
       " 0.9614912462365656,\n",
       " 0.9610105006134474,\n",
       " 0.9605299953631408,\n",
       " 0.9602274004207663,\n",
       " 0.959747286720556,\n",
       " 0.9593009964208943,\n",
       " 0.9591043107020748,\n",
       " 0.9586247585467238,\n",
       " 0.9581454461674505,\n",
       " 0.9576663734443668,\n",
       " 0.9571875402576447,\n",
       " 0.9567567950941942,\n",
       " 0.9562784166966473,\n",
       " 0.955800277488299,\n",
       " 0.9553223773495548,\n",
       " 0.9550023179445662,\n",
       " 0.9545248167855941,\n",
       " 0.9541716196422394,\n",
       " 0.9536945338324183,\n",
       " 0.9532176865655021,\n",
       " 0.9527410777222195,\n",
       " 0.9522647071833584,\n",
       " 0.9518218963440819,\n",
       " 0.9515077684137198,\n",
       " 0.9510320145295129,\n",
       " 0.950784716526215,\n",
       " 0.950494698907162,\n",
       " 0.9500194515577084,\n",
       " 0.9495444418319297,\n",
       " 0.9493829926347253,\n",
       " 0.9489083011384079,\n",
       " 0.9487090014932998,\n",
       " 0.9482346469925532,\n",
       " 0.947760529669057,\n",
       " 0.9475851663481911,\n",
       " 0.9471113737650171,\n",
       " 0.9466378180781346,\n",
       " 0.9461644991690956,\n",
       " 0.9459184668716953,\n",
       " 0.9454455076382596,\n",
       " 0.9449727848844405,\n",
       " 0.9446656418506414,\n",
       " 0.9441933090297161,\n",
       " 0.9437212123752013,\n",
       " 0.9433861670505599,\n",
       " 0.9432729391949977,\n",
       " 0.9428013027254002,\n",
       " 0.9423299020740376,\n",
       " 0.9418587371230006,\n",
       " 0.9413878077544391,\n",
       " 0.940917113850562,\n",
       " 0.9404466552936367,\n",
       " 0.9400563533413266,\n",
       " 0.939586325164656,\n",
       " 0.9393232120474037,\n",
       " 0.93885355044138,\n",
       " 0.9383841236661593,\n",
       " 0.9379149316043263,\n",
       " 0.9374459741385242,\n",
       " 0.936977251151455,\n",
       " 0.9365087625258793,\n",
       " 0.9360405081446164,\n",
       " 0.9355724878905441,\n",
       " 0.9354087360925019,\n",
       " 0.9349410317244556,\n",
       " 0.9346885686089049,\n",
       " 0.9342212243246004,\n",
       " 0.93394560080827,\n",
       " 0.9335346524135307,\n",
       " 0.9332685664296063,\n",
       " 0.9328019321463915,\n",
       " 0.9323355311803184,\n",
       " 0.9318693634147283,\n",
       " 0.9315105730763255,\n",
       " 0.9310448177897873,\n",
       " 0.9305792953808925,\n",
       " 0.9303419685843786,\n",
       " 0.9298767976000865,\n",
       " 0.929583859308369,\n",
       " 0.9291190673787147,\n",
       " 0.9286545078450255,\n",
       " 0.928190180591103,\n",
       " 0.9277910448415317,\n",
       " 0.9273271493191111,\n",
       " 0.9270350142409094,\n",
       " 0.926571496733789,\n",
       " 0.9264463867467403,\n",
       " 0.9262610696685853,\n",
       " 0.9257979391337511,\n",
       " 0.9253350401641842,\n",
       " 0.9250990508166088,\n",
       " 0.9246365012912006,\n",
       " 0.924174183040555,\n",
       " 0.9237120959490347,\n",
       " 0.9232502399010603,\n",
       " 0.9229132308121025,\n",
       " 0.9224517741966966,\n",
       " 0.9219905483095983,\n",
       " 0.921561815200598,\n",
       " 0.9212069934964877,\n",
       " 0.9209490271583216,\n",
       " 0.920580629124793,\n",
       " 0.920401088518999,\n",
       " 0.9199408879747396,\n",
       " 0.9195085092706622,\n",
       " 0.9190487550160269,\n",
       " 0.9185892306385189,\n",
       " 0.9181299360231997,\n",
       " 0.917868240855521,\n",
       " 0.9174093067350934,\n",
       " 0.9169506020817259,\n",
       " 0.916492126780685,\n",
       " 0.9160338807172947,\n",
       " 0.9155758637769361,\n",
       " 0.9151180758450477,\n",
       " 0.9146605168071252,\n",
       " 0.9142031865487217,\n",
       " 0.9137552247471342,\n",
       " 0.9133120501387766,\n",
       " 0.9128553941137072,\n",
       " 0.9123989664166504,\n",
       " 0.9119427669334421,\n",
       " 0.9117694709437566,\n",
       " 0.9114412109527231,\n",
       " 0.9110629467714979,\n",
       " 0.9106074152981122,\n",
       " 0.9104070536127438,\n",
       " 0.9101202488578115,\n",
       " 0.9096651887333826,\n",
       " 0.909210356139016,\n",
       " 0.9087557509609465,\n",
       " 0.9083013730854661,\n",
       " 0.9080742693506785,\n",
       " 0.9076202322160032,\n",
       " 0.9071664220998953,\n",
       " 0.9067128388888454,\n",
       " 0.906508800441418,\n",
       " 0.9064090650229851,\n",
       " 0.9059558604904737,\n",
       " 0.9056296935457376,\n",
       " 0.9051768786989649,\n",
       " 0.9047242902596154,\n",
       " 0.9042854956873398,\n",
       " 0.9039418465770073,\n",
       " 0.9036390010701717,\n",
       " 0.903241387979439,\n",
       " 0.9030110332034924,\n",
       " 0.9028033126201642,\n",
       " 0.9024557133548989,\n",
       " 0.9020044854982215,\n",
       " 0.9015534832554725,\n",
       " 0.9013460979539009,\n",
       " 0.9012198867797522,\n",
       " 0.9007692768363623,\n",
       " 0.9004449771924715,\n",
       " 0.9001297978086509,\n",
       " 0.8996797329097466,\n",
       " 0.8992298930432917,\n",
       " 0.8987802780967701,\n",
       " 0.8983308879577218,\n",
       " 0.8979401013189148,\n",
       " 0.8976931400043147,\n",
       " 0.8973295570098152,\n",
       " 0.8969661212734242,\n",
       " 0.8965176382127876,\n",
       " 0.8963293422026097,\n",
       " 0.8958946192106837,\n",
       " 0.8954466719010784,\n",
       " 0.894998948565128,\n",
       " 0.8945514490908454,\n",
       " 0.8941041733663001,\n",
       " 0.8936571212796169,\n",
       " 0.8934158061020637,\n",
       " 0.8929690981990128,\n",
       " 0.8926074285323412,\n",
       " 0.8922949924963317,\n",
       " 0.8918488450000837,\n",
       " 0.8914029205775836,\n",
       " 0.8909572191172949,\n",
       " 0.8905117405077363,\n",
       " 0.8900664846374825,\n",
       " 0.8897816377226717,\n",
       " 0.8893456425398519,\n",
       " 0.888900969718582,\n",
       " 0.8885631670789572,\n",
       " 0.8881188854954178,\n",
       " 0.8878346618684361,\n",
       " 0.8873907445375019,\n",
       " 0.8869470491652331,\n",
       " 0.8865035756406506,\n",
       " 0.8860603238528304,\n",
       " 0.885617293690904,\n",
       " 0.8851744850440586,\n",
       " 0.8849443120536888,\n",
       " 0.8845947406951931,\n",
       " 0.8841524433248455,\n",
       " 0.8837103671031831,\n",
       " 0.8833612831785369,\n",
       " 0.8829196025369477,\n",
       " 0.8824781427356793,\n",
       " 0.8820369036643115,\n",
       " 0.8818604698154129,\n",
       " 0.8814195395805052,\n",
       " 0.8809788298107151,\n",
       " 0.8805383403958098,\n",
       " 0.8802609451560393,\n",
       " 0.8799220252013816,\n",
       " 0.8794820641887809,\n",
       " 0.8790423231566866,\n",
       " 0.8786028019951083,\n",
       " 0.8781635005941109,\n",
       " 0.8779395414630127,\n",
       " 0.8775005716922812,\n",
       " 0.8770618214064351,\n",
       " 0.876623290495732,\n",
       " 0.8761849788504841,\n",
       " 0.8757468863610589,\n",
       " 0.8753090129178784,\n",
       " 0.8748713584114196,\n",
       " 0.8746526132252497,\n",
       " 0.8742152869186371,\n",
       " 0.8740141902512919,\n",
       " 0.8737038927139748,\n",
       " 0.8732670407676179,\n",
       " 0.8729744721686914,\n",
       " 0.8725379849326071,\n",
       " 0.8722674724551225,\n",
       " 0.8718356989766445,\n",
       " 0.8715000229283181,\n",
       " 0.871064272916854,\n",
       " 0.8707463129918495,\n",
       " 0.8704415289202578,\n",
       " 0.8700063081557978,\n",
       " 0.86957130500172,\n",
       " 0.8691365193492191,\n",
       " 0.8688279535106382,\n",
       " 0.868393539533883,\n",
       " 0.867959342764116,\n",
       " 0.8676338376635432,\n",
       " 0.8672000207447115,\n",
       " 0.8667664207343392,\n",
       " 0.8663330375239721,\n",
       " 0.86589987100521,\n",
       " 0.8656617217454304,\n",
       " 0.8654842349100876,\n",
       " 0.8651812927039841,\n",
       " 0.8649087353818047,\n",
       " 0.8644762810141138,\n",
       " 0.8642558125516693,\n",
       " 0.8640526855180899,\n",
       " 0.8636206591753309,\n",
       " 0.8631888488457433,\n",
       " 0.8627658841946366,\n",
       " 0.8623345012525394,\n",
       " 0.8619507518447107,\n",
       " 0.8615197764687884,\n",
       " 0.8610890165805541,\n",
       " 0.8607359541935384,\n",
       " 0.8603055862164417,\n",
       " 0.860068975558094,\n",
       " 0.859638941070315,\n",
       " 0.8592091215997799,\n",
       " 0.8588954890971493,\n",
       " 0.8584660413526009,\n",
       " 0.858174139543126,\n",
       " 0.8577450524733545,\n",
       " 0.8576592608080579,\n",
       " 0.857230431177654,\n",
       " 0.8568018159620652,\n",
       " 0.8563734150540842,\n",
       " 0.8559452283465572,\n",
       " 0.8555172557323839,\n",
       " 0.8550894971045178,\n",
       " 0.8546619523559656,\n",
       " 0.8545209095065305,\n",
       " 0.8540936490517773,\n",
       " 0.853756264345062,\n",
       " 0.8533293862128896,\n",
       " 0.8529027215197831,\n",
       " 0.8524762701590233,\n",
       " 0.8520500320239438,\n",
       " 0.8516240070079318,\n",
       " 0.851198195004428,\n",
       " 0.8507725959069258,\n",
       " 0.8505088313411773,\n",
       " 0.8500835769255067,\n",
       " 0.849658535137044,\n",
       " 0.8492676843926151,\n",
       " 0.8488430505504189,\n",
       " 0.8484186290251438,\n",
       " 0.8479944197106312,\n",
       " 0.8478078348132738,\n",
       " 0.8473839308958673,\n",
       " 0.8470746148792484,\n",
       " 0.8468670551314484,\n",
       " 0.8464436216038828,\n",
       " 0.8461685033507035,\n",
       " 0.8457454190990281,\n",
       " 0.8453225463894787,\n",
       " 0.844899885116284,\n",
       " 0.8444774351737259,\n",
       " 0.844076303377056,\n",
       " 0.8438483765601956,\n",
       " 0.8434264523719155,\n",
       " 0.8430047391457296,\n",
       " 0.8425832367761568,\n",
       " 0.8421619451577688,\n",
       " 0.8418250635330973,\n",
       " 0.8414041510013307,\n",
       " 0.8410002729694099,\n",
       " 0.8405797728329253,\n",
       " 0.8402309173985821,\n",
       " 0.8398108019398829,\n",
       " 0.8393908965389131,\n",
       " 0.8392313875418321,\n",
       " 0.8388117718480613,\n",
       " 0.8383923659621373,\n",
       " 0.8380779491709855,\n",
       " 0.8378558324124077,\n",
       " 0.8375248619800646,\n",
       " 0.8373196422201105,\n",
       " 0.8369009823990005,\n",
       " 0.836482531907801,\n",
       " 0.8362482910290197,\n",
       " 0.8360601092854211,\n",
       " 0.8358343470899289,\n",
       " 0.8354164299163839,\n",
       " 0.8350989526215835,\n",
       " 0.8346814031452728,\n",
       " 0.8342640624437002,\n",
       " 0.8338469304124784,\n",
       " 0.8334300069472722,\n",
       " 0.8330716194987795,\n",
       " 0.8326550836890302,\n",
       " 0.8323719583073735,\n",
       " 0.8321014137450187,\n",
       " 0.831810156402812,\n",
       " 0.8313942513246105,\n",
       " 0.8310741461290863,\n",
       " 0.8306586090560218,\n",
       " 0.8302432797514938,\n",
       " 0.8298281581116181,\n",
       " 0.8294381330259833,\n",
       " 0.8290234139594704,\n",
       " 0.8286089022524907,\n",
       " 0.8282484456633458,\n",
       " 0.8281241866488125,\n",
       " 0.8279833823017699,\n",
       " 0.8275693906106191,\n",
       " 0.8271556059153138,\n",
       " 0.8267420281123562,\n",
       " 0.8264774468477913,\n",
       " 0.8260642081243674,\n",
       " 0.8258287545104762,\n",
       " 0.8255025350233661,\n",
       " 0.8252094603724921,\n",
       " 0.8249288667053287,\n",
       " 0.8245164022719761,\n",
       " 0.8241041440708401,\n",
       " 0.8238321665820114,\n",
       " 0.8234202504987205,\n",
       " 0.8230085403734712,\n",
       " 0.8225970361032845,\n",
       " 0.8221857375852328,\n",
       " 0.8217746447164402,\n",
       " 0.8214828935625924,\n",
       " 0.821174818219989,\n",
       " 0.8208545424231007,\n",
       " 0.8204441151518892,\n",
       " 0.8200338930943133,\n",
       " 0.819697664065543,\n",
       " 0.8192878152335104,\n",
       " 0.8190870641198322,\n",
       " 0.8188126473108139,\n",
       " 0.8184891993315736,\n",
       " 0.8181699709836702,\n",
       " 0.8177649758353775,\n",
       " 0.8175891313047405,\n",
       " 0.8173356545904965,\n",
       " 0.8169269867632014,\n",
       " 0.8165185232698198,\n",
       " 0.8161878175570042,\n",
       " 0.8157797236482258,\n",
       " 0.8153718337864018,\n",
       " 0.8152372748927136,\n",
       " 0.8148296562552674,\n",
       " 0.8145974048329394,\n",
       " 0.8143204195533709,\n",
       " 0.8139132593435942,\n",
       " 0.8137178947608228,\n",
       " 0.8133110358134424,\n",
       " 0.812981629194763,\n",
       " 0.8125751383801657,\n",
       " 0.8121688508109757,\n",
       " 0.8117627663855702,\n",
       " 0.8113568850023775,\n",
       " 0.8109512065598763,\n",
       " 0.8106876243511291,\n",
       " 0.8102822805389536,\n",
       " 0.8100270180055914,\n",
       " 0.809698941477313,\n",
       " 0.8092940920065744,\n",
       " 0.8088894449605711,\n",
       " 0.8086871973152144,\n",
       " 0.8082828537165568,\n",
       " 0.8080201387983821,\n",
       " 0.8076161287289829,\n",
       " 0.8074505429958274,\n",
       " 0.8072002095426093,\n",
       " 0.8069660968967768,\n",
       " 0.8065626138483284,\n",
       " 0.8063448168927244,\n",
       " 0.8059416444842781,\n",
       " 0.8055386736620359,\n",
       " 0.805135904325205,\n",
       " 0.8047333363730425,\n",
       " 0.804330969704856,\n",
       " 0.804069539261392,\n",
       " 0.8036675044917613,\n",
       " 0.8032737054452402,\n",
       " 0.8029082076842537,\n",
       " 0.8026673111290803,\n",
       " 0.8022659774735158,\n",
       " 0.8021255581067431,\n",
       " 0.8017244953276897,\n",
       " 0.801323633080026,\n",
       " 0.800922971263486,\n",
       " 0.8007627626351348,\n",
       " 0.8003623812538172,\n",
       " 0.7999622000631903,\n",
       " 0.7996781928887129,\n",
       " 0.7992783537922686,\n",
       " 0.7988787146153725,\n",
       " 0.798599086090146,\n",
       " 0.7984393423085645,\n",
       " 0.7980401226374103,\n",
       " 0.7978804906652928,\n",
       " 0.7974815504199602,\n",
       " 0.7972024109388854,\n",
       " 0.7968038097334161,\n",
       " 0.7964054078285494,\n",
       " 0.7960072051246352,\n",
       " 0.7957643992503225,\n",
       " 0.7954062963166687,\n",
       " 0.7950085931685104,\n",
       " 0.7947700667347353,\n",
       " 0.794392546233263,\n",
       " 0.7942177553994378,\n",
       " 0.7938206465217381,\n",
       " 0.7935388197568701,\n",
       " 0.7933761202978293,\n",
       " 0.7929794322376804,\n",
       " 0.7925829425215617,\n",
       " 0.792186651050301,\n",
       " 0.7917905577247758,\n",
       " 0.7916876059041844,\n",
       " 0.7913946624459135,\n",
       " 0.7911216101228337,\n",
       " 0.7909356719046221,\n",
       " 0.7905402040686699,\n",
       " 0.7903899781421998,\n",
       " 0.7899947831531287,\n",
       " 0.7896669213818694,\n",
       " 0.7892720879211785,\n",
       " 0.7888774518772179,\n",
       " 0.7884830131512794,\n",
       " 0.7880887716447038,\n",
       " 0.7877341228298392,\n",
       " 0.7873402557684244,\n",
       " 0.7870843477902718,\n",
       " 0.7869308429302493,\n",
       " 0.7866671993442442,\n",
       " 0.7862738657445721,\n",
       " 0.7858807288116999,\n",
       " 0.785487788447294,\n",
       " 0.7850950445530704,\n",
       " 0.784702497030794,\n",
       " 0.7843101457822786,\n",
       " 0.7839179907093875,\n",
       " 0.7836240030859648,\n",
       " 0.7832321910844219,\n",
       " 0.7830089459079658,\n",
       " 0.7826174414350118,\n",
       " 0.7823356794299271,\n",
       " 0.781956243779169,\n",
       " 0.7815652656572795,\n",
       " 0.7811744830244508,\n",
       " 0.7807838957829386,\n",
       " 0.7803935038350472,\n",
       " 0.7800033070831297,\n",
       " 0.7796133054295882,\n",
       " 0.7792234987768735,\n",
       " 0.778985812432218,\n",
       " 0.7787131469450573,\n",
       " 0.7783237903715848,\n",
       " 0.7780046632546337,\n",
       " 0.7776156609230065,\n",
       " 0.777226853092545,\n",
       " 0.7769625748172708,\n",
       " 0.7765740935298623,\n",
       " 0.7762246264497132,\n",
       " 0.7759956167083011,\n",
       " 0.775607618899947,\n",
       " 0.7752198150904971,\n",
       " 0.7748942097419476,\n",
       " 0.7745067626370766,\n",
       " 0.7742860044751171,\n",
       " 0.7738988614728796,\n",
       " 0.7736008932755134,\n",
       " 0.7732140928288757,\n",
       " 0.7729279850148238,\n",
       " 0.7726574399263118,\n",
       " 0.7722711112063486,\n",
       " 0.7719853523181807,\n",
       " 0.7718309320819786,\n",
       " 0.7716611054983451,\n",
       " 0.771275274945596,\n",
       " 0.7708896373081232,\n",
       " 0.7705041924894692,\n",
       " 0.7701189403932245,\n",
       " 0.769733880923028,\n",
       " 0.7695375747328576,\n",
       " 0.7691528059454912,\n",
       " 0.7689758769117974,\n",
       " 0.7687951436306291,\n",
       " 0.7686721154905632,\n",
       " 0.768287779432818,\n",
       " 0.7679382006264006,\n",
       " 0.7675542315260875,\n",
       " 0.7674314019657206,\n",
       " 0.7670476862647378,\n",
       " 0.7666641624216055,\n",
       " 0.7663919769076833,\n",
       " 0.7662233470617515,\n",
       " 0.7660355984007942,\n",
       " 0.7656525806015938,\n",
       " 0.7652697543112931,\n",
       " 0.7650439765884876,\n",
       " 0.7646614546001933,\n",
       " 0.7642791238728933,\n",
       " 0.7640421748312941,\n",
       " 0.7636601537438785,\n",
       " 0.7632783236670067,\n",
       " 0.7629806287451265,\n",
       " 0.7627746002790503,\n",
       " 0.7624809151685576,\n",
       " 0.7620996747109734,\n",
       " 0.761718624873618,\n",
       " 0.7615586407619526,\n",
       " 0.7613187275951295,\n",
       " 0.7611017284273016,\n",
       " 0.760721177563088,\n",
       " 0.760489134976743,\n",
       " 0.7602533609433424,\n",
       " 0.7598732342628708,\n",
       " 0.7594932976457394,\n",
       " 0.7592958056863138,\n",
       " 0.7589161577834707,\n",
       " 0.7588250705361709,\n",
       " 0.7585177317818105,\n",
       " 0.7581384729159196,\n",
       " 0.7577594036794617,\n",
       " 0.757380523977622,\n",
       " 0.7570018337156332,\n",
       " 0.7566233327987755,\n",
       " 0.7564606355951087,\n",
       " 0.7562147643718494,\n",
       " 0.7558366569896635,\n",
       " 0.7556703496393021,\n",
       " 0.7555456431409574,\n",
       " 0.7553189567763555,\n",
       " 0.7549412972979673,\n",
       " 0.7548204861502449,\n",
       " 0.7545034488626253,\n",
       " 0.754254441555951,\n",
       " 0.7540922537364974,\n",
       " 0.7537152076096291,\n",
       " 0.7533383500058243,\n",
       " 0.7531273920594311,\n",
       " 0.7528750735639177,\n",
       " 0.7526491884503247,\n",
       " 0.7522728638560996,\n",
       " 0.7519832221466596,\n",
       " 0.7516072305355863,\n",
       " 0.7512314269203185,\n",
       " 0.7508558112068584,\n",
       " 0.750480383301255,\n",
       " 0.7501051431096044,\n",
       " 0.7498575873672286,\n",
       " 0.7497375897514107,\n",
       " 0.7494864069333769,\n",
       " 0.7491116637299102,\n",
       " 0.748976802050124,\n",
       " 0.7487183850232759,\n",
       " 0.7483440258307643,\n",
       " 0.747969853817849,\n",
       " 0.7475958688909401,\n",
       " 0.7472220709564947,\n",
       " 0.7468484599210164,\n",
       " 0.746475035691056,\n",
       " 0.7463779759784835,\n",
       " 0.7460047869904943,\n",
       " 0.7457958826676734,\n",
       " 0.7455683927402152,\n",
       " 0.7454528096990888,\n",
       " 0.7450800832942394,\n",
       " 0.7447075432525923,\n",
       " 0.744335189480966,\n",
       " 0.7441751346046891,\n",
       " 0.7438030470373869,\n",
       " 0.7436059160640786,\n",
       " 0.7433158938032226,\n",
       " 0.7430668624308504,\n",
       " 0.7429033648287039,\n",
       " 0.7426767572052227,\n",
       " 0.7425579087176041,\n",
       " 0.7424130878376611,\n",
       " 0.7420418812937424,\n",
       " 0.7417487593594336,\n",
       " 0.7416003873491631,\n",
       " 0.7413964242938338,\n",
       " 0.7411999311505072,\n",
       " 0.7410146079994293,\n",
       " 0.7406441006954296,\n",
       " 0.740399667362492,\n",
       " 0.7400294675288108,\n",
       " 0.7399036417557594,\n",
       " 0.7397371405396802,\n",
       " 0.7396557535821502,\n",
       " 0.7392859257053591,\n",
       " 0.7389162827425065,\n",
       " 0.7387869513743143,\n",
       " 0.7384175578986272,\n",
       " 0.7380483491196779,\n",
       " 0.7378859557450703,\n",
       " 0.737620298202308,\n",
       " 0.7372514880532068,\n",
       " 0.7368828623091803,\n",
       " 0.7365144208780258,\n",
       " 0.7363118566208612,\n",
       " 0.7359437006925508,\n",
       " 0.7357339341850029,\n",
       " 0.7353660672179104,\n",
       " 0.7349983841843014,\n",
       " 0.7347153935320273,\n",
       " 0.734627210928377,\n",
       " 0.7342598973229129,\n",
       " 0.7338927673742515,\n",
       " 0.7338083534546579,\n",
       " 0.7335551699482302,\n",
       " 0.7331883923632562,\n",
       " 0.7328217981670746,\n",
       " 0.7324553872679911,\n",
       " 0.7320891595743572,\n",
       " 0.7319646838764453,\n",
       " 0.7317963092658151,\n",
       " 0.7314304111111822,\n",
       " 0.7312255880626061,\n",
       " 0.7310464149461211,\n",
       " 0.730823424045032,\n",
       " 0.7304580123330096,\n",
       " 0.7302498094147519,\n",
       " 0.7298846845100446,\n",
       " 0.7295197421677896,\n",
       " 0.7293045117798116,\n",
       " 0.7289398595239217,\n",
       " 0.7285753895941598,\n",
       " 0.7282111018993627,\n",
       " 0.7278469963484131,\n",
       " 0.7276759296351544,\n",
       " 0.7273120916703368,\n",
       " 0.7271266043619057,\n",
       " 0.7269738856281522,\n",
       " 0.7266103986853383,\n",
       " 0.7262470934859956,\n",
       " 0.7258839699392526,\n",
       " 0.7257278826406245,\n",
       " 0.7253650186993041,\n",
       " 0.725216296931432,\n",
       " 0.7248536887829663,\n",
       " 0.7244912619385748,\n",
       " 0.7241290163076055,\n",
       " 0.7239008945633404,\n",
       " 0.7236619869581782,\n",
       " 0.7235063774539847,\n",
       " 0.7231446242652578,\n",
       " 0.7227830519531252,\n",
       " 0.7224216604271487,\n",
       " 0.7220604495969352,\n",
       " 0.7218618606291507,\n",
       " 0.7215731014447736,\n",
       " 0.7212123148940512,\n",
       " 0.7211005076963951,\n",
       " 0.7207399574425469,\n",
       " 0.7206246194397383,\n",
       " 0.7204372345496483,\n",
       " 0.7203075350931638,\n",
       " 0.7199473813256172,\n",
       " 0.7195874076349544,\n",
       " 0.7194038903623121,\n",
       " 0.7192348080419244,\n",
       " 0.7188751906379035,\n",
       " 0.7187709352279359,\n",
       " 0.7184115497603221,\n",
       " 0.7180523439854419,\n",
       " 0.7179158928877317,\n",
       " 0.7177830575235885,\n",
       " 0.7174241659948267,\n",
       " 0.7170654539118293,\n",
       " 0.7169435326654117,\n",
       " 0.716585060899079,\n",
       " 0.7162267683686295,\n",
       " 0.7158686549844453,\n",
       " 0.7155107206569531,\n",
       " 0.7153353981739993,\n",
       " 0.7149777304749123,\n",
       " 0.714620241609675,\n",
       " 0.7142629314888701,\n",
       " 0.7139058000231258,\n",
       " 0.7135488471231142,\n",
       " 0.7131920726995526,\n",
       " 0.7130208843448733,\n",
       " 0.7126643739027009,\n",
       " 0.7123080417157496,\n",
       " 0.7121477503636389,\n",
       " 0.7117916764884571,\n",
       " 0.7114357806502128,\n",
       " 0.7110800627598878,\n",
       " 0.7107636234285072,\n",
       " 0.710408241616793,\n",
       " 0.7100530374959846,\n",
       " 0.7096980109772366,\n",
       " 0.7093431619717481,\n",
       " 0.7091799910137344,\n",
       " 0.7088254010182277,\n",
       " 0.7084816181199387,\n",
       " 0.7081273773108788,\n",
       " 0.7079432420937524,\n",
       " 0.7075892704727055,\n",
       " 0.7072354758374693,\n",
       " 0.7071081530778676,\n",
       " 0.7067545990013286,\n",
       " 0.7064012217018281,\n",
       " 0.7060480210909772,\n",
       " 0.7056949970804317,\n",
       " 0.7053421495818916,\n",
       " 0.7049894785071007,\n",
       " 0.7048766610094547,\n",
       " 0.70452422267895,\n",
       " 0.7041719605676106,\n",
       " 0.7040135000855332,\n",
       " 0.7039430846510291,\n",
       " 0.7035911131087036,\n",
       " 0.7032709719479163,\n",
       " 0.7029193364619424,\n",
       " 0.7027717019917534,\n",
       " 0.7024484205421735,\n",
       " 0.7020971963319024,\n",
       " 0.7017461477337364,\n",
       " 0.7013952746598696,\n",
       " 0.7010445770225397,\n",
       " 0.7006940547340286,\n",
       " 0.7003437077066615,\n",
       " 0.7001966141969598,\n",
       " 0.6998465158898614,\n",
       " 0.6995525685934925,\n",
       " 0.6992027923091957,\n",
       " 0.6988531909130412,\n",
       " 0.6985037643175847,\n",
       " 0.6981545124354259,\n",
       " 0.6979380639711902,\n",
       " 0.6975890949392046,\n",
       " 0.6972403003917351,\n",
       " 0.6970555099964908,\n",
       " 0.6967069822414926,\n",
       " 0.6963586287503719,\n",
       " 0.6960104494359968,\n",
       " 0.6959060295931287,\n",
       " 0.6957772666951817,\n",
       " 0.6954293780618341,\n",
       " 0.695349388283746,\n",
       " 0.6950017135896043,\n",
       " 0.6948939697361537,\n",
       " 0.6945465227512857,\n",
       " 0.6944145384520433,\n",
       " 0.6940673311828173,\n",
       " 0.693720297517226,\n",
       " 0.6933734373684673,\n",
       " 0.6932520772936966,\n",
       " 0.6929054512550498,\n",
       " 0.6928188218289332,\n",
       " 0.6924724124180187,\n",
       " 0.6921261762118097,\n",
       " 0.6917801131237039,\n",
       " 0.6916521136405552,\n",
       " 0.691306287583735,\n",
       " 0.6909606344399432,\n",
       " 0.6906151541227232,\n",
       " 0.6905391716376784,\n",
       " 0.6904321195975812,\n",
       " 0.6900869035377825,\n",
       " 0.689817754840028,\n",
       " 0.689472845962608,\n",
       " 0.6891281095396268,\n",
       " 0.688783545484857,\n",
       " 0.6884391537121146,\n",
       " 0.6880949341352586,\n",
       " 0.6880157879806362,\n",
       " 0.687671780086646,\n",
       " 0.6873279441966027,\n",
       " 0.6869842802245044,\n",
       " 0.6868331225182361,\n",
       " 0.6866957352832423,\n",
       " 0.6863523874156008,\n",
       " 0.686009211221893,\n",
       " 0.6856662066162821,\n",
       " 0.685323373512974,\n",
       " 0.6849807118262176,\n",
       " 0.6848025954644713,\n",
       " 0.6844601941667391,\n",
       " 0.6841179640696557,\n",
       " 0.683775905087621,\n",
       " 0.683673320747653,\n",
       " 0.6833314840872792,\n",
       " 0.6829898183452356,\n",
       " 0.6826483234360631,\n",
       " 0.682306999274345,\n",
       " 0.682201223441134,\n",
       " 0.6818601228294134,\n",
       " 0.6817612355572249,\n",
       " 0.6814203549394464,\n",
       " 0.6810796447619767,\n",
       " 0.6807391049395958,\n",
       " 0.680398735387126,\n",
       " 0.6803170720212363,\n",
       " 0.6800891469956771,\n",
       " 0.6797491024221792,\n",
       " 0.6794092278709682,\n",
       " 0.6790695232570327,\n",
       " 0.6787299884954043,\n",
       " 0.6783906235011566,\n",
       " 0.678275278061038,\n",
       " 0.6779361404220076,\n",
       " 0.6775971723517966,\n",
       " 0.6772583737656207,\n",
       " 0.6769197445787379,\n",
       " 0.6765812847064486,\n",
       " 0.6762869622806316,\n",
       " 0.6759488187994912,\n",
       " 0.6756513923950291,\n",
       " 0.6755297556803175,\n",
       " 0.6753068119081003,\n",
       " 0.6749691585021462,\n",
       " 0.6746316739228951,\n",
       " 0.6745439555756866,\n",
       " 0.6742066835978988,\n",
       " 0.6741561073481457,\n",
       " 0.6740347398278185,\n",
       " 0.6739538402865376,\n",
       " 0.6736168633663943,\n",
       " 0.6735326454659719,\n",
       " 0.673195879143239,\n",
       " 0.6731016147507579,\n",
       " 0.6727650639433826,\n",
       " 0.6726641315187027,\n",
       " 0.6723277994529434,\n",
       " 0.6719916355532171,\n",
       " 0.67193786492945,\n",
       " 0.6718303365892322,\n",
       " 0.6717161065819556,\n",
       " 0.6713802485286646,\n",
       " 0.6710445584044004,\n",
       " 0.6707090361251982,\n",
       " 0.6703736816071356,\n",
       " 0.6700384947663321,\n",
       " 0.6697034755189489,\n",
       " 0.6693686237811896,\n",
       " 0.6692648537422171,\n",
       " 0.6689302213153461,\n",
       " 0.6685957562046884,\n",
       " 0.6685054793003217,\n",
       " 0.6681712265606715,\n",
       " 0.6679440301653841,\n",
       " 0.6676100581503014,\n",
       " 0.6672762531212263,\n",
       " 0.6671527875663533,\n",
       " 0.6670927315027684,\n",
       " 0.6669959858825064,\n",
       " 0.6669359439339669,\n",
       " 0.6667024988427273,\n",
       " 0.6663691475933059,\n",
       " 0.6660359630195093,\n",
       " 0.6659460317503076,\n",
       " 0.6656130587344325,\n",
       " 0.6653201802008566,\n",
       " 0.6649875201107561,\n",
       " 0.6647048898144386,\n",
       " 0.6643725373695314,\n",
       " 0.6640403511008467,\n",
       " 0.663837799042285,\n",
       " 0.6637315669329926,\n",
       " 0.6633997011495262,\n",
       " 0.6632670013019962,\n",
       " 0.6630613689938855,\n",
       " 0.6628160203373822,\n",
       " 0.6624846123272136,\n",
       " 0.6622593495354754,\n",
       " 0.6619282198607077,\n",
       " 0.661772646112993,\n",
       " 0.6614417597899366,\n",
       " 0.661276378674765,\n",
       " ...]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epsilon_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the diagram that illustrates the overall resulting data flow.\n",
    "\n",
    ".. figure:: /_static/img/reinforcement_learning_diagram.jpg\n",
    "\n",
    "Actions are chosen either randomly or based on a policy, getting the next\n",
    "step sample from the gym environment. We record the results in the\n",
    "replay memory and also run optimization step on every iteration.\n",
    "Optimization picks a random batch from the replay memory to do training of the\n",
    "new policy. The \"older\" target_net is also used in optimization to compute the\n",
    "expected Q values. A soft update of its weights are performed at every step.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('UNTIL',\n",
       " 'TRUE',\n",
       " ('AND',\n",
       "  ('UNTIL', 'TRUE', ('AND', 'TOUCHED', 'FLAG')),\n",
       "  ('NEXT', ('UNTIL', 'TRUE', ('AND', 'TOUCHED', 'FLAG')))))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.GOAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = {}\n",
    "if env.flag:\n",
    "    \n",
    "    sigma = {'FLAG'}\n",
    "else:\n",
    "    sigma = {}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LTL import prog\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('UNTIL', 'TRUE', ('AND', ('UNTIL', 'TRUE', ('AND', 'TOUCHED', 'FLAG')), ('NEXT', ('UNTIL', 'TRUE', ('AND', 'TOUCHED', 'FLAG')))))\n",
      "('UNTIL', 'TRUE', ('AND', 'TOUCHED', 'FLAG'))\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "T = (\"UNTIL\", \"TRUE\", (\"AND\", \"TOUCHED\", \"FLAG\"))\n",
    "META = (\"UNTIL\", \"TRUE\", (\"AND\", T, (\"NEXT\", T) ))\n",
    "\n",
    "print(META)\n",
    "print(prog({'TOUCHED', \"FLAG\"}, META))\n",
    "print(prog({'TOUCHED', \"FLAG\"},prog({'TOUCHED', \"FLAG\"}, META)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-10., -10.,   9., -10., -10.,   9.,   0.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLAG = False\n",
      "######################\n",
      "#P                  R#\n",
      "#                    #\n",
      "#                    #\n",
      "#                    #\n",
      "#                    #\n",
      "#                    #\n",
      "#                    #\n",
      "#                    #\n",
      "#                    #\n",
      "#                    #\n",
      "#         A          #\n",
      "#                    #\n",
      "#                    #\n",
      "#                    #\n",
      "#                    #\n",
      "#                    #\n",
      "#                    #\n",
      "#                    #\n",
      "#                    #\n",
      "#G                   #\n",
      "######################\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x7 and 8x128)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 6\u001b[0m\n\u001b[0;32m      2\u001b[0m state \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(state, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32, device\u001b[38;5;241m=\u001b[39mdevice)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m count():\n\u001b[1;32m----> 6\u001b[0m     action \u001b[38;5;241m=\u001b[39m \u001b[43mselect_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     observation, reward, terminated, info \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m      8\u001b[0m     env\u001b[38;5;241m.\u001b[39mrender()\n",
      "Cell \u001b[1;32mIn[7], line 44\u001b[0m, in \u001b[0;36mselect_action\u001b[1;34m(state)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample \u001b[38;5;241m>\u001b[39m eps_threshold:\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m     41\u001b[0m         \u001b[38;5;66;03m# t.max(1) will return the largest column value of each row.\u001b[39;00m\n\u001b[0;32m     42\u001b[0m         \u001b[38;5;66;03m# second column on max result is index of where max element was\u001b[39;00m\n\u001b[0;32m     43\u001b[0m         \u001b[38;5;66;03m# found, so we pick action with the larger expected reward.\u001b[39;00m\n\u001b[1;32m---> 44\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpolicy_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mtensor([[np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m4\u001b[39m)]], device\u001b[38;5;241m=\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[6], line 12\u001b[0m, in \u001b[0;36mDQN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 12\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     13\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer2(x))\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer3(x)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x7 and 8x128)"
     ]
    }
   ],
   "source": [
    "state = env.reset()\n",
    "state = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "\n",
    "\n",
    "for t in count():\n",
    "    action = select_action(state)\n",
    "    observation, reward, terminated, info = env.step(action.item())\n",
    "    env.render()\n",
    "    \n",
    "    next_state = torch.tensor(observation, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "\n",
    "    state = next_state\n",
    "    if t>100:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
