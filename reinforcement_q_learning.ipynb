{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For tips on running notebooks in Google Colab, see\n",
    "# https://pytorch.org/tutorials/beginner/colab\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Reinforcement Learning (DQN) Tutorial\n",
    "**Author**: [Adam Paszke](https://github.com/apaszke)\n",
    "            [Mark Towers](https://github.com/pseudo-rnd-thoughts)\n",
    "\n",
    "\n",
    "This tutorial shows how to use PyTorch to train a Deep Q Learning (DQN) agent\n",
    "on the CartPole-v1 task from [Gymnasium](https://www.gymnasium.farama.org)_.\n",
    "\n",
    "**Task**\n",
    "\n",
    "The agent has to decide between two actions - moving the cart left or\n",
    "right - so that the pole attached to it stays upright. You can find more\n",
    "information about the environment and other more challenging environments at\n",
    "[Gymnasium's website](https://gymnasium.farama.org/environments/classic_control/cart_pole/)_.\n",
    "\n",
    ".. figure:: /_static/img/cartpole.gif\n",
    "   :alt: CartPole\n",
    "\n",
    "   CartPole\n",
    "\n",
    "As the agent observes the current state of the environment and chooses\n",
    "an action, the environment *transitions* to a new state, and also\n",
    "returns a reward that indicates the consequences of the action. In this\n",
    "task, rewards are +1 for every incremental timestep and the environment\n",
    "terminates if the pole falls over too far or the cart moves more than 2.4\n",
    "units away from center. This means better performing scenarios will run\n",
    "for longer duration, accumulating larger return.\n",
    "\n",
    "The CartPole task is designed so that the inputs to the agent are 4 real\n",
    "values representing the environment state (position, velocity, etc.).\n",
    "We take these 4 inputs without any scaling and pass them through a \n",
    "small fully-connected network with 2 outputs, one for each action. \n",
    "The network is trained to predict the expected value for each action, \n",
    "given the input state. The action with the highest expected value is \n",
    "then chosen.\n",
    "\n",
    "\n",
    "**Packages**\n",
    "\n",
    "\n",
    "First, let's import needed packages. Firstly, we need\n",
    "[gymnasium](https://gymnasium.farama.org/)_ for the environment,\n",
    "installed by using `pip`. This is a fork of the original OpenAI\n",
    "Gym project and maintained by the same team since Gym v0.19.\n",
    "If you are running this in Google Colab, run:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'bash'\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip3 install gymnasium[classic_control]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also use the following from PyTorch:\n",
    "\n",
    "-  neural networks (``torch.nn``)\n",
    "-  optimization (``torch.optim``)\n",
    "-  automatic differentiation (``torch.autograd``)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from env import PacmanEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import math\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "env = PacmanEnv()\n",
    "\n",
    "# set up matplotlib\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "# if GPU is to be used\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replay Memory\n",
    "\n",
    "We'll be using experience replay memory for training our DQN. It stores\n",
    "the transitions that the agent observes, allowing us to reuse this data\n",
    "later. By sampling from it randomly, the transitions that build up a\n",
    "batch are decorrelated. It has been shown that this greatly stabilizes\n",
    "and improves the DQN training procedure.\n",
    "\n",
    "For this, we're going to need two classes:\n",
    "\n",
    "-  ``Transition`` - a named tuple representing a single transition in\n",
    "   our environment. It essentially maps (state, action) pairs\n",
    "   to their (next_state, reward) result, with the state being the\n",
    "   screen difference image as described later on.\n",
    "-  ``ReplayMemory`` - a cyclic buffer of bounded size that holds the\n",
    "   transitions observed recently. It also implements a ``.sample()``\n",
    "   method for selecting a random batch of transitions for training.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([], maxlen=capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Save a transition\"\"\"\n",
    "        self.memory.append(Transition(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's define our model. But first, let's quickly recap what a DQN is.\n",
    "\n",
    "## DQN algorithm\n",
    "\n",
    "Our environment is deterministic, so all equations presented here are\n",
    "also formulated deterministically for the sake of simplicity. In the\n",
    "reinforcement learning literature, they would also contain expectations\n",
    "over stochastic transitions in the environment.\n",
    "\n",
    "Our aim will be to train a policy that tries to maximize the discounted,\n",
    "cumulative reward\n",
    "$R_{t_0} = \\sum_{t=t_0}^{\\infty} \\gamma^{t - t_0} r_t$, where\n",
    "$R_{t_0}$ is also known as the *return*. The discount,\n",
    "$\\gamma$, should be a constant between $0$ and $1$\n",
    "that ensures the sum converges. A lower $\\gamma$ makes \n",
    "rewards from the uncertain far future less important for our agent \n",
    "than the ones in the near future that it can be fairly confident \n",
    "about. It also encourages agents to collect reward closer in time \n",
    "than equivalent rewards that are temporally far away in the future.\n",
    "\n",
    "The main idea behind Q-learning is that if we had a function\n",
    "$Q^*: State \\times Action \\rightarrow \\mathbb{R}$, that could tell\n",
    "us what our return would be, if we were to take an action in a given\n",
    "state, then we could easily construct a policy that maximizes our\n",
    "rewards:\n",
    "\n",
    "\\begin{align}\\pi^*(s) = \\arg\\!\\max_a \\ Q^*(s, a)\\end{align}\n",
    "\n",
    "However, we don't know everything about the world, so we don't have\n",
    "access to $Q^*$. But, since neural networks are universal function\n",
    "approximators, we can simply create one and train it to resemble\n",
    "$Q^*$.\n",
    "\n",
    "For our training update rule, we'll use a fact that every $Q$\n",
    "function for some policy obeys the Bellman equation:\n",
    "\n",
    "\\begin{align}Q^{\\pi}(s, a) = r + \\gamma Q^{\\pi}(s', \\pi(s'))\\end{align}\n",
    "\n",
    "The difference between the two sides of the equality is known as the\n",
    "temporal difference error, $\\delta$:\n",
    "\n",
    "\\begin{align}\\delta = Q(s, a) - (r + \\gamma \\max_a' Q(s', a))\\end{align}\n",
    "\n",
    "To minimize this error, we will use the [Huber\n",
    "loss](https://en.wikipedia.org/wiki/Huber_loss)_. The Huber loss acts\n",
    "like the mean squared error when the error is small, but like the mean\n",
    "absolute error when the error is large - this makes it more robust to\n",
    "outliers when the estimates of $Q$ are very noisy. We calculate\n",
    "this over a batch of transitions, $B$, sampled from the replay\n",
    "memory:\n",
    "\n",
    "\\begin{align}\\mathcal{L} = \\frac{1}{|B|}\\sum_{(s, a, s', r) \\ \\in \\ B} \\mathcal{L}(\\delta)\\end{align}\n",
    "\n",
    "\\begin{align}\\text{where} \\quad \\mathcal{L}(\\delta) = \\begin{cases}\n",
    "     \\frac{1}{2}{\\delta^2}  & \\text{for } |\\delta| \\le 1, \\\\\n",
    "     |\\delta| - \\frac{1}{2} & \\text{otherwise.}\n",
    "   \\end{cases}\\end{align}\n",
    "\n",
    "### Q-network\n",
    "\n",
    "Our model will be a feed forward  neural network that takes in the\n",
    "difference between the current and previous screen patches. It has two\n",
    "outputs, representing $Q(s, \\mathrm{left})$ and\n",
    "$Q(s, \\mathrm{right})$ (where $s$ is the input to the\n",
    "network). In effect, the network is trying to predict the *expected return* of\n",
    "taking each action given the current input.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "\n",
    "    def __init__(self, n_observations, n_actions):\n",
    "        super(DQN, self).__init__()\n",
    "        self.layer1 = nn.Linear(n_observations, 128)\n",
    "        self.layer2 = nn.Linear(128, 128)\n",
    "        self.layer3 = nn.Linear(128, n_actions)\n",
    "\n",
    "    # Called with either one element to determine next action, or a batch\n",
    "    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        return self.layer3(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "### Hyperparameters and utilities\n",
    "This cell instantiates our model and its optimizer, and defines some\n",
    "utilities:\n",
    "\n",
    "-  ``select_action`` - will select an action accordingly to an epsilon\n",
    "   greedy policy. Simply put, we'll sometimes use our model for choosing\n",
    "   the action, and sometimes we'll just sample one uniformly. The\n",
    "   probability of choosing a random action will start at ``EPS_START``\n",
    "   and will decay exponentially towards ``EPS_END``. ``EPS_DECAY``\n",
    "   controls the rate of the decay.\n",
    "-  ``plot_durations`` - a helper for plotting the duration of episodes,\n",
    "   along with an average over the last 100 episodes (the measure used in\n",
    "   the official evaluations). The plot will be underneath the cell\n",
    "   containing the main training loop, and will update after every\n",
    "   episode.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH_SIZE is the number of transitions sampled from the replay buffer\n",
    "# GAMMA is the discount factor as mentioned in the previous section\n",
    "# EPS_START is the starting value of epsilon\n",
    "# EPS_END is the final value of epsilon\n",
    "# EPS_DECAY controls the rate of exponential decay of epsilon, higher means a slower decay\n",
    "# TAU is the update rate of the target network\n",
    "# LR is the learning rate of the ``AdamW`` optimizer\n",
    "BATCH_SIZE = 128\n",
    "GAMMA = 0.99\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 10000\n",
    "TAU = 0.001\n",
    "LR = 1e-5\n",
    "\n",
    "# Get number of actions from gym action space\n",
    "n_actions = 4\n",
    "# Get the number of state observations\n",
    "state = env.reset()\n",
    "n_observations = len(state)\n",
    "\n",
    "policy_net = DQN(n_observations, n_actions).to(device)\n",
    "target_net = DQN(n_observations, n_actions).to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "optimizer = optim.AdamW(policy_net.parameters(), lr=LR, amsgrad=True)\n",
    "memory = ReplayMemory(10_000)\n",
    "\n",
    "\n",
    "steps_done = 0\n",
    "\n",
    "\n",
    "def select_action(state):\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    eps_threshold = 1*(0.993**(steps_done/100))\n",
    "    steps_done += 1\n",
    "    \n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            # t.max(1) will return the largest column value of each row.\n",
    "            # second column on max result is index of where max element was\n",
    "            # found, so we pick action with the larger expected reward.\n",
    "            return policy_net(state).max(1)[1].view(1, 1)\n",
    "    else:\n",
    "        return torch.tensor([[np.random.randint(4)]], device=device, dtype=torch.long)\n",
    "\n",
    "\n",
    "episode_durations = []\n",
    "epsilon_values = []\n",
    "\n",
    "def plot_durations(show_result=False):\n",
    "    plt.figure(1)\n",
    "    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
    "    if show_result:\n",
    "        plt.title('Result')\n",
    "    else:\n",
    "        plt.clf()\n",
    "        plt.title('Training...')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Duration')\n",
    "    plt.plot(durations_t.numpy())\n",
    "    plt.plot(epsilon_values)\n",
    "    # Take 100 episode averages and plot them too\n",
    "    if len(durations_t) >= 100:\n",
    "        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n",
    "        means = torch.cat((torch.zeros(99), means))\n",
    "        plt.plot(means.numpy())\n",
    "\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "    if is_ipython:\n",
    "        if not show_result:\n",
    "            display.display(plt.gcf())\n",
    "            display.clear_output(wait=True)\n",
    "        else:\n",
    "            display.display(plt.gcf())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop\n",
    "\n",
    "Finally, the code for training our model.\n",
    "\n",
    "Here, you can find an ``optimize_model`` function that performs a\n",
    "single step of the optimization. It first samples a batch, concatenates\n",
    "all the tensors into a single one, computes $Q(s_t, a_t)$ and\n",
    "$V(s_{t+1}) = \\max_a Q(s_{t+1}, a)$, and combines them into our\n",
    "loss. By definition we set $V(s) = 0$ if $s$ is a terminal\n",
    "state. We also use a target network to compute $V(s_{t+1})$ for\n",
    "added stability. The target network is updated at every step with a \n",
    "[soft update](https://arxiv.org/pdf/1509.02971.pdf)_ controlled by \n",
    "the hyperparameter ``TAU``, which was previously defined.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
    "    # detailed explanation). This converts batch-array of Transitions\n",
    "    # to Transition of batch-arrays.\n",
    "    batch = Transition(*zip(*transitions))\n",
    "\n",
    "    # Compute a mask of non-final states and concatenate the batch elements\n",
    "    # (a final state would've been the one after which simulation ended)\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                          batch.next_state)), device=device, dtype=torch.bool)\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                                if s is not None])\n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
    "    # columns of actions taken. These are the actions which would've been taken\n",
    "    # for each batch state according to policy_net\n",
    "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
    "\n",
    "    # Compute V(s_{t+1}) for all next states.\n",
    "    # Expected values of actions for non_final_next_states are computed based\n",
    "    # on the \"older\" target_net; selecting their best reward with max(1)[0].\n",
    "    # This is merged based on the mask, such that we'll have either the expected\n",
    "    # state value or 0 in case the state was final.\n",
    "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
    "    with torch.no_grad():\n",
    "        next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0]\n",
    "    # Compute the expected Q values\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "\n",
    "    # Compute Huber loss\n",
    "    criterion = nn.SmoothL1Loss()\n",
    "    loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "    # Optimize the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    # In-place gradient clipping\n",
    "    torch.nn.utils.clip_grad_value_(policy_net.parameters(), 100)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, you can find the main training loop. At the beginning we reset\n",
    "the environment and obtain the initial ``state`` Tensor. Then, we sample\n",
    "an action, execute it, observe the next state and the reward (always\n",
    "1), and optimize our model once. When the episode ends (our model\n",
    "fails), we restart the loop.\n",
    "\n",
    "Below, `num_episodes` is set to 600 if a GPU is available, otherwise 50 \n",
    "episodes are scheduled so training does not take too long. However, 50 \n",
    "episodes is insufficient for to observe good performance on CartPole.\n",
    "You should see the model constantly achieve 500 steps within 600 training \n",
    "episodes. Training RL agents can be a noisy process, so restarting training\n",
    "can produce better results if convergence is not observed.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    num_episodes = 1000\n",
    "else:\n",
    "    num_episodes = 50\n",
    "\n",
    "for i_episode in range(num_episodes):\n",
    "    # Initialize the environment and get it's state\n",
    "    state = env.reset()\n",
    "    state = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "    \n",
    "    r_sum = 0\n",
    "    for t in range(100):\n",
    "        \n",
    "        action = select_action(state)\n",
    "        observation, reward, terminated, info = env.step(action.item())\n",
    "        \n",
    "        #if i_episode %100==0:\n",
    "        #    env.render()\n",
    "        \n",
    "        r = 0\n",
    "        if info['E'] == 1:\n",
    "            r = 1\n",
    "        reward = torch.tensor([r], device=device)\n",
    "        r_sum +=r\n",
    "        done = terminated or t==99 or r==1\n",
    "\n",
    "        if terminated:\n",
    "            next_state = None\n",
    "        else:\n",
    "            next_state = torch.tensor(observation, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "\n",
    "        # Store the transition in memory\n",
    "        memory.push(state, action, next_state, reward)\n",
    "\n",
    "        # Move to the next state\n",
    "        state = next_state\n",
    "\n",
    "        # Perform one step of the optimization (on the policy network)\n",
    "        optimize_model()\n",
    "\n",
    "        # Soft update of the target network's weights\n",
    "        #     + (1  )\n",
    "        target_net_state_dict = target_net.state_dict()\n",
    "        policy_net_state_dict = policy_net.state_dict()\n",
    "        for key in policy_net_state_dict:\n",
    "            target_net_state_dict[key] = policy_net_state_dict[key]*TAU + target_net_state_dict[key]*(1-TAU)\n",
    "        target_net.load_state_dict(target_net_state_dict)\n",
    "\n",
    "        if done:\n",
    "            episode_durations.append(r_sum)\n",
    "            epsilon_values.append(1*(0.993**(steps_done/100)))\n",
    "            if i_episode%100==0:\n",
    "                plot_durations()\n",
    "                pass\n",
    "            break\n",
    "\n",
    "print('Complete')\n",
    "plot_durations(show_result=True)\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.993,\n",
       " 0.986049,\n",
       " 0.979146657,\n",
       " 0.972292630401,\n",
       " 0.9654865819881929,\n",
       " 0.9587281759142756,\n",
       " 0.954025460172936,\n",
       " 0.9473472819517255,\n",
       " 0.9407158509780634,\n",
       " 0.9341308400212169,\n",
       " 0.9275919241410684,\n",
       " 0.921098780672081,\n",
       " 0.9146510892073764,\n",
       " 0.9082485315829247,\n",
       " 0.9018907918618443,\n",
       " 0.8955775563188113,\n",
       " 0.8893085134245796,\n",
       " 0.8830833538306075,\n",
       " 0.8769017703537934,\n",
       " 0.8707634579613168,\n",
       " 0.8661879380243667,\n",
       " 0.8651541671601084,\n",
       " 0.8590980879899877,\n",
       " 0.8530844013740577,\n",
       " 0.8471128105644393,\n",
       " 0.8411830208904882,\n",
       " 0.8352947397442548,\n",
       " 0.829447676566045,\n",
       " 0.8236415428300827,\n",
       " 0.8178760520302721,\n",
       " 0.8121509196660602,\n",
       " 0.8064658632283978,\n",
       " 0.800820602185799,\n",
       " 0.7956059795962338,\n",
       " 0.7900367377390601,\n",
       " 0.7845064805748867,\n",
       " 0.7790149352108625,\n",
       " 0.7735618306643864,\n",
       " 0.7681468978497358,\n",
       " 0.7637886005295217,\n",
       " 0.7584420803258151,\n",
       " 0.7531329857635344,\n",
       " 0.7478610548631897,\n",
       " 0.7432000820461331,\n",
       " 0.7379976814718101,\n",
       " 0.7328316977015075,\n",
       " 0.7277018758175969,\n",
       " 0.723674718280423,\n",
       " 0.7186089952524599,\n",
       " 0.7135787322856927,\n",
       " 0.7085836811596928,\n",
       " 0.703623595391575,\n",
       " 0.698698230223834,\n",
       " 0.6938073426122672,\n",
       " 0.6889506912139812,\n",
       " 0.6841280363754834,\n",
       " 0.6793391401208551,\n",
       " 0.674583766140009,\n",
       " 0.6740153627985594,\n",
       " 0.6692972552589695,\n",
       " 0.6646121744721568,\n",
       " 0.6599598892508517,\n",
       " 0.6553401700260957,\n",
       " 0.650752788835913,\n",
       " 0.6475607418504775,\n",
       " 0.6430278166575242,\n",
       " 0.6385266219409215,\n",
       " 0.6354391818564059,\n",
       " 0.630991107583411,\n",
       " 0.6265741698303271,\n",
       " 0.623544522919168,\n",
       " 0.6191797112587337,\n",
       " 0.6160992551712299,\n",
       " 0.6122164678651099,\n",
       " 0.6116576470187003,\n",
       " 0.6073760434895694,\n",
       " 0.6031244111851424,\n",
       " 0.5989025403068464,\n",
       " 0.5947102225246984,\n",
       " 0.5905472509670255,\n",
       " 0.5871966151595334,\n",
       " 0.5837009561033881,\n",
       " 0.5831271998551061,\n",
       " 0.5801445955940271,\n",
       " 0.5793301093948273,\n",
       " 0.5761240524997012,\n",
       " 0.5720911841322033,\n",
       " 0.5688452640071582,\n",
       " 0.564863347159108,\n",
       " 0.5618952121472991,\n",
       " 0.5589034113275899,\n",
       " 0.5564354451683367,\n",
       " 0.55397837687952,\n",
       " 0.5534727147784335,\n",
       " 0.5527345003140001,\n",
       " 0.5492896351692518,\n",
       " 0.545444607723067,\n",
       " 0.5450233013001194,\n",
       " 0.5429216454753695,\n",
       " 0.5392726999931525,\n",
       " 0.5369291336201748,\n",
       " 0.5345206505861518,\n",
       " 0.534107781927994,\n",
       " 0.5318613783877019,\n",
       " 0.5281383487389879,\n",
       " 0.5275821465434175,\n",
       " 0.524662466811187,\n",
       " 0.5240362969605696,\n",
       " 0.5215390818049063,\n",
       " 0.5201853057188419,\n",
       " 0.5165440085788101,\n",
       " 0.5129282005187584,\n",
       " 0.5099463096473906,\n",
       " 0.5094092661667835,\n",
       " 0.50755189049386,\n",
       " 0.5054526832161012,\n",
       " 0.5033621581465608,\n",
       " 0.5015620626204782,\n",
       " 0.5012450676034728,\n",
       " 0.49882141906524796,\n",
       " 0.4961654535076403,\n",
       " 0.49390512644465784,\n",
       " 0.49044779055954524,\n",
       " 0.4886938786707093,\n",
       " 0.48838501654591004,\n",
       " 0.48626259740276095,\n",
       " 0.4842854594882877,\n",
       " 0.4817745712451688,\n",
       " 0.48126719647312965,\n",
       " 0.4796134929791335,\n",
       " 0.4780997916545655,\n",
       " 0.4758549057189691,\n",
       " 0.4754205534021991,\n",
       " 0.47328797711755094,\n",
       " 0.4727895398943529,\n",
       " 0.4721257733811517,\n",
       " 0.47182738255633583,\n",
       " 0.47142982146119267,\n",
       " 0.4711318704888041,\n",
       " 0.47070182927878057,\n",
       " 0.46747258815904613,\n",
       " 0.4642002800419328,\n",
       " 0.46101564267946393,\n",
       " 0.45856097328942547,\n",
       " 0.4581424065819379,\n",
       " 0.45778853318070767,\n",
       " 0.4562475542679982,\n",
       " 0.45356331223520485,\n",
       " 0.45321297576849057,\n",
       " 0.4529265381256389,\n",
       " 0.4498508432389518,\n",
       " 0.4493455226343086,\n",
       " 0.4481791417356477,\n",
       " 0.4478958855541221,\n",
       " 0.44516695522938265,\n",
       " 0.4448231041859099,\n",
       " 0.44447951873614017,\n",
       " 0.44413619867492643,\n",
       " 0.4437307986579519,\n",
       " 0.4415232114016446,\n",
       " 0.44112019647529777,\n",
       " 0.4407794711854416,\n",
       " 0.44025341332331763,\n",
       " 0.4380938995956235,\n",
       " 0.43582250201321604,\n",
       " 0.43521063487546047,\n",
       " 0.4338065984664443,\n",
       " 0.43201239774392414,\n",
       " 0.43167870740143033,\n",
       " 0.43116351104410156,\n",
       " 0.42959143006785294,\n",
       " 0.4276343870521752,\n",
       " 0.42535745554953924,\n",
       " 0.42377677451143336,\n",
       " 0.422231626584207,\n",
       " 0.4207512206310631,\n",
       " 0.4192465537076683,\n",
       " 0.41892272382031637,\n",
       " 0.41842275136947743,\n",
       " 0.41809955779461516,\n",
       " 0.41754190222660625,\n",
       " 0.41628258455599815,\n",
       " 0.41596104406563233,\n",
       " 0.41473562686355264,\n",
       " 0.41328150298383143,\n",
       " 0.4129042666116898,\n",
       " 0.4113987613313838,\n",
       " 0.41108099315091706,\n",
       " 0.409697238216166,\n",
       " 0.40745856392400287,\n",
       " 0.4071438391881901,\n",
       " 0.40671506082394115,\n",
       " 0.40543143320440345,\n",
       " 0.40378295383833845,\n",
       " 0.40341438758134684,\n",
       " 0.4018023335741125,\n",
       " 0.4014919777625541,\n",
       " 0.4009846397990618,\n",
       " 0.4006186277958383,\n",
       " 0.40025294988218635,\n",
       " 0.39865352905926194,\n",
       " 0.39837358864096517,\n",
       " 0.396224621494799,\n",
       " 0.3959742013773513,\n",
       " 0.3956127628176509,\n",
       " 0.3952794200549094,\n",
       " 0.3934510491443354,\n",
       " 0.3931471439415469,\n",
       " 0.3928986688377316,\n",
       " 0.39254003757216194,\n",
       " 0.39113625789980083,\n",
       " 0.3894091060725098,\n",
       " 0.38916299346671057,\n",
       " 0.38891703640790243,\n",
       " 0.38752621310916063,\n",
       " 0.38603187934199623,\n",
       " 0.38570660941832224,\n",
       " 0.38540868609188295,\n",
       " 0.38492167148450834,\n",
       " 0.3836259724099132,\n",
       " 0.3832219615884273,\n",
       " 0.38287216305771427,\n",
       " 0.38195881416371946,\n",
       " 0.3810208778914413,\n",
       " 0.3783537317462012,\n",
       " 0.3778225471152258,\n",
       " 0.377504194363448,\n",
       " 0.3767094855553181,\n",
       " 0.37647139930701645,\n",
       " 0.37501969383439165,\n",
       " 0.37467738219507957,\n",
       " 0.3742039280027722,\n",
       " 0.37362607415939514,\n",
       " 0.37320637737202156,\n",
       " 0.37297050514252417,\n",
       " 0.3711410248897753,\n",
       " 0.37064600198150427,\n",
       " 0.36942430648957414,\n",
       " 0.3691389597634112,\n",
       " 0.3680256266764539,\n",
       " 0.3677155287961878,\n",
       " 0.3672766706877825,\n",
       " 0.36686410622982346,\n",
       " 0.3658861220527931,\n",
       " 0.36542377677489535,\n",
       " 0.3645008381831987,\n",
       " 0.36411696875396904,\n",
       " 0.3636313144373196,\n",
       " 0.3631973307235142,\n",
       " 0.3623309165197002,\n",
       " 0.36200018698190134,\n",
       " 0.36169516612872654,\n",
       " 0.3606296156768115,\n",
       " 0.36024982317640686,\n",
       " 0.3591380710131368,\n",
       " 0.35891109017185596,\n",
       " 0.35858348219375796,\n",
       " 0.3583568518612284,\n",
       " 0.3581303647625904,\n",
       " 0.357803469417453,\n",
       " 0.35732623596132107,\n",
       " 0.3571004002279459,\n",
       " 0.3565990539257942,\n",
       " 0.3563736777827647,\n",
       " 0.35607339781840164,\n",
       " 0.3557483800379315,\n",
       " 0.355149126430758,\n",
       " 0.35475018492824945,\n",
       " 0.3543268005919292,\n",
       " 0.3538542042699261,\n",
       " 0.3524401939977837,\n",
       " 0.3522174463188503,\n",
       " 0.3519948394199112,\n",
       " 0.3516982490586517,\n",
       " 0.3513278625135887,\n",
       " 0.3510564936469034,\n",
       " 0.3496045429002496,\n",
       " 0.34923636131524116,\n",
       " 0.3480852346716083,\n",
       " 0.34781637044043995,\n",
       " 0.3474744799334804,\n",
       " 0.34715731109994785,\n",
       " 0.3469379022850931,\n",
       " 0.34666992426399423,\n",
       " 0.34637782066882583,\n",
       " 0.3460616528473384,\n",
       " 0.34574577361849573,\n",
       " 0.34547871640852434,\n",
       " 0.3451633692742124,\n",
       " 0.34489676191870383,\n",
       " 0.3446545702992579,\n",
       " 0.3443399754315877,\n",
       " 0.3440256677207965,\n",
       " 0.3429880770018932,\n",
       " 0.3426268634639284,\n",
       " 0.3423141194527925,\n",
       " 0.3419536156846625,\n",
       " 0.3416654860445318,\n",
       " 0.3413536195624587,\n",
       " 0.3401806792966448,\n",
       " 0.3399417993803338,\n",
       " 0.3396315062503203,\n",
       " 0.33932149635063236,\n",
       " 0.33882130877312017,\n",
       " 0.33763335161648195,\n",
       " 0.3372777773395614,\n",
       " 0.33704093588404127,\n",
       " 0.33675694566106573,\n",
       " 0.33654411003877244,\n",
       " 0.3344701253300857,\n",
       " 0.33404747829942866,\n",
       " 0.3337894569601685,\n",
       " 0.33353163491895965,\n",
       " 0.33177905718820805,\n",
       " 0.3314762148713305,\n",
       " 0.33117364898380225,\n",
       " 0.33087135927330324,\n",
       " 0.3302908082178193,\n",
       " 0.3290171789999556,\n",
       " 0.32871685767881703,\n",
       " 0.3280709424922431,\n",
       " 0.32781753748411324,\n",
       " 0.32756432820833836,\n",
       " 0.3273113145137328,\n",
       " 0.327058496249228,\n",
       " 0.3266911091484539,\n",
       " 0.3264846352912427,\n",
       " 0.3262782919287175,\n",
       " 0.3258888879933485,\n",
       " 0.3256371684241479,\n",
       " 0.3253399323195463,\n",
       " 0.32513431242708596,\n",
       " 0.3247006526532462,\n",
       " 0.32374408767927954,\n",
       " 0.3234485795467919,\n",
       " 0.3232441550186724,\n",
       " 0.32247304988238157,\n",
       " 0.32222396873790005,\n",
       " 0.3219750799859814,\n",
       " 0.3216585905027942,\n",
       " 0.32131983984268986,\n",
       " 0.32091380992875757,\n",
       " 0.3206659331555322,\n",
       " 0.32046326730316965,\n",
       " 0.3202607295387748,\n",
       " 0.3199234510181944,\n",
       " 0.31972125442607957,\n",
       " 0.3193845440468638,\n",
       " 0.31913784849264637,\n",
       " 0.3169038835531979,\n",
       " 0.3166591040839217,\n",
       " 0.3164589706097918,\n",
       " 0.31557101773466123,\n",
       " 0.31356019552628833,\n",
       " 0.3133400089083398,\n",
       " 0.31314197315393394,\n",
       " 0.3122194599376832,\n",
       " 0.31189064997807353,\n",
       " 0.3116497427764393,\n",
       " 0.31136527415760434,\n",
       " 0.3111247727610775,\n",
       " 0.3108844571300375,\n",
       " 0.31064432712099727,\n",
       " 0.310382578643787,\n",
       " 0.310055703172387,\n",
       " 0.30981621330051284,\n",
       " 0.309620404639685,\n",
       " 0.3094247197329733,\n",
       " 0.3090988530185222,\n",
       " 0.3088601022264921,\n",
       " 0.30853483013179817,\n",
       " 0.30829651499622435,\n",
       " 0.3077555740469195,\n",
       " 0.3075610677421188,\n",
       " 0.3072803311967632,\n",
       " 0.306956722817869,\n",
       " 0.30676272139945787,\n",
       " 0.30654730806861635,\n",
       " 0.30626749686595983,\n",
       " 0.30607393104905967,\n",
       " 0.3057086404483279,\n",
       " 0.30472239142924523,\n",
       " 0.3043800946315407,\n",
       " 0.3038887165081418,\n",
       " 0.3031850809784008,\n",
       " 0.3029934632962371,\n",
       " 0.3027381614262256,\n",
       " 0.3025468262041633,\n",
       " 0.3015072316769281,\n",
       " 0.30121086132449343,\n",
       " 0.30102049137982706,\n",
       " 0.3008091103280361,\n",
       " 0.300618994296242,\n",
       " 0.3004289984207342,\n",
       " 0.30019694430399674,\n",
       " 0.29983866772112416,\n",
       " 0.2996491650241367,\n",
       " 0.2983469524202902,\n",
       " 0.2980327521158167,\n",
       " 0.29780254888172614,\n",
       " 0.2975725234587271,\n",
       " 0.2967375641044201,\n",
       " 0.2965500213531044,\n",
       " 0.29636259713172153,\n",
       " 0.2961128824203014,\n",
       " 0.2959257344775165,\n",
       " 0.29449485760681005,\n",
       " 0.2942467166501113,\n",
       " 0.2925772252022544,\n",
       " 0.29239231184976944,\n",
       " 0.2922075153653966,\n",
       " 0.29202283567527326,\n",
       " 0.29146949663247584,\n",
       " 0.2912443629171804,\n",
       " 0.29106029195437016,\n",
       " 0.2900194184582444,\n",
       " 0.28979540479664456,\n",
       " 0.2895715641652536,\n",
       " 0.2893885504372469,\n",
       " 0.2891650240638987,\n",
       " 0.2889416703443735,\n",
       " 0.288718489145312,\n",
       " 0.2885360145739733,\n",
       " 0.2883536553293991,\n",
       " 0.28817141133870094,\n",
       " 0.2879892825290367,\n",
       " 0.28780726882761015,\n",
       " 0.28762537016167117,\n",
       " 0.28744358645851537,\n",
       " 0.28722156239320173,\n",
       " 0.28699970982131473,\n",
       " 0.2851108541700751,\n",
       " 0.28485060980029603,\n",
       " 0.28407130110382095,\n",
       " 0.28263817445394274,\n",
       " 0.28238018710442436,\n",
       " 0.2822017184384621,\n",
       " 0.28042322375449497,\n",
       " 0.2802459919197777,\n",
       " 0.27975426877165904,\n",
       " 0.27838202913532545,\n",
       " 0.2782060873673242,\n",
       " 0.27799119843112174,\n",
       " 0.2778155036741985,\n",
       " 0.2776399199590916,\n",
       " 0.2773864949318138,\n",
       " 0.27709436886698435,\n",
       " 0.275890174690223,\n",
       " 0.2739589434673914,\n",
       " 0.2737857971582596,\n",
       " 0.27361276028028564,\n",
       " 0.2734398327643072,\n",
       " 0.27326701454120594,\n",
       " 0.27294087806966855,\n",
       " 0.27103029192318084,\n",
       " 0.2708209456372632,\n",
       " 0.27061176105233903,\n",
       " 0.2697197909062334,\n",
       " 0.26954932380738955,\n",
       " 0.26926545135981184,\n",
       " 0.26905746825294913,\n",
       " 0.2688496457941477,\n",
       " 0.26721160451074666,\n",
       " 0.26704272262467776,\n",
       " 0.26687394747458504,\n",
       " 0.26619991288543887,\n",
       " 0.2659942976286397,\n",
       " 0.26575150252863317,\n",
       " 0.26554623362811064,\n",
       " 0.2653411232791714,\n",
       " 0.265173423566305,\n",
       " 0.26500582984226295,\n",
       " 0.26478253629927145,\n",
       " 0.2646151896220559,\n",
       " 0.2643736533485331,\n",
       " 0.2642065650916957,\n",
       " 0.2639654018037391,\n",
       " 0.2631138209710256,\n",
       " 0.2628921216320729,\n",
       " 0.2622649874298498,\n",
       " 0.2618232054047683,\n",
       " 0.26162097075701146,\n",
       " 0.26145562223834395,\n",
       " 0.26125367151519974,\n",
       " 0.26108855513536033,\n",
       " 0.26092354311163857,\n",
       " 0.25909707830985707,\n",
       " 0.25882421351190044,\n",
       " 0.25864246331200424,\n",
       " 0.25840637884212797,\n",
       " 0.25820678338257935,\n",
       " 0.2579710965939804,\n",
       " 0.2578080548524968,\n",
       " 0.2576089215438912,\n",
       " 0.25740994204768153,\n",
       " 0.25717498260238775,\n",
       " 0.25694023762410517,\n",
       " 0.2567417746254945,\n",
       " 0.25654346492152624,\n",
       " 0.2563813254654427,\n",
       " 0.255554211680302,\n",
       " 0.2553926974476382,\n",
       " 0.2548550535506321,\n",
       " 0.25439001111648496,\n",
       " 0.2533378677342482,\n",
       " 0.25310662520957633,\n",
       " 0.25284006918123425,\n",
       " 0.2522014794883738,\n",
       " 0.2520066767500556,\n",
       " 0.25184740461459043,\n",
       " 0.2516528753669557,\n",
       " 0.25145849637549783,\n",
       " 0.2512995706985472,\n",
       " 0.2509820206116559,\n",
       " 0.2507881597945704,\n",
       " 0.2504712559426748,\n",
       " 0.25031295421701777,\n",
       " 0.25004934030780696,\n",
       " 0.2498561999015515,\n",
       " 0.2496281353844428,\n",
       " 0.24943532032073742,\n",
       " 0.24913762630383313,\n",
       " 0.2473936629197063,\n",
       " 0.24723730628066035,\n",
       " 0.24708104846143983,\n",
       " 0.246924889399589,\n",
       " 0.24676882903269182,\n",
       " 0.24661286729837134,\n",
       " 0.2456101423247935,\n",
       " 0.24538595353728943,\n",
       " 0.24521363988277478,\n",
       " 0.24452559442735422,\n",
       " 0.24437105045216043,\n",
       " 0.2441136941834481,\n",
       " 0.24389087132851994,\n",
       " 0.24344583559982352,\n",
       " 0.24329197404898634,\n",
       " 0.24313820974104003,\n",
       " 0.2429845426145256,\n",
       " 0.24194557775733944,\n",
       " 0.24174171475062475,\n",
       " 0.24153802351859546,\n",
       " 0.2413853677346378,\n",
       " 0.24118197676010772,\n",
       " 0.24102954600323379,\n",
       " 0.24080953830664745,\n",
       " 0.23962832883047927,\n",
       " 0.2394432377091683,\n",
       " 0.23925828955393888,\n",
       " 0.2379676462523752,\n",
       " 0.23781724700232745,\n",
       " 0.23763355477724885,\n",
       " 0.23688356289442294,\n",
       " 0.236517762145131,\n",
       " 0.23628527401496524,\n",
       " 0.2361027650998877,\n",
       " 0.2359203971563719,\n",
       " 0.2357050530045167,\n",
       " 0.23555608374855846,\n",
       " 0.23537413806673765,\n",
       " 0.2351262567820595,\n",
       " 0.23405511763348508,\n",
       " 0.2335623928734731,\n",
       " 0.23275983880789067,\n",
       " 0.23251471073928015,\n",
       " 0.23236775782920607,\n",
       " 0.23220458574471736,\n",
       " 0.23202522879072618,\n",
       " 0.23187858524084934,\n",
       " 0.23173203437197462,\n",
       " 0.23158557612552616,\n",
       " 0.23075739277335722,\n",
       " 0.2304981813769696,\n",
       " 0.23032014246537919,\n",
       " 0.23017457655655413,\n",
       " 0.23002910264764534,\n",
       " 0.2298514260567723,\n",
       " 0.22969002097775978,\n",
       " 0.2295126062966818,\n",
       " 0.22933532865233242,\n",
       " 0.22915818793886317,\n",
       " 0.2289811840505074,\n",
       " 0.22878824482386675,\n",
       " 0.22864364709815424,\n",
       " 0.2284670406458681,\n",
       " 0.2282584997918861,\n",
       " 0.22805014929047165,\n",
       " 0.2275380963867761,\n",
       " 0.2271548113665755,\n",
       " 0.22694746829330517,\n",
       " 0.22677217198510116,\n",
       " 0.22662884844874912,\n",
       " 0.22642198546554226,\n",
       " 0.22621531130337078,\n",
       " 0.2259929500977565,\n",
       " 0.2258342544977658,\n",
       " 0.22569152373983942,\n",
       " 0.2254855163307876,\n",
       " 0.22531134924770213,\n",
       " 0.2250740654612895,\n",
       " 0.22493181515464625,\n",
       " 0.224758075755433,\n",
       " 0.22458447055412686,\n",
       " 0.22444252967907244,\n",
       " 0.22423766233069328,\n",
       " 0.22406445910149458,\n",
       " 0.2238913896560603,\n",
       " 0.22371845389105477,\n",
       " 0.22357706035198782,\n",
       " 0.22340436737782265,\n",
       " 0.2232631723463125,\n",
       " 0.22302804557139538,\n",
       " 0.22285577666128747,\n",
       " 0.22248037894892272,\n",
       " 0.22233976789245677,\n",
       " 0.2221992457043634,\n",
       " 0.22202761696688234,\n",
       " 0.22188729206302418,\n",
       " 0.22166918513874329,\n",
       " 0.2209851009830999,\n",
       " 0.22084543496554246,\n",
       " 0.2207058572190783,\n",
       " 0.2205353819885747,\n",
       " 0.2202721792326487,\n",
       " 0.21997838316198437,\n",
       " 0.21942279112867155,\n",
       " 0.2191917088024679,\n",
       " 0.21905317623663492,\n",
       " 0.2183464870836116,\n",
       " 0.21814718409990047,\n",
       " 0.21794806303658498,\n",
       " 0.21773382822737203,\n",
       " 0.21759621706471552,\n",
       " 0.217428143748818,\n",
       " 0.21726020025429277,\n",
       " 0.21712288843187466,\n",
       " 0.21697042152068777,\n",
       " 0.21680283157501412,\n",
       " 0.216665808816708,\n",
       " 0.21649845415668365,\n",
       " 0.21590614674257627,\n",
       " 0.2157393788525127,\n",
       " 0.214847092403248,\n",
       " 0.2146208289160539,\n",
       " 0.21445505381728058,\n",
       " 0.21431951489099788,\n",
       " 0.21415397252994403,\n",
       " 0.21397352669107178,\n",
       " 0.21380825157448016,\n",
       " 0.21362809703960337,\n",
       " 0.21346308873604605,\n",
       " 0.21326824323582513,\n",
       " 0.21308854371122204,\n",
       " 0.2129239521636095,\n",
       " 0.21278938091736263,\n",
       " 0.21262502044583872,\n",
       " 0.21243093992019113,\n",
       " 0.21229668026534268,\n",
       " 0.21214760238908076,\n",
       " 0.21198373763318454,\n",
       " 0.2117902424596517,\n",
       " 0.21162665373184605,\n",
       " 0.2114929023983659,\n",
       " 0.2113443889468385,\n",
       " 0.2112108160090884,\n",
       " 0.21104767483559306,\n",
       " 0.21088465967383804,\n",
       " 0.2106625691723572,\n",
       " 0.2105294271552989,\n",
       " 0.21039636928606417,\n",
       " 0.21023385719869553,\n",
       " 0.21004195928645317,\n",
       " 0.2097912801344468,\n",
       " 0.20965868878559882,\n",
       " 0.20934963476816723,\n",
       " 0.20918793118815068,\n",
       " 0.20893827129458303,\n",
       " 0.20880621906057617,\n",
       " 0.20858631744243472,\n",
       " 0.20842520345572885,\n",
       " 0.208001044666223,\n",
       " 0.20683542116014836,\n",
       " 0.20664662528289396,\n",
       " 0.206458001735326,\n",
       " 0.20629853167921322,\n",
       " 0.20608127100019435,\n",
       " 0.20563299038404914,\n",
       " 0.20547415757427884,\n",
       " 0.20534429471396967,\n",
       " 0.20515685991173777,\n",
       " 0.20499839486951585,\n",
       " 0.2048400522271474,\n",
       " 0.2046530776889366,\n",
       " 0.20450936726372315,\n",
       " 0.2043801141658815,\n",
       " 0.20422224908920528,\n",
       " 0.20409317745451125,\n",
       " 0.20396418739509592,\n",
       " 0.2038066435840762,\n",
       " 0.20367783461851924,\n",
       " 0.20354910706222998,\n",
       " 0.20339188386307042,\n",
       " 0.2032347821045534,\n",
       " 0.20306353676031988,\n",
       " 0.20293519744982216,\n",
       " 0.20269300001754822,\n",
       " 0.20256489489202945,\n",
       " 0.20235156624518258,\n",
       " 0.20216686315492471,\n",
       " 0.20199651763771023,\n",
       " 0.20186885269987767,\n",
       " 0.20171292734461463,\n",
       " 0.20155712242752766,\n",
       " 0.20142973519429538,\n",
       " 0.20124587353584336,\n",
       " 0.2010621797032062,\n",
       " 0.20058254201424625,\n",
       " 0.2004416899795308,\n",
       " 0.20031500771693764,\n",
       " 0.20010404851019967,\n",
       " 0.19997757964226148,\n",
       " 0.1997950434868583,\n",
       " 0.1996126739473732,\n",
       " 0.19948651563579387,\n",
       " 0.19930442771531756,\n",
       " 0.19916447319141137,\n",
       " 0.19895472565549926,\n",
       " 0.19877312314393064,\n",
       " 0.19864749544150426,\n",
       " 0.1980901100263433,\n",
       " 0.197951008214321,\n",
       " 0.1977842149706055,\n",
       " 0.19763144462702723,\n",
       " 0.1975065384831633,\n",
       " 0.19735398261945344,\n",
       " 0.19720154459129333,\n",
       " 0.19699386428871077,\n",
       " 0.19684170441925578,\n",
       " 0.1967034792561589,\n",
       " 0.19657915960082836,\n",
       " 0.19645491851745173,\n",
       " 0.19633075595637028,\n",
       " 0.1961791082778794,\n",
       " 0.196055120033155,\n",
       " 0.19593121015092785,\n",
       " 0.19577987108528547,\n",
       " 0.1956149072386898,\n",
       " 0.1954912755777889,\n",
       " 0.19536772205401873,\n",
       " 0.19521681823175602,\n",
       " 0.19462803902782902,\n",
       " 0.1943957559547426,\n",
       " 0.19424560288801898,\n",
       " 0.19412283664874436,\n",
       " 0.1940001479996406,\n",
       " 0.19387753689166942,\n",
       " 0.19372778410210806,\n",
       " 0.1936053451323522,\n",
       " 0.1934829835459277,\n",
       " 0.1933335355129932,\n",
       " 0.1932113457144716,\n",
       " 0.19264214696364312,\n",
       " 0.1925068707920516,\n",
       " 0.19235817671757025,\n",
       " 0.19218259542440128,\n",
       " 0.19203415182319117,\n",
       " 0.19191278325535177,\n",
       " 0.1917914913943331,\n",
       " 0.19164334988546675,\n",
       " 0.19152222831052437,\n",
       " 0.19117275137449372,\n",
       " 0.1910519272251226,\n",
       " 0.1909311794384913,\n",
       " 0.19081050796633736,\n",
       " 0.1906765179988045,\n",
       " 0.19055600747663745,\n",
       " 0.19040882026689257,\n",
       " 0.19020829363567696,\n",
       " 0.1900613750032953,\n",
       " 0.18991456985221428,\n",
       " 0.18976787809477977,\n",
       " 0.18962129964340557,\n",
       " 0.18912909342181758,\n",
       " 0.18898300837358967,\n",
       " 0.18883703616279432,\n",
       " 0.18871768822173007,\n",
       " 0.18853218577968955,\n",
       " 0.18838656178840493,\n",
       " 0.1882674985541449,\n",
       " 0.18810886462217696,\n",
       " 0.18795036435493906,\n",
       " 0.18777880643840988,\n",
       " 0.18760740511704785,\n",
       " 0.18700216341044118,\n",
       " 0.18658227769201657,\n",
       " 0.1864381598276417,\n",
       " 0.1863203280136958,\n",
       " 0.1861764124816575,\n",
       " 0.18605874609610135,\n",
       " 0.1859280928862005,\n",
       " 0.18581058344248713,\n",
       " 0.1856931482665681,\n",
       " 0.18557578731150498,\n",
       " 0.18545850053038906,\n",
       " 0.18534128787634127,\n",
       " 0.1852241493025121,\n",
       " 0.18510708476208174,\n",
       " 0.18486019142155785,\n",
       " 0.18474335690816354,\n",
       " 0.1846265962359971,\n",
       " 0.18448398895793472,\n",
       " 0.1843414918310433,\n",
       " 0.18417322803236988,\n",
       " 0.18405682769051177,\n",
       " 0.18391466050690522,\n",
       " 0.1831539993783515,\n",
       " 0.18298681950272216,\n",
       " 0.1828711689894896,\n",
       " 0.18275559156917845,\n",
       " 0.18262725788335687,\n",
       " 0.18248619491259485,\n",
       " 0.18237086080188208,\n",
       " 0.18222999587457983,\n",
       " 0.18211482368564005,\n",
       " 0.18199972428731323,\n",
       " 0.18188469763359458,\n",
       " 0.18146355486448562,\n",
       " 0.18099252396835874,\n",
       " 0.18039595001525233,\n",
       " 0.1802819369717936,\n",
       " 0.18014268554843696,\n",
       " 0.18002883257205654,\n",
       " 0.1798645052958778,\n",
       " 0.17972557630058023,\n",
       " 0.17961198694372568,\n",
       " 0.1794984693771096,\n",
       " 0.17886912144124842,\n",
       " 0.17875607337717278,\n",
       " 0.1782294597184715,\n",
       " 0.1780792838240405,\n",
       " 0.17796673494961168,\n",
       " 0.1771435471368323,\n",
       " 0.17700671983459895,\n",
       " 0.1768948488372773,\n",
       " 0.17675821363189398,\n",
       " 0.1766092774073656,\n",
       " 0.17649765759983355,\n",
       " 0.17638610833775425,\n",
       " 0.17624986608820364,\n",
       " 0.17611372907341755,\n",
       " 0.17600242246013253,\n",
       " 0.17584177042306423,\n",
       " 0.17570594862511674,\n",
       " 0.17559489973541131,\n",
       " 0.17545926862264957,\n",
       " 0.17534837563853867,\n",
       " 0.17521293494325282,\n",
       " 0.17507759886360352,\n",
       " 0.17494236731878474,\n",
       " 0.17480724022805275,\n",
       " 0.17469675933601866,\n",
       " 0.1745618219551476,\n",
       " 0.17440248487387644,\n",
       " 0.17424329323280052,\n",
       " 0.1741209370090689,\n",
       " 0.17401088987133317,\n",
       " 0.17390091228509846,\n",
       " 0.1737910042064071,\n",
       " 0.1736567664391143,\n",
       " 0.17354701266439124,\n",
       " 0.17343732825575917,\n",
       " 0.1733277131693777,\n",
       " 0.17281709140720766,\n",
       " 0.17268360589910278,\n",
       " 0.1725744671769623,\n",
       " 0.17246539743219003,\n",
       " 0.1723563966211912,\n",
       " 0.17224746470039862,\n",
       " 0.17211441917719206,\n",
       " 0.172005640189904,\n",
       " 0.17189692995262618,\n",
       " 0.1717520898389527,\n",
       " 0.17123408089052222,\n",
       " 0.1711258582907103,\n",
       " 0.1707296269487429,\n",
       " 0.1705977538173516,\n",
       " 0.17046598254597772,\n",
       " 0.17035824539625458,\n",
       " 0.17025057633808405,\n",
       " 0.17013102385934942,\n",
       " 0.17002349840872089,\n",
       " 0.1699160409158479,\n",
       " 0.16978479620577822,\n",
       " 0.16930839669764017,\n",
       " 0.16917762133754372,\n",
       " 0.1690231988636121,\n",
       " 0.1689163735755946,\n",
       " 0.16826501779030256,\n",
       " 0.1681586716845042,\n",
       " 0.168028784382564,\n",
       " 0.16789899740676828,\n",
       " 0.16779288263153969,\n",
       " 0.16726331390086285,\n",
       " 0.16715760088748746,\n",
       " 0.16700502225408762,\n",
       " 0.16689947248504639,\n",
       " 0.16679398942509926,\n",
       " 0.16666515621626588,\n",
       " 0.1665598212478415,\n",
       " 0.16645455285275387,\n",
       " 0.16634935098892764,\n",
       " 0.16622086122290475,\n",
       " 0.16611580705581977,\n",
       " 0.1659641793542249,\n",
       " 0.16583598709830902,\n",
       " 0.16570789385926862,\n",
       " 0.16560316389552812,\n",
       " 0.165498500122752,\n",
       " 0.16539390249910657,\n",
       " 0.16496458412624518,\n",
       " 0.16481400724148654,\n",
       " 0.16450170966107402,\n",
       " 0.16437464703017665,\n",
       " 0.16424768254362207,\n",
       " 0.16414387545612222,\n",
       " 0.1640170892196502,\n",
       " 0.16343054050173997,\n",
       " 0.16332724986070768,\n",
       " 0.1632240245009654,\n",
       " 0.16312086438125453,\n",
       " 0.16301776946034216,\n",
       " 0.16291473969702178,\n",
       " 0.16177433651914264,\n",
       " 0.16167209262476195,\n",
       " 0.16156991335011117,\n",
       " 0.1614677986543497,\n",
       " 0.16132041357627994,\n",
       " 0.1611958082076872,\n",
       " 0.16109392995218866,\n",
       " 0.16099211608533068,\n",
       " 0.1608677642967342,\n",
       " 0.16076609337008466,\n",
       " 0.16064191616350865,\n",
       " 0.16054038797638862,\n",
       " 0.16041638510673098,\n",
       " 0.16029247801802837,\n",
       " 0.1601461657527744,\n",
       " 0.1600449508876171,\n",
       " 0.15994379999182726,\n",
       " 0.1598202579322064,\n",
       " 0.1594166052605539,\n",
       " 0.15929347041098385,\n",
       " 0.15918161217447452,\n",
       " 0.15908100692216623,\n",
       " 0.158868826814293,\n",
       " 0.15870151612668093,\n",
       " 0.15860121430253474,\n",
       " 0.15845644579422072,\n",
       " 0.15835629885833255,\n",
       " 0.15825621521686406,\n",
       " 0.1579341535680557,\n",
       " 0.15783433672897007,\n",
       " 0.1577345829756777,\n",
       " 0.15763489226830746,\n",
       " 0.15751313363021122,\n",
       " 0.15741358288226825,\n",
       " 0.1573140950519448,\n",
       " 0.15720362676215763,\n",
       " 0.15710427162736443,\n",
       " 0.1570049792865603,\n",
       " 0.15690574970005833,\n",
       " 0.1561690091348787,\n",
       " 0.15607030789450216,\n",
       " 0.15597166903484325,\n",
       " 0.15587309251647627,\n",
       " 0.1557526947086842,\n",
       " 0.15565425658549384,\n",
       " 0.15555588067672696,\n",
       " 0.1554357278862723,\n",
       " 0.15529384878046748,\n",
       " 0.155130303035576,\n",
       " 0.15465156178743913,\n",
       " 0.1545538195973648,\n",
       " 0.15406603448525633,\n",
       " 0.15396866235753504,\n",
       " 0.15384973554908304,\n",
       " 0.1537416999838992,\n",
       " 0.15364453284062243,\n",
       " 0.15354742710848995,\n",
       " 0.1531596175155158,\n",
       " 0.15275132550780335,\n",
       " 0.15261189667912758,\n",
       " 0.15249401784894256,\n",
       " 0.1523762300694483,\n",
       " 0.1517353509917296,\n",
       " 0.15134148656862198,\n",
       " 0.15122458901487043,\n",
       " 0.15112901272483775,\n",
       " 0.15101227928783395,\n",
       " 0.15089563601680867]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epsilon_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the diagram that illustrates the overall resulting data flow.\n",
    "\n",
    ".. figure:: /_static/img/reinforcement_learning_diagram.jpg\n",
    "\n",
    "Actions are chosen either randomly or based on a policy, getting the next\n",
    "step sample from the gym environment. We record the results in the\n",
    "replay memory and also run optimization step on every iteration.\n",
    "Optimization picks a random batch from the replay memory to do training of the\n",
    "new policy. The \"older\" target_net is also used in optimization to compute the\n",
    "expected Q values. A soft update of its weights are performed at every step.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLAG = False\n",
      "############\n",
      "#P        R#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#     A    #\n",
      "#          #\n",
      "#          #\n",
      "#G         #\n",
      "############\n",
      "FLAG = False\n",
      "############\n",
      "#         R#\n",
      "#P         #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#     A    #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#G         #\n",
      "############\n",
      "FLAG = False\n",
      "############\n",
      "#         R#\n",
      "#          #\n",
      "#P         #\n",
      "#          #\n",
      "#          #\n",
      "#    A     #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#G         #\n",
      "############\n",
      "FLAG = False\n",
      "############\n",
      "#         R#\n",
      "#          #\n",
      "#          #\n",
      "#P         #\n",
      "#          #\n",
      "#   A      #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#G         #\n",
      "############\n",
      "FLAG = False\n",
      "############\n",
      "#         R#\n",
      "#          #\n",
      "#          #\n",
      "#P         #\n",
      "#          #\n",
      "#  A       #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#G         #\n",
      "############\n",
      "FLAG = False\n",
      "############\n",
      "#         R#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#P         #\n",
      "# A        #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#G         #\n",
      "############\n",
      "FLAG = False\n",
      "############\n",
      "#         R#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#P         #\n",
      "#A         #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#G         #\n",
      "############\n",
      "FLAG = False\n",
      "############\n",
      "#         R#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#P         #\n",
      "#          #\n",
      "#A         #\n",
      "#          #\n",
      "#          #\n",
      "#G         #\n",
      "############\n",
      "FLAG = False\n",
      "############\n",
      "#         R#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#P         #\n",
      "#          #\n",
      "#          #\n",
      "#A         #\n",
      "#          #\n",
      "#G         #\n",
      "############\n",
      "FLAG = False\n",
      "############\n",
      "#         R#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#P         #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#A         #\n",
      "#G         #\n",
      "############\n",
      "FLAG = True\n",
      "############\n",
      "#         R#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#P         #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#A         #\n",
      "############\n",
      "FLAG = True\n",
      "############\n",
      "#         R#\n",
      "#          #\n",
      "#          #\n",
      "#P         #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#A         #\n",
      "############\n",
      "FLAG = True\n",
      "############\n",
      "#         R#\n",
      "#          #\n",
      "#          #\n",
      "#P         #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#A         #\n",
      "############\n",
      "FLAG = True\n",
      "############\n",
      "#         R#\n",
      "#          #\n",
      "#          #\n",
      "#P         #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#A         #\n",
      "############\n",
      "FLAG = True\n",
      "############\n",
      "#         R#\n",
      "#          #\n",
      "#          #\n",
      "#P         #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#A         #\n",
      "############\n",
      "FLAG = True\n",
      "############\n",
      "#         R#\n",
      "#          #\n",
      "#P         #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#A         #\n",
      "############\n",
      "FLAG = True\n",
      "############\n",
      "#         R#\n",
      "#P         #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#A         #\n",
      "############\n",
      "FLAG = True\n",
      "############\n",
      "#         R#\n",
      "#P         #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#A         #\n",
      "############\n",
      "FLAG = True\n",
      "############\n",
      "#P        R#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#A         #\n",
      "############\n",
      "FLAG = True\n",
      "############\n",
      "#P        R#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#A         #\n",
      "############\n",
      "FLAG = True\n",
      "############\n",
      "# P       R#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#A         #\n",
      "############\n",
      "FLAG = True\n",
      "############\n",
      "#  P      R#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#A         #\n",
      "############\n",
      "FLAG = True\n",
      "############\n",
      "#   P     R#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#A         #\n",
      "#G         #\n",
      "############\n",
      "FLAG = True\n",
      "############\n",
      "#   P     R#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#A         #\n",
      "############\n",
      "FLAG = True\n",
      "############\n",
      "#   P     R#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#A         #\n",
      "############\n",
      "FLAG = True\n",
      "############\n",
      "#    P    R#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#A         #\n",
      "#G         #\n",
      "############\n",
      "FLAG = True\n",
      "############\n",
      "#    P    R#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#A         #\n",
      "############\n",
      "FLAG = True\n",
      "############\n",
      "#     P   R#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#A         #\n",
      "############\n",
      "FLAG = True\n",
      "############\n",
      "#     P   R#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#A         #\n",
      "############\n",
      "FLAG = True\n",
      "############\n",
      "#      P  R#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#A         #\n",
      "############\n",
      "FLAG = True\n",
      "############\n",
      "#       P R#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#A         #\n",
      "############\n",
      "FLAG = True\n",
      "############\n",
      "#        PR#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#A         #\n",
      "############\n",
      "FLAG = True\n",
      "############\n",
      "#        PR#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#A         #\n",
      "############\n",
      "FLAG = False\n",
      "############\n",
      "#         P#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#A         #\n",
      "############\n",
      "FLAG = True\n",
      "############\n",
      "#         R#\n",
      "#         P#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#A         #\n",
      "############\n",
      "FLAG = False\n",
      "############\n",
      "#         P#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#A         #\n",
      "############\n",
      "FLAG = False\n",
      "############\n",
      "#         P#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#A         #\n",
      "############\n",
      "FLAG = True\n",
      "############\n",
      "#         R#\n",
      "#         P#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#A         #\n",
      "############\n",
      "FLAG = True\n",
      "############\n",
      "#         R#\n",
      "#         P#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#A         #\n",
      "############\n",
      "FLAG = False\n",
      "############\n",
      "#         P#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#A         #\n",
      "############\n",
      "FLAG = False\n",
      "############\n",
      "#         P#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#A         #\n",
      "############\n",
      "FLAG = True\n",
      "############\n",
      "#         R#\n",
      "#         P#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#A         #\n",
      "############\n",
      "FLAG = False\n",
      "############\n",
      "#         P#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#A         #\n",
      "############\n",
      "FLAG = False\n",
      "############\n",
      "#         P#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#A         #\n",
      "############\n",
      "FLAG = False\n",
      "############\n",
      "#         P#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#A         #\n",
      "############\n",
      "FLAG = False\n",
      "############\n",
      "#         P#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#A         #\n",
      "############\n",
      "FLAG = True\n",
      "############\n",
      "#         R#\n",
      "#         P#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#A         #\n",
      "############\n",
      "FLAG = True\n",
      "############\n",
      "#         R#\n",
      "#         P#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#A         #\n",
      "############\n",
      "FLAG = False\n",
      "############\n",
      "#         P#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#A         #\n",
      "############\n",
      "FLAG = False\n",
      "############\n",
      "#         P#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#GA        #\n",
      "############\n",
      "FLAG = False\n",
      "############\n",
      "#         R#\n",
      "#         P#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#GA        #\n",
      "############\n",
      "FLAG = False\n",
      "############\n",
      "#         R#\n",
      "#          #\n",
      "#         P#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#GA        #\n",
      "############\n",
      "FLAG = False\n",
      "############\n",
      "#         R#\n",
      "#          #\n",
      "#          #\n",
      "#         P#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#GA        #\n",
      "############\n",
      "FLAG = False\n",
      "############\n",
      "#         R#\n",
      "#          #\n",
      "#          #\n",
      "#         P#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#GA        #\n",
      "############\n",
      "FLAG = False\n",
      "############\n",
      "#         R#\n",
      "#          #\n",
      "#          #\n",
      "#         P#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#G A       #\n",
      "############\n",
      "FLAG = False\n",
      "############\n",
      "#         R#\n",
      "#          #\n",
      "#          #\n",
      "#         P#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#GA        #\n",
      "############\n",
      "FLAG = False\n",
      "############\n",
      "#         R#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#         P#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#GA        #\n",
      "############\n",
      "FLAG = False\n",
      "############\n",
      "#         R#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#         P#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#GA        #\n",
      "############\n",
      "FLAG = True\n",
      "############\n",
      "#         R#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#         P#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#A         #\n",
      "############\n",
      "FLAG = True\n",
      "############\n",
      "#         R#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#         P#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#A         #\n",
      "############\n",
      "FLAG = True\n",
      "############\n",
      "#         R#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#         P#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#A         #\n",
      "############\n",
      "FLAG = True\n",
      "############\n",
      "#         R#\n",
      "#          #\n",
      "#          #\n",
      "#         P#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#A         #\n",
      "############\n",
      "FLAG = True\n",
      "############\n",
      "#         R#\n",
      "#          #\n",
      "#          #\n",
      "#         P#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#A         #\n",
      "############\n",
      "FLAG = True\n",
      "############\n",
      "#         R#\n",
      "#          #\n",
      "#          #\n",
      "#         P#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#A         #\n",
      "############\n",
      "FLAG = True\n",
      "############\n",
      "#         R#\n",
      "#          #\n",
      "#         P#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#A         #\n",
      "############\n",
      "FLAG = True\n",
      "############\n",
      "#         R#\n",
      "#         P#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#A         #\n",
      "############\n",
      "FLAG = False\n",
      "############\n",
      "#         P#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#A         #\n",
      "############\n",
      "FLAG = False\n",
      "############\n",
      "#         P#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#A         #\n",
      "############\n",
      "FLAG = True\n",
      "############\n",
      "#         R#\n",
      "#         P#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#A         #\n",
      "############\n",
      "FLAG = False\n",
      "############\n",
      "#         P#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#A         #\n",
      "############\n",
      "FLAG = True\n",
      "############\n",
      "#         R#\n",
      "#         P#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#A         #\n",
      "############\n",
      "FLAG = True\n",
      "############\n",
      "#         R#\n",
      "#         P#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#A         #\n",
      "############\n",
      "FLAG = False\n",
      "############\n",
      "#         P#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#A         #\n",
      "############\n",
      "FLAG = False\n",
      "############\n",
      "#         P#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#A         #\n",
      "############\n",
      "FLAG = False\n",
      "############\n",
      "#         P#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#A         #\n",
      "############\n",
      "FLAG = True\n",
      "############\n",
      "#         R#\n",
      "#         P#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#A         #\n",
      "############\n",
      "FLAG = False\n",
      "############\n",
      "#         P#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#A         #\n",
      "############\n",
      "FLAG = False\n",
      "############\n",
      "#         P#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#A         #\n",
      "############\n",
      "FLAG = False\n",
      "############\n",
      "#         P#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#A         #\n",
      "############\n",
      "FLAG = False\n",
      "############\n",
      "#         P#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#A         #\n",
      "############\n",
      "FLAG = True\n",
      "############\n",
      "#         R#\n",
      "#         P#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#A         #\n",
      "############\n",
      "FLAG = False\n",
      "############\n",
      "#         P#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#A         #\n",
      "############\n",
      "FLAG = False\n",
      "############\n",
      "#         P#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#A         #\n",
      "############\n",
      "FLAG = True\n",
      "############\n",
      "#         R#\n",
      "#         P#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#A         #\n",
      "############\n",
      "FLAG = False\n",
      "############\n",
      "#         P#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#A         #\n",
      "############\n",
      "FLAG = True\n",
      "############\n",
      "#         R#\n",
      "#         P#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#A         #\n",
      "############\n",
      "FLAG = True\n",
      "############\n",
      "#         R#\n",
      "#         P#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#A         #\n",
      "############\n",
      "FLAG = False\n",
      "############\n",
      "#         P#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#A         #\n",
      "#G         #\n",
      "############\n",
      "FLAG = True\n",
      "############\n",
      "#         R#\n",
      "#         P#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#A         #\n",
      "############\n",
      "FLAG = False\n",
      "############\n",
      "#         P#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#A         #\n",
      "############\n",
      "FLAG = True\n",
      "############\n",
      "#         R#\n",
      "#         P#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#A         #\n",
      "############\n",
      "FLAG = False\n",
      "############\n",
      "#         P#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#GA        #\n",
      "############\n",
      "FLAG = False\n",
      "############\n",
      "#         P#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#GA        #\n",
      "############\n",
      "FLAG = False\n",
      "############\n",
      "#         P#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#GA        #\n",
      "############\n",
      "FLAG = False\n",
      "############\n",
      "#         R#\n",
      "#         P#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#GA        #\n",
      "############\n",
      "FLAG = False\n",
      "############\n",
      "#         R#\n",
      "#         P#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#GA        #\n",
      "############\n",
      "FLAG = False\n",
      "############\n",
      "#         R#\n",
      "#         P#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#GA        #\n",
      "############\n",
      "FLAG = False\n",
      "############\n",
      "#         R#\n",
      "#         P#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#GA        #\n",
      "############\n",
      "FLAG = False\n",
      "############\n",
      "#         R#\n",
      "#          #\n",
      "#         P#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#GA        #\n",
      "############\n",
      "FLAG = False\n",
      "############\n",
      "#         R#\n",
      "#          #\n",
      "#         P#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#GA        #\n",
      "############\n",
      "FLAG = False\n",
      "############\n",
      "#         R#\n",
      "#          #\n",
      "#          #\n",
      "#         P#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#G A       #\n",
      "############\n",
      "FLAG = False\n",
      "############\n",
      "#         R#\n",
      "#          #\n",
      "#          #\n",
      "#         P#\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#          #\n",
      "#GA        #\n",
      "############\n"
     ]
    }
   ],
   "source": [
    "state = env.reset()\n",
    "state = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "\n",
    "\n",
    "for t in count():\n",
    "    action = select_action(state)\n",
    "    observation, reward, terminated, info = env.step(action.item())\n",
    "    env.render()\n",
    "    \n",
    "    next_state = torch.tensor(observation, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "\n",
    "    state = next_state\n",
    "    if t>100:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
